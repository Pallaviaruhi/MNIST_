{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4407fd3c-d31e-454a-b78c-710262a65410",
   "metadata": {},
   "source": [
    "## Data and problem statement\n",
    "\n",
    "The MNIST dataset contains handwritten digits as gray-scale images with pixel sizes of 28-by-28. The pixel values are converted to float numbers and normalized with minimum-maximum scaling. The dataset is labeled with ten categories, represents digits of 0-9.\n",
    "\n",
    "A supervised image classification problem is proposed to demonstrate the application of the Swin Transformer. By taking preprocessed grayscale images as inputs, the Swin Transformer is trained to classify the ten image labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea0d3593-3c00-48fe-8b57-9b217670251e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: timm in c:\\users\\palla\\appdata\\roaming\\python\\python312\\site-packages (1.0.15)\n",
      "Requirement already satisfied: torch in c:\\users\\palla\\appdata\\roaming\\python\\python312\\site-packages (from timm) (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\palla\\appdata\\roaming\\python\\python312\\site-packages (from timm) (0.21.0)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from timm) (6.0.1)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\palla\\appdata\\roaming\\python\\python312\\site-packages (from timm) (0.29.2)\n",
      "Requirement already satisfied: safetensors in c:\\users\\palla\\appdata\\roaming\\python\\python312\\site-packages (from timm) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub->timm) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub->timm) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub->timm) (23.2)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub->timm) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub->timm) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub->timm) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch->timm) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\palla\\appdata\\roaming\\python\\python312\\site-packages (from torch->timm) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from torch->timm) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\palla\\appdata\\roaming\\python\\python312\\site-packages (from torch->timm) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision->timm) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision->timm) (10.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\palla\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.42.1->huggingface_hub->timm) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\palla\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch->timm) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface_hub->timm) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface_hub->timm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface_hub->timm) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface_hub->timm) (2024.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install timm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f143c7b6-3fa6-4b2c-ad17-e3b1812e3cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: jupyter in c:\\users\\palla\\appdata\\roaming\\python\\python312\\site-packages (1.1.1)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\palla\\appdata\\roaming\\python\\python312\\site-packages (8.1.5)\n",
      "Requirement already satisfied: notebook in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter) (7.0.8)\n",
      "Requirement already satisfied: jupyter-console in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter) (7.10.0)\n",
      "Requirement already satisfied: ipykernel in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter) (6.28.0)\n",
      "Requirement already satisfied: jupyterlab in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter) (4.0.11)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipywidgets) (8.25.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\palla\\appdata\\roaming\\python\\python312\\site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\users\\palla\\appdata\\roaming\\python\\python312\\site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\palla\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel->jupyter) (1.6.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel->jupyter) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel->jupyter) (5.7.2)\n",
      "Requirement already satisfied: nest-asyncio in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel->jupyter) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel->jupyter) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel->jupyter) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel->jupyter) (6.4.1)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyterlab->jupyter) (2.0.4)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\palla\\appdata\\roaming\\python\\python312\\site-packages (from jupyterlab->jupyter) (3.1.4)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyterlab->jupyter) (2.2.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyterlab->jupyter) (2.14.1)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.19.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyterlab->jupyter) (2.25.1)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyterlab->jupyter) (0.2.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->jupyter) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->jupyter) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->jupyter) (0.1.2)\n",
      "Requirement already satisfied: markupsafe>=2.0 in c:\\users\\palla\\appdata\\roaming\\python\\python312\\site-packages (from nbconvert->jupyter) (2.1.5)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->jupyter) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->jupyter) (0.8.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->jupyter) (5.9.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->jupyter) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->jupyter) (1.2.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from bleach!=5.0.0->nbconvert->jupyter) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\programdata\\anaconda3\\lib\\site-packages (from bleach!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (305.1)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (4.2.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (21.3.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.4.4)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.14.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.0.10)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.17.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter) (2.11.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter) (0.9.6)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter) (4.19.2)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter) (2.32.2)\n",
      "Requirement already satisfied: fastjsonschema in c:\\programdata\\anaconda3\\lib\\site-packages (from nbformat>=5.7->nbconvert->jupyter) (2.16.2)\n",
      "Requirement already satisfied: wcwidth in c:\\programdata\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter) (2.5)\n",
      "Requirement already satisfied: executing in c:\\programdata\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\programdata\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\programdata\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\programdata\\anaconda3\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (21.2.0)\n",
      "Requirement already satisfied: pytz>=2015.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from babel>=2.10->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter) (2024.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter) (0.10.6)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (6.0.1)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.19.0->jupyterlab->jupyter) (2024.6.2)\n",
      "Requirement already satisfied: fqdn in c:\\users\\palla\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\palla\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.1)\n",
      "Requirement already satisfied: uri-template in c:\\users\\palla\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in c:\\users\\palla\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade jupyter ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2f958c3-e2d1-4432-ad39-39d6fd3e7f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\palla\\.conda\\envs\\pytorch_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.15\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "print(timm.__version__)  # To verify installation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee832b44-7f2c-45d3-9bea-b424d4d9e959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import timm  \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a62f5da5-c6b2-4e4c-ab5b-1582619475b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f174976-20ca-4143-8a05-8b60a8253c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Enable cuDNN optimization for performance boost\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0447a997-45e1-4940-83b6-a796bea190ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Reduce size for faster training\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90a3f744-62d3-4abd-a89c-4ab6491424b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f99e39c1-e324-474b-8ed6-f62f4396255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False, num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11a85aa0-a8e2-4d2c-a36e-226d8f8da923",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define Swin Transformer Model\n",
    "class SwinModel(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SwinModel, self).__init__()\n",
    "        self.swin = timm.create_model(\"swin_s3_tiny_224\", pretrained=True, num_classes=num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.swin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9137582-dcda-4e22-a05e-39cf5fb76baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = SwinModel(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f70472a-8deb-4e7d-97bb-66b3dc97dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)  # AdamW is better for transformers\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)  # Reduce LR every 3 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cf63946-3826-4914-8d46-ac07520724cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable mixed precision training\n",
    "scaler = torch.amp.GradScaler(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e5b43ab-680a-4510-8c4a-0d19b782ad23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.amp import GradScaler, autocast\n",
    "\n",
    "scaler = GradScaler(device=\"cuda\")  # Use correct syntax\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast(device_type=\"cuda\"):  # Mixed precision\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Show progress every 10 batches\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}], Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} completed. Average Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ceb5beb-5666-4204-9253-33b3cd7b9cfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Batch [0/30000], Loss: 2.1016\n",
      "Epoch [1/1], Batch [10/30000], Loss: 1.6470\n",
      "Epoch [1/1], Batch [20/30000], Loss: 2.0225\n",
      "Epoch [1/1], Batch [30/30000], Loss: 1.3716\n",
      "Epoch [1/1], Batch [40/30000], Loss: 3.6309\n",
      "Epoch [1/1], Batch [50/30000], Loss: 2.3115\n",
      "Epoch [1/1], Batch [60/30000], Loss: 3.3623\n",
      "Epoch [1/1], Batch [70/30000], Loss: 2.6348\n",
      "Epoch [1/1], Batch [80/30000], Loss: 1.6543\n",
      "Epoch [1/1], Batch [90/30000], Loss: 2.4692\n",
      "Epoch [1/1], Batch [100/30000], Loss: 2.1953\n",
      "Epoch [1/1], Batch [110/30000], Loss: 2.9629\n",
      "Epoch [1/1], Batch [120/30000], Loss: 1.8965\n",
      "Epoch [1/1], Batch [130/30000], Loss: 1.6411\n",
      "Epoch [1/1], Batch [140/30000], Loss: 3.6162\n",
      "Epoch [1/1], Batch [150/30000], Loss: 2.0730\n",
      "Epoch [1/1], Batch [160/30000], Loss: 2.0894\n",
      "Epoch [1/1], Batch [170/30000], Loss: 2.0029\n",
      "Epoch [1/1], Batch [180/30000], Loss: 2.9443\n",
      "Epoch [1/1], Batch [190/30000], Loss: 2.3604\n",
      "Epoch [1/1], Batch [200/30000], Loss: 2.4756\n",
      "Epoch [1/1], Batch [210/30000], Loss: 2.6797\n",
      "Epoch [1/1], Batch [220/30000], Loss: 2.8906\n",
      "Epoch [1/1], Batch [230/30000], Loss: 2.3018\n",
      "Epoch [1/1], Batch [240/30000], Loss: 2.7656\n",
      "Epoch [1/1], Batch [250/30000], Loss: 1.9282\n",
      "Epoch [1/1], Batch [260/30000], Loss: 2.0161\n",
      "Epoch [1/1], Batch [270/30000], Loss: 2.3809\n",
      "Epoch [1/1], Batch [280/30000], Loss: 2.6660\n",
      "Epoch [1/1], Batch [290/30000], Loss: 2.3594\n",
      "Epoch [1/1], Batch [300/30000], Loss: 2.2129\n",
      "Epoch [1/1], Batch [310/30000], Loss: 2.2109\n",
      "Epoch [1/1], Batch [320/30000], Loss: 2.5283\n",
      "Epoch [1/1], Batch [330/30000], Loss: 2.4727\n",
      "Epoch [1/1], Batch [340/30000], Loss: 2.5664\n",
      "Epoch [1/1], Batch [350/30000], Loss: 2.3896\n",
      "Epoch [1/1], Batch [360/30000], Loss: 2.4424\n",
      "Epoch [1/1], Batch [370/30000], Loss: 2.1484\n",
      "Epoch [1/1], Batch [380/30000], Loss: 2.2920\n",
      "Epoch [1/1], Batch [390/30000], Loss: 2.6875\n",
      "Epoch [1/1], Batch [400/30000], Loss: 2.5107\n",
      "Epoch [1/1], Batch [410/30000], Loss: 2.5020\n",
      "Epoch [1/1], Batch [420/30000], Loss: 2.0527\n",
      "Epoch [1/1], Batch [430/30000], Loss: 2.6846\n",
      "Epoch [1/1], Batch [440/30000], Loss: 2.2529\n",
      "Epoch [1/1], Batch [450/30000], Loss: 2.0557\n",
      "Epoch [1/1], Batch [460/30000], Loss: 2.5264\n",
      "Epoch [1/1], Batch [470/30000], Loss: 2.2832\n",
      "Epoch [1/1], Batch [480/30000], Loss: 2.3301\n",
      "Epoch [1/1], Batch [490/30000], Loss: 2.0215\n",
      "Epoch [1/1], Batch [500/30000], Loss: 2.7979\n",
      "Epoch [1/1], Batch [510/30000], Loss: 2.5322\n",
      "Epoch [1/1], Batch [520/30000], Loss: 2.4365\n",
      "Epoch [1/1], Batch [530/30000], Loss: 2.5791\n",
      "Epoch [1/1], Batch [540/30000], Loss: 2.2979\n",
      "Epoch [1/1], Batch [550/30000], Loss: 2.2861\n",
      "Epoch [1/1], Batch [560/30000], Loss: 2.2510\n",
      "Epoch [1/1], Batch [570/30000], Loss: 2.1421\n",
      "Epoch [1/1], Batch [580/30000], Loss: 2.0303\n",
      "Epoch [1/1], Batch [590/30000], Loss: 2.3408\n",
      "Epoch [1/1], Batch [600/30000], Loss: 2.0938\n",
      "Epoch [1/1], Batch [610/30000], Loss: 2.4395\n",
      "Epoch [1/1], Batch [620/30000], Loss: 2.1611\n",
      "Epoch [1/1], Batch [630/30000], Loss: 2.0947\n",
      "Epoch [1/1], Batch [640/30000], Loss: 2.2383\n",
      "Epoch [1/1], Batch [650/30000], Loss: 2.4922\n",
      "Epoch [1/1], Batch [660/30000], Loss: 2.5957\n",
      "Epoch [1/1], Batch [670/30000], Loss: 2.4619\n",
      "Epoch [1/1], Batch [680/30000], Loss: 2.3984\n",
      "Epoch [1/1], Batch [690/30000], Loss: 2.2900\n",
      "Epoch [1/1], Batch [700/30000], Loss: 2.5186\n",
      "Epoch [1/1], Batch [710/30000], Loss: 2.0234\n",
      "Epoch [1/1], Batch [720/30000], Loss: 2.1719\n",
      "Epoch [1/1], Batch [730/30000], Loss: 2.3018\n",
      "Epoch [1/1], Batch [740/30000], Loss: 2.2334\n",
      "Epoch [1/1], Batch [750/30000], Loss: 2.3281\n",
      "Epoch [1/1], Batch [760/30000], Loss: 2.4443\n",
      "Epoch [1/1], Batch [770/30000], Loss: 2.1006\n",
      "Epoch [1/1], Batch [780/30000], Loss: 2.2520\n",
      "Epoch [1/1], Batch [790/30000], Loss: 2.3364\n",
      "Epoch [1/1], Batch [800/30000], Loss: 2.2002\n",
      "Epoch [1/1], Batch [810/30000], Loss: 2.3965\n",
      "Epoch [1/1], Batch [820/30000], Loss: 2.5830\n",
      "Epoch [1/1], Batch [830/30000], Loss: 2.1592\n",
      "Epoch [1/1], Batch [840/30000], Loss: 2.1855\n",
      "Epoch [1/1], Batch [850/30000], Loss: 2.3057\n",
      "Epoch [1/1], Batch [860/30000], Loss: 2.4160\n",
      "Epoch [1/1], Batch [870/30000], Loss: 2.0879\n",
      "Epoch [1/1], Batch [880/30000], Loss: 2.3408\n",
      "Epoch [1/1], Batch [890/30000], Loss: 2.5273\n",
      "Epoch [1/1], Batch [900/30000], Loss: 1.9609\n",
      "Epoch [1/1], Batch [910/30000], Loss: 2.3906\n",
      "Epoch [1/1], Batch [920/30000], Loss: 2.3438\n",
      "Epoch [1/1], Batch [930/30000], Loss: 2.1538\n",
      "Epoch [1/1], Batch [940/30000], Loss: 2.6445\n",
      "Epoch [1/1], Batch [950/30000], Loss: 2.2134\n",
      "Epoch [1/1], Batch [960/30000], Loss: 2.1982\n",
      "Epoch [1/1], Batch [970/30000], Loss: 2.4424\n",
      "Epoch [1/1], Batch [980/30000], Loss: 2.6396\n",
      "Epoch [1/1], Batch [990/30000], Loss: 2.4297\n",
      "Epoch [1/1], Batch [1000/30000], Loss: 2.5742\n",
      "Epoch [1/1], Batch [1010/30000], Loss: 2.4795\n",
      "Epoch [1/1], Batch [1020/30000], Loss: 2.1504\n",
      "Epoch [1/1], Batch [1030/30000], Loss: 2.4404\n",
      "Epoch [1/1], Batch [1040/30000], Loss: 2.3330\n",
      "Epoch [1/1], Batch [1050/30000], Loss: 2.1377\n",
      "Epoch [1/1], Batch [1060/30000], Loss: 2.2139\n",
      "Epoch [1/1], Batch [1070/30000], Loss: 3.2764\n",
      "Epoch [1/1], Batch [1080/30000], Loss: 2.3457\n",
      "Epoch [1/1], Batch [1090/30000], Loss: 2.3330\n",
      "Epoch [1/1], Batch [1100/30000], Loss: 2.4658\n",
      "Epoch [1/1], Batch [1110/30000], Loss: 2.2627\n",
      "Epoch [1/1], Batch [1120/30000], Loss: 2.4209\n",
      "Epoch [1/1], Batch [1130/30000], Loss: 2.3555\n",
      "Epoch [1/1], Batch [1140/30000], Loss: 2.1807\n",
      "Epoch [1/1], Batch [1150/30000], Loss: 2.3125\n",
      "Epoch [1/1], Batch [1160/30000], Loss: 2.2295\n",
      "Epoch [1/1], Batch [1170/30000], Loss: 2.3711\n",
      "Epoch [1/1], Batch [1180/30000], Loss: 2.2637\n",
      "Epoch [1/1], Batch [1190/30000], Loss: 2.4287\n",
      "Epoch [1/1], Batch [1200/30000], Loss: 2.1504\n",
      "Epoch [1/1], Batch [1210/30000], Loss: 2.3301\n",
      "Epoch [1/1], Batch [1220/30000], Loss: 2.1240\n",
      "Epoch [1/1], Batch [1230/30000], Loss: 2.5254\n",
      "Epoch [1/1], Batch [1240/30000], Loss: 2.3779\n",
      "Epoch [1/1], Batch [1250/30000], Loss: 2.4414\n",
      "Epoch [1/1], Batch [1260/30000], Loss: 2.3545\n",
      "Epoch [1/1], Batch [1270/30000], Loss: 2.2373\n",
      "Epoch [1/1], Batch [1280/30000], Loss: 2.5234\n",
      "Epoch [1/1], Batch [1290/30000], Loss: 2.3535\n",
      "Epoch [1/1], Batch [1300/30000], Loss: 2.3691\n",
      "Epoch [1/1], Batch [1310/30000], Loss: 2.3057\n",
      "Epoch [1/1], Batch [1320/30000], Loss: 2.2021\n",
      "Epoch [1/1], Batch [1330/30000], Loss: 2.3438\n",
      "Epoch [1/1], Batch [1340/30000], Loss: 2.4023\n",
      "Epoch [1/1], Batch [1350/30000], Loss: 2.5518\n",
      "Epoch [1/1], Batch [1360/30000], Loss: 2.1758\n",
      "Epoch [1/1], Batch [1370/30000], Loss: 2.2969\n",
      "Epoch [1/1], Batch [1380/30000], Loss: 2.3135\n",
      "Epoch [1/1], Batch [1390/30000], Loss: 2.2754\n",
      "Epoch [1/1], Batch [1400/30000], Loss: 2.3516\n",
      "Epoch [1/1], Batch [1410/30000], Loss: 2.4131\n",
      "Epoch [1/1], Batch [1420/30000], Loss: 2.3857\n",
      "Epoch [1/1], Batch [1430/30000], Loss: 2.5488\n",
      "Epoch [1/1], Batch [1440/30000], Loss: 2.1123\n",
      "Epoch [1/1], Batch [1450/30000], Loss: 2.2783\n",
      "Epoch [1/1], Batch [1460/30000], Loss: 2.4395\n",
      "Epoch [1/1], Batch [1470/30000], Loss: 2.3359\n",
      "Epoch [1/1], Batch [1480/30000], Loss: 2.2627\n",
      "Epoch [1/1], Batch [1490/30000], Loss: 2.8857\n",
      "Epoch [1/1], Batch [1500/30000], Loss: 2.0532\n",
      "Epoch [1/1], Batch [1510/30000], Loss: 2.4268\n",
      "Epoch [1/1], Batch [1520/30000], Loss: 2.3779\n",
      "Epoch [1/1], Batch [1530/30000], Loss: 2.3828\n",
      "Epoch [1/1], Batch [1540/30000], Loss: 2.3213\n",
      "Epoch [1/1], Batch [1550/30000], Loss: 2.2002\n",
      "Epoch [1/1], Batch [1560/30000], Loss: 2.4795\n",
      "Epoch [1/1], Batch [1570/30000], Loss: 2.0752\n",
      "Epoch [1/1], Batch [1580/30000], Loss: 2.6016\n",
      "Epoch [1/1], Batch [1590/30000], Loss: 2.2119\n",
      "Epoch [1/1], Batch [1600/30000], Loss: 2.4482\n",
      "Epoch [1/1], Batch [1610/30000], Loss: 2.2324\n",
      "Epoch [1/1], Batch [1620/30000], Loss: 2.3018\n",
      "Epoch [1/1], Batch [1630/30000], Loss: 2.2998\n",
      "Epoch [1/1], Batch [1640/30000], Loss: 2.2764\n",
      "Epoch [1/1], Batch [1650/30000], Loss: 2.3779\n",
      "Epoch [1/1], Batch [1660/30000], Loss: 2.0151\n",
      "Epoch [1/1], Batch [1670/30000], Loss: 2.1338\n",
      "Epoch [1/1], Batch [1680/30000], Loss: 2.3613\n",
      "Epoch [1/1], Batch [1690/30000], Loss: 2.1445\n",
      "Epoch [1/1], Batch [1700/30000], Loss: 2.3550\n",
      "Epoch [1/1], Batch [1710/30000], Loss: 2.3848\n",
      "Epoch [1/1], Batch [1720/30000], Loss: 2.1719\n",
      "Epoch [1/1], Batch [1730/30000], Loss: 2.1904\n",
      "Epoch [1/1], Batch [1740/30000], Loss: 2.0635\n",
      "Epoch [1/1], Batch [1750/30000], Loss: 2.5518\n",
      "Epoch [1/1], Batch [1760/30000], Loss: 2.6367\n",
      "Epoch [1/1], Batch [1770/30000], Loss: 2.2539\n",
      "Epoch [1/1], Batch [1780/30000], Loss: 2.2529\n",
      "Epoch [1/1], Batch [1790/30000], Loss: 2.4268\n",
      "Epoch [1/1], Batch [1800/30000], Loss: 2.3574\n",
      "Epoch [1/1], Batch [1810/30000], Loss: 2.3906\n",
      "Epoch [1/1], Batch [1820/30000], Loss: 2.2939\n",
      "Epoch [1/1], Batch [1830/30000], Loss: 2.3115\n",
      "Epoch [1/1], Batch [1840/30000], Loss: 2.4961\n",
      "Epoch [1/1], Batch [1850/30000], Loss: 2.3486\n",
      "Epoch [1/1], Batch [1860/30000], Loss: 2.3076\n",
      "Epoch [1/1], Batch [1870/30000], Loss: 2.2734\n",
      "Epoch [1/1], Batch [1880/30000], Loss: 2.3027\n",
      "Epoch [1/1], Batch [1890/30000], Loss: 2.2217\n",
      "Epoch [1/1], Batch [1900/30000], Loss: 2.1270\n",
      "Epoch [1/1], Batch [1910/30000], Loss: 2.6035\n",
      "Epoch [1/1], Batch [1920/30000], Loss: 2.2231\n",
      "Epoch [1/1], Batch [1930/30000], Loss: 1.9692\n",
      "Epoch [1/1], Batch [1940/30000], Loss: 2.1553\n",
      "Epoch [1/1], Batch [1950/30000], Loss: 2.3418\n",
      "Epoch [1/1], Batch [1960/30000], Loss: 2.2383\n",
      "Epoch [1/1], Batch [1970/30000], Loss: 2.3037\n",
      "Epoch [1/1], Batch [1980/30000], Loss: 2.2559\n",
      "Epoch [1/1], Batch [1990/30000], Loss: 2.2559\n",
      "Epoch [1/1], Batch [2000/30000], Loss: 2.2920\n",
      "Epoch [1/1], Batch [2010/30000], Loss: 2.0176\n",
      "Epoch [1/1], Batch [2020/30000], Loss: 2.3770\n",
      "Epoch [1/1], Batch [2030/30000], Loss: 2.2432\n",
      "Epoch [1/1], Batch [2040/30000], Loss: 2.5723\n",
      "Epoch [1/1], Batch [2050/30000], Loss: 2.1025\n",
      "Epoch [1/1], Batch [2060/30000], Loss: 2.4004\n",
      "Epoch [1/1], Batch [2070/30000], Loss: 2.2754\n",
      "Epoch [1/1], Batch [2080/30000], Loss: 2.2666\n",
      "Epoch [1/1], Batch [2090/30000], Loss: 2.3477\n",
      "Epoch [1/1], Batch [2100/30000], Loss: 1.8154\n",
      "Epoch [1/1], Batch [2110/30000], Loss: 2.2373\n",
      "Epoch [1/1], Batch [2120/30000], Loss: 2.3604\n",
      "Epoch [1/1], Batch [2130/30000], Loss: 2.3281\n",
      "Epoch [1/1], Batch [2140/30000], Loss: 1.9644\n",
      "Epoch [1/1], Batch [2150/30000], Loss: 2.2803\n",
      "Epoch [1/1], Batch [2160/30000], Loss: 2.2979\n",
      "Epoch [1/1], Batch [2170/30000], Loss: 2.8799\n",
      "Epoch [1/1], Batch [2180/30000], Loss: 3.0420\n",
      "Epoch [1/1], Batch [2190/30000], Loss: 2.2651\n",
      "Epoch [1/1], Batch [2200/30000], Loss: 2.7559\n",
      "Epoch [1/1], Batch [2210/30000], Loss: 2.2988\n",
      "Epoch [1/1], Batch [2220/30000], Loss: 2.4131\n",
      "Epoch [1/1], Batch [2230/30000], Loss: 2.5684\n",
      "Epoch [1/1], Batch [2240/30000], Loss: 2.4902\n",
      "Epoch [1/1], Batch [2250/30000], Loss: 2.2100\n",
      "Epoch [1/1], Batch [2260/30000], Loss: 2.5371\n",
      "Epoch [1/1], Batch [2270/30000], Loss: 2.2803\n",
      "Epoch [1/1], Batch [2280/30000], Loss: 2.3916\n",
      "Epoch [1/1], Batch [2290/30000], Loss: 2.4795\n",
      "Epoch [1/1], Batch [2300/30000], Loss: 2.4463\n",
      "Epoch [1/1], Batch [2310/30000], Loss: 2.1240\n",
      "Epoch [1/1], Batch [2320/30000], Loss: 2.1543\n",
      "Epoch [1/1], Batch [2330/30000], Loss: 2.2520\n",
      "Epoch [1/1], Batch [2340/30000], Loss: 2.5527\n",
      "Epoch [1/1], Batch [2350/30000], Loss: 2.1279\n",
      "Epoch [1/1], Batch [2360/30000], Loss: 2.3896\n",
      "Epoch [1/1], Batch [2370/30000], Loss: 2.7100\n",
      "Epoch [1/1], Batch [2380/30000], Loss: 2.2480\n",
      "Epoch [1/1], Batch [2390/30000], Loss: 2.3086\n",
      "Epoch [1/1], Batch [2400/30000], Loss: 2.1895\n",
      "Epoch [1/1], Batch [2410/30000], Loss: 2.4092\n",
      "Epoch [1/1], Batch [2420/30000], Loss: 2.3145\n",
      "Epoch [1/1], Batch [2430/30000], Loss: 2.1445\n",
      "Epoch [1/1], Batch [2440/30000], Loss: 2.3213\n",
      "Epoch [1/1], Batch [2450/30000], Loss: 2.2744\n",
      "Epoch [1/1], Batch [2460/30000], Loss: 2.1621\n",
      "Epoch [1/1], Batch [2470/30000], Loss: 2.3379\n",
      "Epoch [1/1], Batch [2480/30000], Loss: 2.4189\n",
      "Epoch [1/1], Batch [2490/30000], Loss: 2.2812\n",
      "Epoch [1/1], Batch [2500/30000], Loss: 2.3701\n",
      "Epoch [1/1], Batch [2510/30000], Loss: 2.2266\n",
      "Epoch [1/1], Batch [2520/30000], Loss: 2.2422\n",
      "Epoch [1/1], Batch [2530/30000], Loss: 2.5635\n",
      "Epoch [1/1], Batch [2540/30000], Loss: 2.3535\n",
      "Epoch [1/1], Batch [2550/30000], Loss: 2.4873\n",
      "Epoch [1/1], Batch [2560/30000], Loss: 2.5566\n",
      "Epoch [1/1], Batch [2570/30000], Loss: 2.5400\n",
      "Epoch [1/1], Batch [2580/30000], Loss: 2.2930\n",
      "Epoch [1/1], Batch [2590/30000], Loss: 2.3506\n",
      "Epoch [1/1], Batch [2600/30000], Loss: 2.2969\n",
      "Epoch [1/1], Batch [2610/30000], Loss: 2.1387\n",
      "Epoch [1/1], Batch [2620/30000], Loss: 2.2949\n",
      "Epoch [1/1], Batch [2630/30000], Loss: 2.2676\n",
      "Epoch [1/1], Batch [2640/30000], Loss: 2.3066\n",
      "Epoch [1/1], Batch [2650/30000], Loss: 2.5020\n",
      "Epoch [1/1], Batch [2660/30000], Loss: 2.2012\n",
      "Epoch [1/1], Batch [2670/30000], Loss: 2.4277\n",
      "Epoch [1/1], Batch [2680/30000], Loss: 2.4414\n",
      "Epoch [1/1], Batch [2690/30000], Loss: 2.3955\n",
      "Epoch [1/1], Batch [2700/30000], Loss: 2.1963\n",
      "Epoch [1/1], Batch [2710/30000], Loss: 2.3730\n",
      "Epoch [1/1], Batch [2720/30000], Loss: 2.2871\n",
      "Epoch [1/1], Batch [2730/30000], Loss: 2.3096\n",
      "Epoch [1/1], Batch [2740/30000], Loss: 2.3066\n",
      "Epoch [1/1], Batch [2750/30000], Loss: 2.4229\n",
      "Epoch [1/1], Batch [2760/30000], Loss: 1.9424\n",
      "Epoch [1/1], Batch [2770/30000], Loss: 2.2666\n",
      "Epoch [1/1], Batch [2780/30000], Loss: 2.0938\n",
      "Epoch [1/1], Batch [2790/30000], Loss: 2.2998\n",
      "Epoch [1/1], Batch [2800/30000], Loss: 2.2715\n",
      "Epoch [1/1], Batch [2810/30000], Loss: 3.0820\n",
      "Epoch [1/1], Batch [2820/30000], Loss: 2.3633\n",
      "Epoch [1/1], Batch [2830/30000], Loss: 2.2695\n",
      "Epoch [1/1], Batch [2840/30000], Loss: 2.2637\n",
      "Epoch [1/1], Batch [2850/30000], Loss: 2.4883\n",
      "Epoch [1/1], Batch [2860/30000], Loss: 2.0898\n",
      "Epoch [1/1], Batch [2870/30000], Loss: 2.3711\n",
      "Epoch [1/1], Batch [2880/30000], Loss: 1.8838\n",
      "Epoch [1/1], Batch [2890/30000], Loss: 2.3496\n",
      "Epoch [1/1], Batch [2900/30000], Loss: 1.9058\n",
      "Epoch [1/1], Batch [2910/30000], Loss: 2.3652\n",
      "Epoch [1/1], Batch [2920/30000], Loss: 2.5781\n",
      "Epoch [1/1], Batch [2930/30000], Loss: 2.3540\n",
      "Epoch [1/1], Batch [2940/30000], Loss: 2.4805\n",
      "Epoch [1/1], Batch [2950/30000], Loss: 2.4004\n",
      "Epoch [1/1], Batch [2960/30000], Loss: 2.4209\n",
      "Epoch [1/1], Batch [2970/30000], Loss: 2.4229\n",
      "Epoch [1/1], Batch [2980/30000], Loss: 2.2969\n",
      "Epoch [1/1], Batch [2990/30000], Loss: 2.4180\n",
      "Epoch [1/1], Batch [3000/30000], Loss: 2.2891\n",
      "Epoch [1/1], Batch [3010/30000], Loss: 2.2422\n",
      "Epoch [1/1], Batch [3020/30000], Loss: 2.4639\n",
      "Epoch [1/1], Batch [3030/30000], Loss: 2.3672\n",
      "Epoch [1/1], Batch [3040/30000], Loss: 2.2422\n",
      "Epoch [1/1], Batch [3050/30000], Loss: 2.3467\n",
      "Epoch [1/1], Batch [3060/30000], Loss: 2.2490\n",
      "Epoch [1/1], Batch [3070/30000], Loss: 2.4082\n",
      "Epoch [1/1], Batch [3080/30000], Loss: 2.1367\n",
      "Epoch [1/1], Batch [3090/30000], Loss: 2.1729\n",
      "Epoch [1/1], Batch [3100/30000], Loss: 2.3262\n",
      "Epoch [1/1], Batch [3110/30000], Loss: 2.3545\n",
      "Epoch [1/1], Batch [3120/30000], Loss: 2.3174\n",
      "Epoch [1/1], Batch [3130/30000], Loss: 2.2461\n",
      "Epoch [1/1], Batch [3140/30000], Loss: 2.4590\n",
      "Epoch [1/1], Batch [3150/30000], Loss: 2.3564\n",
      "Epoch [1/1], Batch [3160/30000], Loss: 1.5889\n",
      "Epoch [1/1], Batch [3170/30000], Loss: 2.2383\n",
      "Epoch [1/1], Batch [3180/30000], Loss: 2.1108\n",
      "Epoch [1/1], Batch [3190/30000], Loss: 2.3086\n",
      "Epoch [1/1], Batch [3200/30000], Loss: 2.2305\n",
      "Epoch [1/1], Batch [3210/30000], Loss: 2.4883\n",
      "Epoch [1/1], Batch [3220/30000], Loss: 2.4482\n",
      "Epoch [1/1], Batch [3230/30000], Loss: 2.2363\n",
      "Epoch [1/1], Batch [3240/30000], Loss: 2.3877\n",
      "Epoch [1/1], Batch [3250/30000], Loss: 2.3506\n",
      "Epoch [1/1], Batch [3260/30000], Loss: 2.3379\n",
      "Epoch [1/1], Batch [3270/30000], Loss: 2.3076\n",
      "Epoch [1/1], Batch [3280/30000], Loss: 2.2471\n",
      "Epoch [1/1], Batch [3290/30000], Loss: 2.3447\n",
      "Epoch [1/1], Batch [3300/30000], Loss: 2.2461\n",
      "Epoch [1/1], Batch [3310/30000], Loss: 2.3311\n",
      "Epoch [1/1], Batch [3320/30000], Loss: 2.3857\n",
      "Epoch [1/1], Batch [3330/30000], Loss: 2.2476\n",
      "Epoch [1/1], Batch [3340/30000], Loss: 2.1611\n",
      "Epoch [1/1], Batch [3350/30000], Loss: 2.3828\n",
      "Epoch [1/1], Batch [3360/30000], Loss: 2.2148\n",
      "Epoch [1/1], Batch [3370/30000], Loss: 2.2139\n",
      "Epoch [1/1], Batch [3380/30000], Loss: 2.1621\n",
      "Epoch [1/1], Batch [3390/30000], Loss: 2.2754\n",
      "Epoch [1/1], Batch [3400/30000], Loss: 2.3115\n",
      "Epoch [1/1], Batch [3410/30000], Loss: 2.1304\n",
      "Epoch [1/1], Batch [3420/30000], Loss: 2.3779\n",
      "Epoch [1/1], Batch [3430/30000], Loss: 2.2236\n",
      "Epoch [1/1], Batch [3440/30000], Loss: 2.1992\n",
      "Epoch [1/1], Batch [3450/30000], Loss: 2.3779\n",
      "Epoch [1/1], Batch [3460/30000], Loss: 2.2500\n",
      "Epoch [1/1], Batch [3470/30000], Loss: 2.2148\n",
      "Epoch [1/1], Batch [3480/30000], Loss: 2.3154\n",
      "Epoch [1/1], Batch [3490/30000], Loss: 2.1885\n",
      "Epoch [1/1], Batch [3500/30000], Loss: 2.1387\n",
      "Epoch [1/1], Batch [3510/30000], Loss: 2.3750\n",
      "Epoch [1/1], Batch [3520/30000], Loss: 2.3232\n",
      "Epoch [1/1], Batch [3530/30000], Loss: 2.5352\n",
      "Epoch [1/1], Batch [3540/30000], Loss: 2.1445\n",
      "Epoch [1/1], Batch [3550/30000], Loss: 2.3320\n",
      "Epoch [1/1], Batch [3560/30000], Loss: 2.1133\n",
      "Epoch [1/1], Batch [3570/30000], Loss: 2.1611\n",
      "Epoch [1/1], Batch [3580/30000], Loss: 2.2935\n",
      "Epoch [1/1], Batch [3590/30000], Loss: 2.9219\n",
      "Epoch [1/1], Batch [3600/30000], Loss: 2.3711\n",
      "Epoch [1/1], Batch [3610/30000], Loss: 2.4971\n",
      "Epoch [1/1], Batch [3620/30000], Loss: 2.1299\n",
      "Epoch [1/1], Batch [3630/30000], Loss: 2.1191\n",
      "Epoch [1/1], Batch [3640/30000], Loss: 2.4346\n",
      "Epoch [1/1], Batch [3650/30000], Loss: 2.3311\n",
      "Epoch [1/1], Batch [3660/30000], Loss: 2.4590\n",
      "Epoch [1/1], Batch [3670/30000], Loss: 2.3320\n",
      "Epoch [1/1], Batch [3680/30000], Loss: 2.3818\n",
      "Epoch [1/1], Batch [3690/30000], Loss: 2.2559\n",
      "Epoch [1/1], Batch [3700/30000], Loss: 2.1738\n",
      "Epoch [1/1], Batch [3710/30000], Loss: 2.2930\n",
      "Epoch [1/1], Batch [3720/30000], Loss: 2.4092\n",
      "Epoch [1/1], Batch [3730/30000], Loss: 2.2754\n",
      "Epoch [1/1], Batch [3740/30000], Loss: 2.3809\n",
      "Epoch [1/1], Batch [3750/30000], Loss: 2.2744\n",
      "Epoch [1/1], Batch [3760/30000], Loss: 2.3369\n",
      "Epoch [1/1], Batch [3770/30000], Loss: 2.3477\n",
      "Epoch [1/1], Batch [3780/30000], Loss: 2.2539\n",
      "Epoch [1/1], Batch [3790/30000], Loss: 2.3740\n",
      "Epoch [1/1], Batch [3800/30000], Loss: 2.3359\n",
      "Epoch [1/1], Batch [3810/30000], Loss: 2.4297\n",
      "Epoch [1/1], Batch [3820/30000], Loss: 2.2134\n",
      "Epoch [1/1], Batch [3830/30000], Loss: 2.5225\n",
      "Epoch [1/1], Batch [3840/30000], Loss: 2.2617\n",
      "Epoch [1/1], Batch [3850/30000], Loss: 2.4443\n",
      "Epoch [1/1], Batch [3860/30000], Loss: 2.3174\n",
      "Epoch [1/1], Batch [3870/30000], Loss: 2.2021\n",
      "Epoch [1/1], Batch [3880/30000], Loss: 2.3330\n",
      "Epoch [1/1], Batch [3890/30000], Loss: 2.5215\n",
      "Epoch [1/1], Batch [3900/30000], Loss: 2.3809\n",
      "Epoch [1/1], Batch [3910/30000], Loss: 2.2822\n",
      "Epoch [1/1], Batch [3920/30000], Loss: 2.2568\n",
      "Epoch [1/1], Batch [3930/30000], Loss: 2.3486\n",
      "Epoch [1/1], Batch [3940/30000], Loss: 2.2705\n",
      "Epoch [1/1], Batch [3950/30000], Loss: 2.3330\n",
      "Epoch [1/1], Batch [3960/30000], Loss: 2.1401\n",
      "Epoch [1/1], Batch [3970/30000], Loss: 2.3525\n",
      "Epoch [1/1], Batch [3980/30000], Loss: 2.1680\n",
      "Epoch [1/1], Batch [3990/30000], Loss: 2.2666\n",
      "Epoch [1/1], Batch [4000/30000], Loss: 2.3223\n",
      "Epoch [1/1], Batch [4010/30000], Loss: 2.3984\n",
      "Epoch [1/1], Batch [4020/30000], Loss: 2.5059\n",
      "Epoch [1/1], Batch [4030/30000], Loss: 2.6211\n",
      "Epoch [1/1], Batch [4040/30000], Loss: 2.4355\n",
      "Epoch [1/1], Batch [4050/30000], Loss: 2.2803\n",
      "Epoch [1/1], Batch [4060/30000], Loss: 2.3320\n",
      "Epoch [1/1], Batch [4070/30000], Loss: 2.3223\n",
      "Epoch [1/1], Batch [4080/30000], Loss: 2.2490\n",
      "Epoch [1/1], Batch [4090/30000], Loss: 2.5317\n",
      "Epoch [1/1], Batch [4100/30000], Loss: 1.8667\n",
      "Epoch [1/1], Batch [4110/30000], Loss: 2.2412\n",
      "Epoch [1/1], Batch [4120/30000], Loss: 2.3174\n",
      "Epoch [1/1], Batch [4130/30000], Loss: 2.4131\n",
      "Epoch [1/1], Batch [4140/30000], Loss: 2.3701\n",
      "Epoch [1/1], Batch [4150/30000], Loss: 2.1123\n",
      "Epoch [1/1], Batch [4160/30000], Loss: 2.1846\n",
      "Epoch [1/1], Batch [4170/30000], Loss: 2.4111\n",
      "Epoch [1/1], Batch [4180/30000], Loss: 2.3242\n",
      "Epoch [1/1], Batch [4190/30000], Loss: 2.3340\n",
      "Epoch [1/1], Batch [4200/30000], Loss: 2.3076\n",
      "Epoch [1/1], Batch [4210/30000], Loss: 2.3887\n",
      "Epoch [1/1], Batch [4220/30000], Loss: 2.2324\n",
      "Epoch [1/1], Batch [4230/30000], Loss: 2.3418\n",
      "Epoch [1/1], Batch [4240/30000], Loss: 2.1641\n",
      "Epoch [1/1], Batch [4250/30000], Loss: 2.4756\n",
      "Epoch [1/1], Batch [4260/30000], Loss: 2.2271\n",
      "Epoch [1/1], Batch [4270/30000], Loss: 2.2109\n",
      "Epoch [1/1], Batch [4280/30000], Loss: 2.1240\n",
      "Epoch [1/1], Batch [4290/30000], Loss: 2.4014\n",
      "Epoch [1/1], Batch [4300/30000], Loss: 2.3057\n",
      "Epoch [1/1], Batch [4310/30000], Loss: 2.3779\n",
      "Epoch [1/1], Batch [4320/30000], Loss: 2.3682\n",
      "Epoch [1/1], Batch [4330/30000], Loss: 2.3506\n",
      "Epoch [1/1], Batch [4340/30000], Loss: 2.5762\n",
      "Epoch [1/1], Batch [4350/30000], Loss: 2.6592\n",
      "Epoch [1/1], Batch [4360/30000], Loss: 2.0879\n",
      "Epoch [1/1], Batch [4370/30000], Loss: 2.2881\n",
      "Epoch [1/1], Batch [4380/30000], Loss: 2.2832\n",
      "Epoch [1/1], Batch [4390/30000], Loss: 2.3604\n",
      "Epoch [1/1], Batch [4400/30000], Loss: 2.3516\n",
      "Epoch [1/1], Batch [4410/30000], Loss: 2.1680\n",
      "Epoch [1/1], Batch [4420/30000], Loss: 2.4424\n",
      "Epoch [1/1], Batch [4430/30000], Loss: 2.4883\n",
      "Epoch [1/1], Batch [4440/30000], Loss: 2.4502\n",
      "Epoch [1/1], Batch [4450/30000], Loss: 2.4072\n",
      "Epoch [1/1], Batch [4460/30000], Loss: 2.0347\n",
      "Epoch [1/1], Batch [4470/30000], Loss: 2.5684\n",
      "Epoch [1/1], Batch [4480/30000], Loss: 1.3146\n",
      "Epoch [1/1], Batch [4490/30000], Loss: 2.1543\n",
      "Epoch [1/1], Batch [4500/30000], Loss: 2.1660\n",
      "Epoch [1/1], Batch [4510/30000], Loss: 2.2861\n",
      "Epoch [1/1], Batch [4520/30000], Loss: 2.5840\n",
      "Epoch [1/1], Batch [4530/30000], Loss: 2.2852\n",
      "Epoch [1/1], Batch [4540/30000], Loss: 2.8496\n",
      "Epoch [1/1], Batch [4550/30000], Loss: 2.3789\n",
      "Epoch [1/1], Batch [4560/30000], Loss: 2.3232\n",
      "Epoch [1/1], Batch [4570/30000], Loss: 2.3477\n",
      "Epoch [1/1], Batch [4580/30000], Loss: 2.6709\n",
      "Epoch [1/1], Batch [4590/30000], Loss: 2.2900\n",
      "Epoch [1/1], Batch [4600/30000], Loss: 2.2793\n",
      "Epoch [1/1], Batch [4610/30000], Loss: 2.4980\n",
      "Epoch [1/1], Batch [4620/30000], Loss: 1.7764\n",
      "Epoch [1/1], Batch [4630/30000], Loss: 2.3340\n",
      "Epoch [1/1], Batch [4640/30000], Loss: 2.0918\n",
      "Epoch [1/1], Batch [4650/30000], Loss: 1.4414\n",
      "Epoch [1/1], Batch [4660/30000], Loss: 2.3379\n",
      "Epoch [1/1], Batch [4670/30000], Loss: 2.0400\n",
      "Epoch [1/1], Batch [4680/30000], Loss: 2.4570\n",
      "Epoch [1/1], Batch [4690/30000], Loss: 2.4043\n",
      "Epoch [1/1], Batch [4700/30000], Loss: 1.9224\n",
      "Epoch [1/1], Batch [4710/30000], Loss: 2.2939\n",
      "Epoch [1/1], Batch [4720/30000], Loss: 2.4141\n",
      "Epoch [1/1], Batch [4730/30000], Loss: 2.4004\n",
      "Epoch [1/1], Batch [4740/30000], Loss: 2.4883\n",
      "Epoch [1/1], Batch [4750/30000], Loss: 2.3066\n",
      "Epoch [1/1], Batch [4760/30000], Loss: 1.9858\n",
      "Epoch [1/1], Batch [4770/30000], Loss: 2.3330\n",
      "Epoch [1/1], Batch [4780/30000], Loss: 2.0186\n",
      "Epoch [1/1], Batch [4790/30000], Loss: 2.0869\n",
      "Epoch [1/1], Batch [4800/30000], Loss: 2.2197\n",
      "Epoch [1/1], Batch [4810/30000], Loss: 2.4893\n",
      "Epoch [1/1], Batch [4820/30000], Loss: 2.2686\n",
      "Epoch [1/1], Batch [4830/30000], Loss: 2.2461\n",
      "Epoch [1/1], Batch [4840/30000], Loss: 2.3662\n",
      "Epoch [1/1], Batch [4850/30000], Loss: 2.2930\n",
      "Epoch [1/1], Batch [4860/30000], Loss: 2.3643\n",
      "Epoch [1/1], Batch [4870/30000], Loss: 2.2744\n",
      "Epoch [1/1], Batch [4880/30000], Loss: 2.2764\n",
      "Epoch [1/1], Batch [4890/30000], Loss: 2.2598\n",
      "Epoch [1/1], Batch [4900/30000], Loss: 2.3838\n",
      "Epoch [1/1], Batch [4910/30000], Loss: 2.2578\n",
      "Epoch [1/1], Batch [4920/30000], Loss: 2.3066\n",
      "Epoch [1/1], Batch [4930/30000], Loss: 2.2734\n",
      "Epoch [1/1], Batch [4940/30000], Loss: 2.3857\n",
      "Epoch [1/1], Batch [4950/30000], Loss: 2.2412\n",
      "Epoch [1/1], Batch [4960/30000], Loss: 2.1357\n",
      "Epoch [1/1], Batch [4970/30000], Loss: 2.5352\n",
      "Epoch [1/1], Batch [4980/30000], Loss: 2.2666\n",
      "Epoch [1/1], Batch [4990/30000], Loss: 2.3584\n",
      "Epoch [1/1], Batch [5000/30000], Loss: 2.2803\n",
      "Epoch [1/1], Batch [5010/30000], Loss: 2.0820\n",
      "Epoch [1/1], Batch [5020/30000], Loss: 2.3496\n",
      "Epoch [1/1], Batch [5030/30000], Loss: 2.3389\n",
      "Epoch [1/1], Batch [5040/30000], Loss: 2.1309\n",
      "Epoch [1/1], Batch [5050/30000], Loss: 2.2754\n",
      "Epoch [1/1], Batch [5060/30000], Loss: 2.3486\n",
      "Epoch [1/1], Batch [5070/30000], Loss: 2.2979\n",
      "Epoch [1/1], Batch [5080/30000], Loss: 2.3125\n",
      "Epoch [1/1], Batch [5090/30000], Loss: 2.3672\n",
      "Epoch [1/1], Batch [5100/30000], Loss: 2.3379\n",
      "Epoch [1/1], Batch [5110/30000], Loss: 2.4990\n",
      "Epoch [1/1], Batch [5120/30000], Loss: 2.1816\n",
      "Epoch [1/1], Batch [5130/30000], Loss: 2.1709\n",
      "Epoch [1/1], Batch [5140/30000], Loss: 2.1484\n",
      "Epoch [1/1], Batch [5150/30000], Loss: 2.2100\n",
      "Epoch [1/1], Batch [5160/30000], Loss: 2.4209\n",
      "Epoch [1/1], Batch [5170/30000], Loss: 2.3672\n",
      "Epoch [1/1], Batch [5180/30000], Loss: 2.2168\n",
      "Epoch [1/1], Batch [5190/30000], Loss: 2.2256\n",
      "Epoch [1/1], Batch [5200/30000], Loss: 2.3672\n",
      "Epoch [1/1], Batch [5210/30000], Loss: 2.5234\n",
      "Epoch [1/1], Batch [5220/30000], Loss: 2.1436\n",
      "Epoch [1/1], Batch [5230/30000], Loss: 2.4541\n",
      "Epoch [1/1], Batch [5240/30000], Loss: 2.1802\n",
      "Epoch [1/1], Batch [5250/30000], Loss: 2.3447\n",
      "Epoch [1/1], Batch [5260/30000], Loss: 2.2480\n",
      "Epoch [1/1], Batch [5270/30000], Loss: 2.3125\n",
      "Epoch [1/1], Batch [5280/30000], Loss: 2.4141\n",
      "Epoch [1/1], Batch [5290/30000], Loss: 2.4336\n",
      "Epoch [1/1], Batch [5300/30000], Loss: 2.4023\n",
      "Epoch [1/1], Batch [5310/30000], Loss: 2.4014\n",
      "Epoch [1/1], Batch [5320/30000], Loss: 2.3418\n",
      "Epoch [1/1], Batch [5330/30000], Loss: 2.3105\n",
      "Epoch [1/1], Batch [5340/30000], Loss: 2.2998\n",
      "Epoch [1/1], Batch [5350/30000], Loss: 2.3857\n",
      "Epoch [1/1], Batch [5360/30000], Loss: 2.2646\n",
      "Epoch [1/1], Batch [5370/30000], Loss: 2.2002\n",
      "Epoch [1/1], Batch [5380/30000], Loss: 2.2041\n",
      "Epoch [1/1], Batch [5390/30000], Loss: 2.1348\n",
      "Epoch [1/1], Batch [5400/30000], Loss: 2.5410\n",
      "Epoch [1/1], Batch [5410/30000], Loss: 2.5811\n",
      "Epoch [1/1], Batch [5420/30000], Loss: 2.1431\n",
      "Epoch [1/1], Batch [5430/30000], Loss: 2.1846\n",
      "Epoch [1/1], Batch [5440/30000], Loss: 2.2158\n",
      "Epoch [1/1], Batch [5450/30000], Loss: 2.3789\n",
      "Epoch [1/1], Batch [5460/30000], Loss: 2.2520\n",
      "Epoch [1/1], Batch [5470/30000], Loss: 2.2852\n",
      "Epoch [1/1], Batch [5480/30000], Loss: 2.3721\n",
      "Epoch [1/1], Batch [5490/30000], Loss: 2.2598\n",
      "Epoch [1/1], Batch [5500/30000], Loss: 2.1934\n",
      "Epoch [1/1], Batch [5510/30000], Loss: 2.5142\n",
      "Epoch [1/1], Batch [5520/30000], Loss: 2.1694\n",
      "Epoch [1/1], Batch [5530/30000], Loss: 2.2266\n",
      "Epoch [1/1], Batch [5540/30000], Loss: 2.3887\n",
      "Epoch [1/1], Batch [5550/30000], Loss: 2.2549\n",
      "Epoch [1/1], Batch [5560/30000], Loss: 2.3037\n",
      "Epoch [1/1], Batch [5570/30000], Loss: 2.4199\n",
      "Epoch [1/1], Batch [5580/30000], Loss: 2.2549\n",
      "Epoch [1/1], Batch [5590/30000], Loss: 2.2432\n",
      "Epoch [1/1], Batch [5600/30000], Loss: 2.0630\n",
      "Epoch [1/1], Batch [5610/30000], Loss: 2.1611\n",
      "Epoch [1/1], Batch [5620/30000], Loss: 2.0586\n",
      "Epoch [1/1], Batch [5630/30000], Loss: 2.3037\n",
      "Epoch [1/1], Batch [5640/30000], Loss: 2.0635\n",
      "Epoch [1/1], Batch [5650/30000], Loss: 2.5850\n",
      "Epoch [1/1], Batch [5660/30000], Loss: 2.4238\n",
      "Epoch [1/1], Batch [5670/30000], Loss: 2.4102\n",
      "Epoch [1/1], Batch [5680/30000], Loss: 2.2842\n",
      "Epoch [1/1], Batch [5690/30000], Loss: 2.2559\n",
      "Epoch [1/1], Batch [5700/30000], Loss: 2.0186\n",
      "Epoch [1/1], Batch [5710/30000], Loss: 2.3428\n",
      "Epoch [1/1], Batch [5720/30000], Loss: 2.2129\n",
      "Epoch [1/1], Batch [5730/30000], Loss: 2.1411\n",
      "Epoch [1/1], Batch [5740/30000], Loss: 2.5664\n",
      "Epoch [1/1], Batch [5750/30000], Loss: 2.4707\n",
      "Epoch [1/1], Batch [5760/30000], Loss: 2.3672\n",
      "Epoch [1/1], Batch [5770/30000], Loss: 2.2324\n",
      "Epoch [1/1], Batch [5780/30000], Loss: 2.2930\n",
      "Epoch [1/1], Batch [5790/30000], Loss: 2.3574\n",
      "Epoch [1/1], Batch [5800/30000], Loss: 2.2881\n",
      "Epoch [1/1], Batch [5810/30000], Loss: 2.2686\n",
      "Epoch [1/1], Batch [5820/30000], Loss: 2.3838\n",
      "Epoch [1/1], Batch [5830/30000], Loss: 2.2744\n",
      "Epoch [1/1], Batch [5840/30000], Loss: 2.2910\n",
      "Epoch [1/1], Batch [5850/30000], Loss: 2.2910\n",
      "Epoch [1/1], Batch [5860/30000], Loss: 2.3145\n",
      "Epoch [1/1], Batch [5870/30000], Loss: 2.3965\n",
      "Epoch [1/1], Batch [5880/30000], Loss: 2.2695\n",
      "Epoch [1/1], Batch [5890/30000], Loss: 2.2451\n",
      "Epoch [1/1], Batch [5900/30000], Loss: 2.2520\n",
      "Epoch [1/1], Batch [5910/30000], Loss: 2.2744\n",
      "Epoch [1/1], Batch [5920/30000], Loss: 2.3711\n",
      "Epoch [1/1], Batch [5930/30000], Loss: 2.3223\n",
      "Epoch [1/1], Batch [5940/30000], Loss: 2.4043\n",
      "Epoch [1/1], Batch [5950/30000], Loss: 2.2568\n",
      "Epoch [1/1], Batch [5960/30000], Loss: 2.2686\n",
      "Epoch [1/1], Batch [5970/30000], Loss: 2.3008\n",
      "Epoch [1/1], Batch [5980/30000], Loss: 2.2471\n",
      "Epoch [1/1], Batch [5990/30000], Loss: 2.1689\n",
      "Epoch [1/1], Batch [6000/30000], Loss: 2.4473\n",
      "Epoch [1/1], Batch [6010/30000], Loss: 2.3330\n",
      "Epoch [1/1], Batch [6020/30000], Loss: 2.3271\n",
      "Epoch [1/1], Batch [6030/30000], Loss: 2.2832\n",
      "Epoch [1/1], Batch [6040/30000], Loss: 2.2764\n",
      "Epoch [1/1], Batch [6050/30000], Loss: 2.3809\n",
      "Epoch [1/1], Batch [6060/30000], Loss: 2.3027\n",
      "Epoch [1/1], Batch [6070/30000], Loss: 2.3271\n",
      "Epoch [1/1], Batch [6080/30000], Loss: 2.4443\n",
      "Epoch [1/1], Batch [6090/30000], Loss: 2.3135\n",
      "Epoch [1/1], Batch [6100/30000], Loss: 2.2373\n",
      "Epoch [1/1], Batch [6110/30000], Loss: 2.4688\n",
      "Epoch [1/1], Batch [6120/30000], Loss: 2.3467\n",
      "Epoch [1/1], Batch [6130/30000], Loss: 2.4102\n",
      "Epoch [1/1], Batch [6140/30000], Loss: 2.2432\n",
      "Epoch [1/1], Batch [6150/30000], Loss: 2.3604\n",
      "Epoch [1/1], Batch [6160/30000], Loss: 2.3574\n",
      "Epoch [1/1], Batch [6170/30000], Loss: 2.2075\n",
      "Epoch [1/1], Batch [6180/30000], Loss: 2.4248\n",
      "Epoch [1/1], Batch [6190/30000], Loss: 2.2617\n",
      "Epoch [1/1], Batch [6200/30000], Loss: 2.2480\n",
      "Epoch [1/1], Batch [6210/30000], Loss: 2.3975\n",
      "Epoch [1/1], Batch [6220/30000], Loss: 2.3594\n",
      "Epoch [1/1], Batch [6230/30000], Loss: 2.2822\n",
      "Epoch [1/1], Batch [6240/30000], Loss: 2.2881\n",
      "Epoch [1/1], Batch [6250/30000], Loss: 2.4062\n",
      "Epoch [1/1], Batch [6260/30000], Loss: 2.4219\n",
      "Epoch [1/1], Batch [6270/30000], Loss: 2.2002\n",
      "Epoch [1/1], Batch [6280/30000], Loss: 2.3271\n",
      "Epoch [1/1], Batch [6290/30000], Loss: 2.2373\n",
      "Epoch [1/1], Batch [6300/30000], Loss: 2.3467\n",
      "Epoch [1/1], Batch [6310/30000], Loss: 2.3896\n",
      "Epoch [1/1], Batch [6320/30000], Loss: 2.2812\n",
      "Epoch [1/1], Batch [6330/30000], Loss: 2.2256\n",
      "Epoch [1/1], Batch [6340/30000], Loss: 2.3262\n",
      "Epoch [1/1], Batch [6350/30000], Loss: 2.2236\n",
      "Epoch [1/1], Batch [6360/30000], Loss: 2.2090\n",
      "Epoch [1/1], Batch [6370/30000], Loss: 2.2549\n",
      "Epoch [1/1], Batch [6380/30000], Loss: 2.3506\n",
      "Epoch [1/1], Batch [6390/30000], Loss: 2.2744\n",
      "Epoch [1/1], Batch [6400/30000], Loss: 2.0967\n",
      "Epoch [1/1], Batch [6410/30000], Loss: 2.3086\n",
      "Epoch [1/1], Batch [6420/30000], Loss: 2.1396\n",
      "Epoch [1/1], Batch [6430/30000], Loss: 2.8281\n",
      "Epoch [1/1], Batch [6440/30000], Loss: 2.1699\n",
      "Epoch [1/1], Batch [6450/30000], Loss: 2.2861\n",
      "Epoch [1/1], Batch [6460/30000], Loss: 2.2695\n",
      "Epoch [1/1], Batch [6470/30000], Loss: 2.2520\n",
      "Epoch [1/1], Batch [6480/30000], Loss: 2.3145\n",
      "Epoch [1/1], Batch [6490/30000], Loss: 2.3193\n",
      "Epoch [1/1], Batch [6500/30000], Loss: 2.1157\n",
      "Epoch [1/1], Batch [6510/30000], Loss: 2.1914\n",
      "Epoch [1/1], Batch [6520/30000], Loss: 2.4033\n",
      "Epoch [1/1], Batch [6530/30000], Loss: 2.2949\n",
      "Epoch [1/1], Batch [6540/30000], Loss: 2.2021\n",
      "Epoch [1/1], Batch [6550/30000], Loss: 2.4248\n",
      "Epoch [1/1], Batch [6560/30000], Loss: 2.3193\n",
      "Epoch [1/1], Batch [6570/30000], Loss: 2.5039\n",
      "Epoch [1/1], Batch [6580/30000], Loss: 2.3320\n",
      "Epoch [1/1], Batch [6590/30000], Loss: 2.2832\n",
      "Epoch [1/1], Batch [6600/30000], Loss: 2.3701\n",
      "Epoch [1/1], Batch [6610/30000], Loss: 2.4102\n",
      "Epoch [1/1], Batch [6620/30000], Loss: 2.3311\n",
      "Epoch [1/1], Batch [6630/30000], Loss: 2.3311\n",
      "Epoch [1/1], Batch [6640/30000], Loss: 2.2803\n",
      "Epoch [1/1], Batch [6650/30000], Loss: 2.4502\n",
      "Epoch [1/1], Batch [6660/30000], Loss: 2.2617\n",
      "Epoch [1/1], Batch [6670/30000], Loss: 2.3291\n",
      "Epoch [1/1], Batch [6680/30000], Loss: 2.2354\n",
      "Epoch [1/1], Batch [6690/30000], Loss: 2.3066\n",
      "Epoch [1/1], Batch [6700/30000], Loss: 2.2490\n",
      "Epoch [1/1], Batch [6710/30000], Loss: 2.2627\n",
      "Epoch [1/1], Batch [6720/30000], Loss: 2.4336\n",
      "Epoch [1/1], Batch [6730/30000], Loss: 2.4375\n",
      "Epoch [1/1], Batch [6740/30000], Loss: 2.2383\n",
      "Epoch [1/1], Batch [6750/30000], Loss: 2.2090\n",
      "Epoch [1/1], Batch [6760/30000], Loss: 2.3643\n",
      "Epoch [1/1], Batch [6770/30000], Loss: 2.7363\n",
      "Epoch [1/1], Batch [6780/30000], Loss: 2.6191\n",
      "Epoch [1/1], Batch [6790/30000], Loss: 2.2715\n",
      "Epoch [1/1], Batch [6800/30000], Loss: 2.3623\n",
      "Epoch [1/1], Batch [6810/30000], Loss: 2.6709\n",
      "Epoch [1/1], Batch [6820/30000], Loss: 2.1992\n",
      "Epoch [1/1], Batch [6830/30000], Loss: 2.2734\n",
      "Epoch [1/1], Batch [6840/30000], Loss: 2.2471\n",
      "Epoch [1/1], Batch [6850/30000], Loss: 2.1953\n",
      "Epoch [1/1], Batch [6860/30000], Loss: 2.0967\n",
      "Epoch [1/1], Batch [6870/30000], Loss: 2.2256\n",
      "Epoch [1/1], Batch [6880/30000], Loss: 2.5742\n",
      "Epoch [1/1], Batch [6890/30000], Loss: 2.1230\n",
      "Epoch [1/1], Batch [6900/30000], Loss: 2.2705\n",
      "Epoch [1/1], Batch [6910/30000], Loss: 2.1377\n",
      "Epoch [1/1], Batch [6920/30000], Loss: 2.3994\n",
      "Epoch [1/1], Batch [6930/30000], Loss: 2.4092\n",
      "Epoch [1/1], Batch [6940/30000], Loss: 2.5938\n",
      "Epoch [1/1], Batch [6950/30000], Loss: 2.2363\n",
      "Epoch [1/1], Batch [6960/30000], Loss: 2.3965\n",
      "Epoch [1/1], Batch [6970/30000], Loss: 2.3135\n",
      "Epoch [1/1], Batch [6980/30000], Loss: 2.4180\n",
      "Epoch [1/1], Batch [6990/30000], Loss: 2.1758\n",
      "Epoch [1/1], Batch [7000/30000], Loss: 2.2217\n",
      "Epoch [1/1], Batch [7010/30000], Loss: 2.2002\n",
      "Epoch [1/1], Batch [7020/30000], Loss: 2.1924\n",
      "Epoch [1/1], Batch [7030/30000], Loss: 2.3975\n",
      "Epoch [1/1], Batch [7040/30000], Loss: 2.2891\n",
      "Epoch [1/1], Batch [7050/30000], Loss: 2.2422\n",
      "Epoch [1/1], Batch [7060/30000], Loss: 2.2959\n",
      "Epoch [1/1], Batch [7070/30000], Loss: 2.3330\n",
      "Epoch [1/1], Batch [7080/30000], Loss: 2.2695\n",
      "Epoch [1/1], Batch [7090/30000], Loss: 2.3672\n",
      "Epoch [1/1], Batch [7100/30000], Loss: 2.0469\n",
      "Epoch [1/1], Batch [7110/30000], Loss: 2.3037\n",
      "Epoch [1/1], Batch [7120/30000], Loss: 2.2598\n",
      "Epoch [1/1], Batch [7130/30000], Loss: 2.3438\n",
      "Epoch [1/1], Batch [7140/30000], Loss: 2.3574\n",
      "Epoch [1/1], Batch [7150/30000], Loss: 2.0537\n",
      "Epoch [1/1], Batch [7160/30000], Loss: 2.1719\n",
      "Epoch [1/1], Batch [7170/30000], Loss: 1.9873\n",
      "Epoch [1/1], Batch [7180/30000], Loss: 2.2734\n",
      "Epoch [1/1], Batch [7190/30000], Loss: 2.3184\n",
      "Epoch [1/1], Batch [7200/30000], Loss: 2.2939\n",
      "Epoch [1/1], Batch [7210/30000], Loss: 2.2979\n",
      "Epoch [1/1], Batch [7220/30000], Loss: 2.1665\n",
      "Epoch [1/1], Batch [7230/30000], Loss: 2.6045\n",
      "Epoch [1/1], Batch [7240/30000], Loss: 2.1455\n",
      "Epoch [1/1], Batch [7250/30000], Loss: 2.3945\n",
      "Epoch [1/1], Batch [7260/30000], Loss: 2.1855\n",
      "Epoch [1/1], Batch [7270/30000], Loss: 2.1748\n",
      "Epoch [1/1], Batch [7280/30000], Loss: 2.3311\n",
      "Epoch [1/1], Batch [7290/30000], Loss: 2.2412\n",
      "Epoch [1/1], Batch [7300/30000], Loss: 2.3662\n",
      "Epoch [1/1], Batch [7310/30000], Loss: 2.4795\n",
      "Epoch [1/1], Batch [7320/30000], Loss: 2.3125\n",
      "Epoch [1/1], Batch [7330/30000], Loss: 2.1875\n",
      "Epoch [1/1], Batch [7340/30000], Loss: 2.3936\n",
      "Epoch [1/1], Batch [7350/30000], Loss: 2.3057\n",
      "Epoch [1/1], Batch [7360/30000], Loss: 2.2451\n",
      "Epoch [1/1], Batch [7370/30000], Loss: 2.0303\n",
      "Epoch [1/1], Batch [7380/30000], Loss: 2.2705\n",
      "Epoch [1/1], Batch [7390/30000], Loss: 2.4404\n",
      "Epoch [1/1], Batch [7400/30000], Loss: 2.2363\n",
      "Epoch [1/1], Batch [7410/30000], Loss: 2.1553\n",
      "Epoch [1/1], Batch [7420/30000], Loss: 2.3057\n",
      "Epoch [1/1], Batch [7430/30000], Loss: 1.8984\n",
      "Epoch [1/1], Batch [7440/30000], Loss: 2.1455\n",
      "Epoch [1/1], Batch [7450/30000], Loss: 2.3398\n",
      "Epoch [1/1], Batch [7460/30000], Loss: 2.2900\n",
      "Epoch [1/1], Batch [7470/30000], Loss: 2.4053\n",
      "Epoch [1/1], Batch [7480/30000], Loss: 2.3906\n",
      "Epoch [1/1], Batch [7490/30000], Loss: 2.4609\n",
      "Epoch [1/1], Batch [7500/30000], Loss: 2.5205\n",
      "Epoch [1/1], Batch [7510/30000], Loss: 2.4785\n",
      "Epoch [1/1], Batch [7520/30000], Loss: 2.4160\n",
      "Epoch [1/1], Batch [7530/30000], Loss: 2.2998\n",
      "Epoch [1/1], Batch [7540/30000], Loss: 2.2344\n",
      "Epoch [1/1], Batch [7550/30000], Loss: 2.3896\n",
      "Epoch [1/1], Batch [7560/30000], Loss: 2.2373\n",
      "Epoch [1/1], Batch [7570/30000], Loss: 2.3662\n",
      "Epoch [1/1], Batch [7580/30000], Loss: 2.1777\n",
      "Epoch [1/1], Batch [7590/30000], Loss: 2.3633\n",
      "Epoch [1/1], Batch [7600/30000], Loss: 2.2461\n",
      "Epoch [1/1], Batch [7610/30000], Loss: 2.4287\n",
      "Epoch [1/1], Batch [7620/30000], Loss: 2.3105\n",
      "Epoch [1/1], Batch [7630/30000], Loss: 2.3770\n",
      "Epoch [1/1], Batch [7640/30000], Loss: 2.3740\n",
      "Epoch [1/1], Batch [7650/30000], Loss: 2.3818\n",
      "Epoch [1/1], Batch [7660/30000], Loss: 2.1729\n",
      "Epoch [1/1], Batch [7670/30000], Loss: 2.2783\n",
      "Epoch [1/1], Batch [7680/30000], Loss: 2.3418\n",
      "Epoch [1/1], Batch [7690/30000], Loss: 2.3770\n",
      "Epoch [1/1], Batch [7700/30000], Loss: 2.5186\n",
      "Epoch [1/1], Batch [7710/30000], Loss: 2.1201\n",
      "Epoch [1/1], Batch [7720/30000], Loss: 2.3115\n",
      "Epoch [1/1], Batch [7730/30000], Loss: 2.2100\n",
      "Epoch [1/1], Batch [7740/30000], Loss: 2.3809\n",
      "Epoch [1/1], Batch [7750/30000], Loss: 2.4424\n",
      "Epoch [1/1], Batch [7760/30000], Loss: 2.4707\n",
      "Epoch [1/1], Batch [7770/30000], Loss: 1.6003\n",
      "Epoch [1/1], Batch [7780/30000], Loss: 2.3711\n",
      "Epoch [1/1], Batch [7790/30000], Loss: 2.4199\n",
      "Epoch [1/1], Batch [7800/30000], Loss: 2.4102\n",
      "Epoch [1/1], Batch [7810/30000], Loss: 2.4102\n",
      "Epoch [1/1], Batch [7820/30000], Loss: 2.2607\n",
      "Epoch [1/1], Batch [7830/30000], Loss: 2.3184\n",
      "Epoch [1/1], Batch [7840/30000], Loss: 2.2363\n",
      "Epoch [1/1], Batch [7850/30000], Loss: 2.4434\n",
      "Epoch [1/1], Batch [7860/30000], Loss: 2.5967\n",
      "Epoch [1/1], Batch [7870/30000], Loss: 2.2764\n",
      "Epoch [1/1], Batch [7880/30000], Loss: 2.3135\n",
      "Epoch [1/1], Batch [7890/30000], Loss: 2.4375\n",
      "Epoch [1/1], Batch [7900/30000], Loss: 2.2842\n",
      "Epoch [1/1], Batch [7910/30000], Loss: 2.1768\n",
      "Epoch [1/1], Batch [7920/30000], Loss: 2.2900\n",
      "Epoch [1/1], Batch [7930/30000], Loss: 2.3887\n",
      "Epoch [1/1], Batch [7940/30000], Loss: 2.3359\n",
      "Epoch [1/1], Batch [7950/30000], Loss: 2.2334\n",
      "Epoch [1/1], Batch [7960/30000], Loss: 2.3457\n",
      "Epoch [1/1], Batch [7970/30000], Loss: 1.9658\n",
      "Epoch [1/1], Batch [7980/30000], Loss: 2.6016\n",
      "Epoch [1/1], Batch [7990/30000], Loss: 2.4766\n",
      "Epoch [1/1], Batch [8000/30000], Loss: 2.2329\n",
      "Epoch [1/1], Batch [8010/30000], Loss: 2.3032\n",
      "Epoch [1/1], Batch [8020/30000], Loss: 2.2734\n",
      "Epoch [1/1], Batch [8030/30000], Loss: 2.3711\n",
      "Epoch [1/1], Batch [8040/30000], Loss: 2.2646\n",
      "Epoch [1/1], Batch [8050/30000], Loss: 1.9888\n",
      "Epoch [1/1], Batch [8060/30000], Loss: 2.8076\n",
      "Epoch [1/1], Batch [8070/30000], Loss: 2.4600\n",
      "Epoch [1/1], Batch [8080/30000], Loss: 2.2090\n",
      "Epoch [1/1], Batch [8090/30000], Loss: 2.2939\n",
      "Epoch [1/1], Batch [8100/30000], Loss: 2.3789\n",
      "Epoch [1/1], Batch [8110/30000], Loss: 2.2617\n",
      "Epoch [1/1], Batch [8120/30000], Loss: 2.4844\n",
      "Epoch [1/1], Batch [8130/30000], Loss: 2.2939\n",
      "Epoch [1/1], Batch [8140/30000], Loss: 2.2969\n",
      "Epoch [1/1], Batch [8150/30000], Loss: 2.2373\n",
      "Epoch [1/1], Batch [8160/30000], Loss: 2.1162\n",
      "Epoch [1/1], Batch [8170/30000], Loss: 1.6470\n",
      "Epoch [1/1], Batch [8180/30000], Loss: 2.6318\n",
      "Epoch [1/1], Batch [8190/30000], Loss: 2.4414\n",
      "Epoch [1/1], Batch [8200/30000], Loss: 2.6377\n",
      "Epoch [1/1], Batch [8210/30000], Loss: 2.1582\n",
      "Epoch [1/1], Batch [8220/30000], Loss: 2.3125\n",
      "Epoch [1/1], Batch [8230/30000], Loss: 2.1162\n",
      "Epoch [1/1], Batch [8240/30000], Loss: 2.1035\n",
      "Epoch [1/1], Batch [8250/30000], Loss: 2.2427\n",
      "Epoch [1/1], Batch [8260/30000], Loss: 2.3555\n",
      "Epoch [1/1], Batch [8270/30000], Loss: 2.3564\n",
      "Epoch [1/1], Batch [8280/30000], Loss: 2.4375\n",
      "Epoch [1/1], Batch [8290/30000], Loss: 2.3115\n",
      "Epoch [1/1], Batch [8300/30000], Loss: 2.2314\n",
      "Epoch [1/1], Batch [8310/30000], Loss: 2.3125\n",
      "Epoch [1/1], Batch [8320/30000], Loss: 2.3018\n",
      "Epoch [1/1], Batch [8330/30000], Loss: 2.4072\n",
      "Epoch [1/1], Batch [8340/30000], Loss: 2.1191\n",
      "Epoch [1/1], Batch [8350/30000], Loss: 2.2539\n",
      "Epoch [1/1], Batch [8360/30000], Loss: 2.4277\n",
      "Epoch [1/1], Batch [8370/30000], Loss: 2.3301\n",
      "Epoch [1/1], Batch [8380/30000], Loss: 2.2812\n",
      "Epoch [1/1], Batch [8390/30000], Loss: 2.2100\n",
      "Epoch [1/1], Batch [8400/30000], Loss: 2.2686\n",
      "Epoch [1/1], Batch [8410/30000], Loss: 2.2842\n",
      "Epoch [1/1], Batch [8420/30000], Loss: 2.0542\n",
      "Epoch [1/1], Batch [8430/30000], Loss: 2.6348\n",
      "Epoch [1/1], Batch [8440/30000], Loss: 2.3936\n",
      "Epoch [1/1], Batch [8450/30000], Loss: 2.3174\n",
      "Epoch [1/1], Batch [8460/30000], Loss: 2.4258\n",
      "Epoch [1/1], Batch [8470/30000], Loss: 2.2139\n",
      "Epoch [1/1], Batch [8480/30000], Loss: 2.5146\n",
      "Epoch [1/1], Batch [8490/30000], Loss: 2.3193\n",
      "Epoch [1/1], Batch [8500/30000], Loss: 2.2793\n",
      "Epoch [1/1], Batch [8510/30000], Loss: 2.1953\n",
      "Epoch [1/1], Batch [8520/30000], Loss: 2.4355\n",
      "Epoch [1/1], Batch [8530/30000], Loss: 2.2129\n",
      "Epoch [1/1], Batch [8540/30000], Loss: 2.1768\n",
      "Epoch [1/1], Batch [8550/30000], Loss: 2.3301\n",
      "Epoch [1/1], Batch [8560/30000], Loss: 2.4219\n",
      "Epoch [1/1], Batch [8570/30000], Loss: 2.3789\n",
      "Epoch [1/1], Batch [8580/30000], Loss: 2.4131\n",
      "Epoch [1/1], Batch [8590/30000], Loss: 2.4141\n",
      "Epoch [1/1], Batch [8600/30000], Loss: 2.2998\n",
      "Epoch [1/1], Batch [8610/30000], Loss: 2.4346\n",
      "Epoch [1/1], Batch [8620/30000], Loss: 2.3369\n",
      "Epoch [1/1], Batch [8630/30000], Loss: 2.2939\n",
      "Epoch [1/1], Batch [8640/30000], Loss: 2.4785\n",
      "Epoch [1/1], Batch [8650/30000], Loss: 2.1387\n",
      "Epoch [1/1], Batch [8660/30000], Loss: 1.8438\n",
      "Epoch [1/1], Batch [8670/30000], Loss: 2.2939\n",
      "Epoch [1/1], Batch [8680/30000], Loss: 2.1738\n",
      "Epoch [1/1], Batch [8690/30000], Loss: 2.4277\n",
      "Epoch [1/1], Batch [8700/30000], Loss: 2.4609\n",
      "Epoch [1/1], Batch [8710/30000], Loss: 2.3555\n",
      "Epoch [1/1], Batch [8720/30000], Loss: 2.0737\n",
      "Epoch [1/1], Batch [8730/30000], Loss: 2.2490\n",
      "Epoch [1/1], Batch [8740/30000], Loss: 2.2275\n",
      "Epoch [1/1], Batch [8750/30000], Loss: 2.2139\n",
      "Epoch [1/1], Batch [8760/30000], Loss: 2.5918\n",
      "Epoch [1/1], Batch [8770/30000], Loss: 2.1826\n",
      "Epoch [1/1], Batch [8780/30000], Loss: 2.2100\n",
      "Epoch [1/1], Batch [8790/30000], Loss: 2.4502\n",
      "Epoch [1/1], Batch [8800/30000], Loss: 2.1680\n",
      "Epoch [1/1], Batch [8810/30000], Loss: 2.0493\n",
      "Epoch [1/1], Batch [8820/30000], Loss: 2.3994\n",
      "Epoch [1/1], Batch [8830/30000], Loss: 2.3389\n",
      "Epoch [1/1], Batch [8840/30000], Loss: 2.2637\n",
      "Epoch [1/1], Batch [8850/30000], Loss: 2.2812\n",
      "Epoch [1/1], Batch [8860/30000], Loss: 2.2861\n",
      "Epoch [1/1], Batch [8870/30000], Loss: 2.3867\n",
      "Epoch [1/1], Batch [8880/30000], Loss: 2.2754\n",
      "Epoch [1/1], Batch [8890/30000], Loss: 1.9121\n",
      "Epoch [1/1], Batch [8900/30000], Loss: 1.8164\n",
      "Epoch [1/1], Batch [8910/30000], Loss: 2.1968\n",
      "Epoch [1/1], Batch [8920/30000], Loss: 2.2422\n",
      "Epoch [1/1], Batch [8930/30000], Loss: 2.2920\n",
      "Epoch [1/1], Batch [8940/30000], Loss: 2.2490\n",
      "Epoch [1/1], Batch [8950/30000], Loss: 2.5586\n",
      "Epoch [1/1], Batch [8960/30000], Loss: 2.3843\n",
      "Epoch [1/1], Batch [8970/30000], Loss: 2.2573\n",
      "Epoch [1/1], Batch [8980/30000], Loss: 2.6211\n",
      "Epoch [1/1], Batch [8990/30000], Loss: 2.2910\n",
      "Epoch [1/1], Batch [9000/30000], Loss: 2.3916\n",
      "Epoch [1/1], Batch [9010/30000], Loss: 2.4141\n",
      "Epoch [1/1], Batch [9020/30000], Loss: 2.3008\n",
      "Epoch [1/1], Batch [9030/30000], Loss: 2.3662\n",
      "Epoch [1/1], Batch [9040/30000], Loss: 2.3789\n",
      "Epoch [1/1], Batch [9050/30000], Loss: 2.1543\n",
      "Epoch [1/1], Batch [9060/30000], Loss: 2.2471\n",
      "Epoch [1/1], Batch [9070/30000], Loss: 2.2715\n",
      "Epoch [1/1], Batch [9080/30000], Loss: 2.3516\n",
      "Epoch [1/1], Batch [9090/30000], Loss: 2.2549\n",
      "Epoch [1/1], Batch [9100/30000], Loss: 2.1113\n",
      "Epoch [1/1], Batch [9110/30000], Loss: 2.2793\n",
      "Epoch [1/1], Batch [9120/30000], Loss: 2.1934\n",
      "Epoch [1/1], Batch [9130/30000], Loss: 2.2529\n",
      "Epoch [1/1], Batch [9140/30000], Loss: 2.4248\n",
      "Epoch [1/1], Batch [9150/30000], Loss: 2.2920\n",
      "Epoch [1/1], Batch [9160/30000], Loss: 2.1562\n",
      "Epoch [1/1], Batch [9170/30000], Loss: 2.3203\n",
      "Epoch [1/1], Batch [9180/30000], Loss: 2.3584\n",
      "Epoch [1/1], Batch [9190/30000], Loss: 2.3457\n",
      "Epoch [1/1], Batch [9200/30000], Loss: 2.1670\n",
      "Epoch [1/1], Batch [9210/30000], Loss: 2.4482\n",
      "Epoch [1/1], Batch [9220/30000], Loss: 2.2217\n",
      "Epoch [1/1], Batch [9230/30000], Loss: 2.2900\n",
      "Epoch [1/1], Batch [9240/30000], Loss: 2.0791\n",
      "Epoch [1/1], Batch [9250/30000], Loss: 2.3105\n",
      "Epoch [1/1], Batch [9260/30000], Loss: 2.3398\n",
      "Epoch [1/1], Batch [9270/30000], Loss: 2.2734\n",
      "Epoch [1/1], Batch [9280/30000], Loss: 2.2344\n",
      "Epoch [1/1], Batch [9290/30000], Loss: 2.1875\n",
      "Epoch [1/1], Batch [9300/30000], Loss: 2.1523\n",
      "Epoch [1/1], Batch [9310/30000], Loss: 2.4932\n",
      "Epoch [1/1], Batch [9320/30000], Loss: 2.4229\n",
      "Epoch [1/1], Batch [9330/30000], Loss: 2.2598\n",
      "Epoch [1/1], Batch [9340/30000], Loss: 2.2832\n",
      "Epoch [1/1], Batch [9350/30000], Loss: 2.3770\n",
      "Epoch [1/1], Batch [9360/30000], Loss: 2.2432\n",
      "Epoch [1/1], Batch [9370/30000], Loss: 2.3867\n",
      "Epoch [1/1], Batch [9380/30000], Loss: 2.3975\n",
      "Epoch [1/1], Batch [9390/30000], Loss: 2.4541\n",
      "Epoch [1/1], Batch [9400/30000], Loss: 2.3418\n",
      "Epoch [1/1], Batch [9410/30000], Loss: 2.2832\n",
      "Epoch [1/1], Batch [9420/30000], Loss: 2.4209\n",
      "Epoch [1/1], Batch [9430/30000], Loss: 2.5088\n",
      "Epoch [1/1], Batch [9440/30000], Loss: 2.5410\n",
      "Epoch [1/1], Batch [9450/30000], Loss: 2.2715\n",
      "Epoch [1/1], Batch [9460/30000], Loss: 2.2324\n",
      "Epoch [1/1], Batch [9470/30000], Loss: 2.3223\n",
      "Epoch [1/1], Batch [9480/30000], Loss: 2.3350\n",
      "Epoch [1/1], Batch [9490/30000], Loss: 2.3789\n",
      "Epoch [1/1], Batch [9500/30000], Loss: 2.2373\n",
      "Epoch [1/1], Batch [9510/30000], Loss: 2.3320\n",
      "Epoch [1/1], Batch [9520/30000], Loss: 2.3877\n",
      "Epoch [1/1], Batch [9530/30000], Loss: 2.2188\n",
      "Epoch [1/1], Batch [9540/30000], Loss: 2.2607\n",
      "Epoch [1/1], Batch [9550/30000], Loss: 2.4717\n",
      "Epoch [1/1], Batch [9560/30000], Loss: 2.1924\n",
      "Epoch [1/1], Batch [9570/30000], Loss: 2.2773\n",
      "Epoch [1/1], Batch [9580/30000], Loss: 2.2861\n",
      "Epoch [1/1], Batch [9590/30000], Loss: 2.2305\n",
      "Epoch [1/1], Batch [9600/30000], Loss: 2.2471\n",
      "Epoch [1/1], Batch [9610/30000], Loss: 2.1924\n",
      "Epoch [1/1], Batch [9620/30000], Loss: 2.2969\n",
      "Epoch [1/1], Batch [9630/30000], Loss: 2.2969\n",
      "Epoch [1/1], Batch [9640/30000], Loss: 2.2676\n",
      "Epoch [1/1], Batch [9650/30000], Loss: 2.3496\n",
      "Epoch [1/1], Batch [9660/30000], Loss: 2.2764\n",
      "Epoch [1/1], Batch [9670/30000], Loss: 2.5664\n",
      "Epoch [1/1], Batch [9680/30000], Loss: 2.2871\n",
      "Epoch [1/1], Batch [9690/30000], Loss: 2.4346\n",
      "Epoch [1/1], Batch [9700/30000], Loss: 2.3740\n",
      "Epoch [1/1], Batch [9710/30000], Loss: 2.1963\n",
      "Epoch [1/1], Batch [9720/30000], Loss: 2.1572\n",
      "Epoch [1/1], Batch [9730/30000], Loss: 2.6240\n",
      "Epoch [1/1], Batch [9740/30000], Loss: 2.2891\n",
      "Epoch [1/1], Batch [9750/30000], Loss: 2.3281\n",
      "Epoch [1/1], Batch [9760/30000], Loss: 2.2910\n",
      "Epoch [1/1], Batch [9770/30000], Loss: 2.2451\n",
      "Epoch [1/1], Batch [9780/30000], Loss: 2.3340\n",
      "Epoch [1/1], Batch [9790/30000], Loss: 2.2637\n",
      "Epoch [1/1], Batch [9800/30000], Loss: 2.3320\n",
      "Epoch [1/1], Batch [9810/30000], Loss: 2.3262\n",
      "Epoch [1/1], Batch [9820/30000], Loss: 2.2085\n",
      "Epoch [1/1], Batch [9830/30000], Loss: 2.4209\n",
      "Epoch [1/1], Batch [9840/30000], Loss: 2.3818\n",
      "Epoch [1/1], Batch [9850/30000], Loss: 2.4375\n",
      "Epoch [1/1], Batch [9860/30000], Loss: 2.4072\n",
      "Epoch [1/1], Batch [9870/30000], Loss: 2.3096\n",
      "Epoch [1/1], Batch [9880/30000], Loss: 2.4814\n",
      "Epoch [1/1], Batch [9890/30000], Loss: 2.2227\n",
      "Epoch [1/1], Batch [9900/30000], Loss: 2.1523\n",
      "Epoch [1/1], Batch [9910/30000], Loss: 2.3086\n",
      "Epoch [1/1], Batch [9920/30000], Loss: 2.3965\n",
      "Epoch [1/1], Batch [9930/30000], Loss: 2.6416\n",
      "Epoch [1/1], Batch [9940/30000], Loss: 2.2793\n",
      "Epoch [1/1], Batch [9950/30000], Loss: 2.3916\n",
      "Epoch [1/1], Batch [9960/30000], Loss: 2.3994\n",
      "Epoch [1/1], Batch [9970/30000], Loss: 2.3457\n",
      "Epoch [1/1], Batch [9980/30000], Loss: 2.3818\n",
      "Epoch [1/1], Batch [9990/30000], Loss: 2.3701\n",
      "Epoch [1/1], Batch [10000/30000], Loss: 2.2617\n",
      "Epoch [1/1], Batch [10010/30000], Loss: 2.4492\n",
      "Epoch [1/1], Batch [10020/30000], Loss: 2.4258\n",
      "Epoch [1/1], Batch [10030/30000], Loss: 2.2852\n",
      "Epoch [1/1], Batch [10040/30000], Loss: 2.3584\n",
      "Epoch [1/1], Batch [10050/30000], Loss: 2.2998\n",
      "Epoch [1/1], Batch [10060/30000], Loss: 2.3164\n",
      "Epoch [1/1], Batch [10070/30000], Loss: 2.2490\n",
      "Epoch [1/1], Batch [10080/30000], Loss: 1.9409\n",
      "Epoch [1/1], Batch [10090/30000], Loss: 2.4277\n",
      "Epoch [1/1], Batch [10100/30000], Loss: 2.2705\n",
      "Epoch [1/1], Batch [10110/30000], Loss: 2.2148\n",
      "Epoch [1/1], Batch [10120/30000], Loss: 2.1699\n",
      "Epoch [1/1], Batch [10130/30000], Loss: 2.3887\n",
      "Epoch [1/1], Batch [10140/30000], Loss: 2.3154\n",
      "Epoch [1/1], Batch [10150/30000], Loss: 2.2461\n",
      "Epoch [1/1], Batch [10160/30000], Loss: 2.1826\n",
      "Epoch [1/1], Batch [10170/30000], Loss: 2.4834\n",
      "Epoch [1/1], Batch [10180/30000], Loss: 2.2500\n",
      "Epoch [1/1], Batch [10190/30000], Loss: 2.1680\n",
      "Epoch [1/1], Batch [10200/30000], Loss: 2.5195\n",
      "Epoch [1/1], Batch [10210/30000], Loss: 2.3496\n",
      "Epoch [1/1], Batch [10220/30000], Loss: 2.3975\n",
      "Epoch [1/1], Batch [10230/30000], Loss: 2.3252\n",
      "Epoch [1/1], Batch [10240/30000], Loss: 2.2871\n",
      "Epoch [1/1], Batch [10250/30000], Loss: 2.0889\n",
      "Epoch [1/1], Batch [10260/30000], Loss: 2.2695\n",
      "Epoch [1/1], Batch [10270/30000], Loss: 2.4141\n",
      "Epoch [1/1], Batch [10280/30000], Loss: 2.0728\n",
      "Epoch [1/1], Batch [10290/30000], Loss: 2.2666\n",
      "Epoch [1/1], Batch [10300/30000], Loss: 2.1953\n",
      "Epoch [1/1], Batch [10310/30000], Loss: 2.2422\n",
      "Epoch [1/1], Batch [10320/30000], Loss: 2.1211\n",
      "Epoch [1/1], Batch [10330/30000], Loss: 2.3408\n",
      "Epoch [1/1], Batch [10340/30000], Loss: 2.3584\n",
      "Epoch [1/1], Batch [10350/30000], Loss: 2.4863\n",
      "Epoch [1/1], Batch [10360/30000], Loss: 2.2002\n",
      "Epoch [1/1], Batch [10370/30000], Loss: 2.2573\n",
      "Epoch [1/1], Batch [10380/30000], Loss: 2.2441\n",
      "Epoch [1/1], Batch [10390/30000], Loss: 2.4199\n",
      "Epoch [1/1], Batch [10400/30000], Loss: 2.3037\n",
      "Epoch [1/1], Batch [10410/30000], Loss: 2.2109\n",
      "Epoch [1/1], Batch [10420/30000], Loss: 2.4180\n",
      "Epoch [1/1], Batch [10430/30000], Loss: 2.4033\n",
      "Epoch [1/1], Batch [10440/30000], Loss: 2.4795\n",
      "Epoch [1/1], Batch [10450/30000], Loss: 2.2832\n",
      "Epoch [1/1], Batch [10460/30000], Loss: 2.6357\n",
      "Epoch [1/1], Batch [10470/30000], Loss: 2.3867\n",
      "Epoch [1/1], Batch [10480/30000], Loss: 2.3711\n",
      "Epoch [1/1], Batch [10490/30000], Loss: 2.0669\n",
      "Epoch [1/1], Batch [10500/30000], Loss: 2.6094\n",
      "Epoch [1/1], Batch [10510/30000], Loss: 2.3525\n",
      "Epoch [1/1], Batch [10520/30000], Loss: 2.3955\n",
      "Epoch [1/1], Batch [10530/30000], Loss: 2.3740\n",
      "Epoch [1/1], Batch [10540/30000], Loss: 2.2939\n",
      "Epoch [1/1], Batch [10550/30000], Loss: 2.3428\n",
      "Epoch [1/1], Batch [10560/30000], Loss: 2.3486\n",
      "Epoch [1/1], Batch [10570/30000], Loss: 2.2949\n",
      "Epoch [1/1], Batch [10580/30000], Loss: 2.1934\n",
      "Epoch [1/1], Batch [10590/30000], Loss: 2.3438\n",
      "Epoch [1/1], Batch [10600/30000], Loss: 2.2539\n",
      "Epoch [1/1], Batch [10610/30000], Loss: 2.1377\n",
      "Epoch [1/1], Batch [10620/30000], Loss: 2.3340\n",
      "Epoch [1/1], Batch [10630/30000], Loss: 2.3457\n",
      "Epoch [1/1], Batch [10640/30000], Loss: 2.3438\n",
      "Epoch [1/1], Batch [10650/30000], Loss: 2.2930\n",
      "Epoch [1/1], Batch [10660/30000], Loss: 2.2891\n",
      "Epoch [1/1], Batch [10670/30000], Loss: 2.3711\n",
      "Epoch [1/1], Batch [10680/30000], Loss: 2.2930\n",
      "Epoch [1/1], Batch [10690/30000], Loss: 2.3105\n",
      "Epoch [1/1], Batch [10700/30000], Loss: 2.4385\n",
      "Epoch [1/1], Batch [10710/30000], Loss: 2.3408\n",
      "Epoch [1/1], Batch [10720/30000], Loss: 2.5361\n",
      "Epoch [1/1], Batch [10730/30000], Loss: 2.2627\n",
      "Epoch [1/1], Batch [10740/30000], Loss: 2.3066\n",
      "Epoch [1/1], Batch [10750/30000], Loss: 2.3135\n",
      "Epoch [1/1], Batch [10760/30000], Loss: 2.4102\n",
      "Epoch [1/1], Batch [10770/30000], Loss: 2.1523\n",
      "Epoch [1/1], Batch [10780/30000], Loss: 2.3486\n",
      "Epoch [1/1], Batch [10790/30000], Loss: 2.3828\n",
      "Epoch [1/1], Batch [10800/30000], Loss: 2.1211\n",
      "Epoch [1/1], Batch [10810/30000], Loss: 2.3828\n",
      "Epoch [1/1], Batch [10820/30000], Loss: 2.3516\n",
      "Epoch [1/1], Batch [10830/30000], Loss: 2.3242\n",
      "Epoch [1/1], Batch [10840/30000], Loss: 2.1689\n",
      "Epoch [1/1], Batch [10850/30000], Loss: 2.3457\n",
      "Epoch [1/1], Batch [10860/30000], Loss: 2.1846\n",
      "Epoch [1/1], Batch [10870/30000], Loss: 2.3066\n",
      "Epoch [1/1], Batch [10880/30000], Loss: 2.4326\n",
      "Epoch [1/1], Batch [10890/30000], Loss: 2.2979\n",
      "Epoch [1/1], Batch [10900/30000], Loss: 2.1763\n",
      "Epoch [1/1], Batch [10910/30000], Loss: 2.3027\n",
      "Epoch [1/1], Batch [10920/30000], Loss: 2.3701\n",
      "Epoch [1/1], Batch [10930/30000], Loss: 2.3984\n",
      "Epoch [1/1], Batch [10940/30000], Loss: 2.4766\n",
      "Epoch [1/1], Batch [10950/30000], Loss: 2.2246\n",
      "Epoch [1/1], Batch [10960/30000], Loss: 2.3135\n",
      "Epoch [1/1], Batch [10970/30000], Loss: 2.3936\n",
      "Epoch [1/1], Batch [10980/30000], Loss: 2.3008\n",
      "Epoch [1/1], Batch [10990/30000], Loss: 2.3203\n",
      "Epoch [1/1], Batch [11000/30000], Loss: 2.3564\n",
      "Epoch [1/1], Batch [11010/30000], Loss: 2.3359\n",
      "Epoch [1/1], Batch [11020/30000], Loss: 2.3877\n",
      "Epoch [1/1], Batch [11030/30000], Loss: 2.3096\n",
      "Epoch [1/1], Batch [11040/30000], Loss: 3.0234\n",
      "Epoch [1/1], Batch [11050/30000], Loss: 1.9658\n",
      "Epoch [1/1], Batch [11060/30000], Loss: 1.5210\n",
      "Epoch [1/1], Batch [11070/30000], Loss: 2.9688\n",
      "Epoch [1/1], Batch [11080/30000], Loss: 2.6650\n",
      "Epoch [1/1], Batch [11090/30000], Loss: 2.3877\n",
      "Epoch [1/1], Batch [11100/30000], Loss: 2.3057\n",
      "Epoch [1/1], Batch [11110/30000], Loss: 1.7417\n",
      "Epoch [1/1], Batch [11120/30000], Loss: 2.0498\n",
      "Epoch [1/1], Batch [11130/30000], Loss: 2.5156\n",
      "Epoch [1/1], Batch [11140/30000], Loss: 2.1919\n",
      "Epoch [1/1], Batch [11150/30000], Loss: 2.5938\n",
      "Epoch [1/1], Batch [11160/30000], Loss: 2.6533\n",
      "Epoch [1/1], Batch [11170/30000], Loss: 1.9829\n",
      "Epoch [1/1], Batch [11180/30000], Loss: 2.3428\n",
      "Epoch [1/1], Batch [11190/30000], Loss: 2.5439\n",
      "Epoch [1/1], Batch [11200/30000], Loss: 2.2891\n",
      "Epoch [1/1], Batch [11210/30000], Loss: 2.4482\n",
      "Epoch [1/1], Batch [11220/30000], Loss: 2.5518\n",
      "Epoch [1/1], Batch [11230/30000], Loss: 2.2861\n",
      "Epoch [1/1], Batch [11240/30000], Loss: 2.3662\n",
      "Epoch [1/1], Batch [11250/30000], Loss: 3.1719\n",
      "Epoch [1/1], Batch [11260/30000], Loss: 2.1670\n",
      "Epoch [1/1], Batch [11270/30000], Loss: 2.3262\n",
      "Epoch [1/1], Batch [11280/30000], Loss: 2.2773\n",
      "Epoch [1/1], Batch [11290/30000], Loss: 2.2666\n",
      "Epoch [1/1], Batch [11300/30000], Loss: 2.9043\n",
      "Epoch [1/1], Batch [11310/30000], Loss: 2.3262\n",
      "Epoch [1/1], Batch [11320/30000], Loss: 2.4238\n",
      "Epoch [1/1], Batch [11330/30000], Loss: 2.2637\n",
      "Epoch [1/1], Batch [11340/30000], Loss: 2.6123\n",
      "Epoch [1/1], Batch [11350/30000], Loss: 2.2012\n",
      "Epoch [1/1], Batch [11360/30000], Loss: 2.5234\n",
      "Epoch [1/1], Batch [11370/30000], Loss: 2.2646\n",
      "Epoch [1/1], Batch [11380/30000], Loss: 2.2686\n",
      "Epoch [1/1], Batch [11390/30000], Loss: 2.3809\n",
      "Epoch [1/1], Batch [11400/30000], Loss: 2.3428\n",
      "Epoch [1/1], Batch [11410/30000], Loss: 2.3936\n",
      "Epoch [1/1], Batch [11420/30000], Loss: 2.3877\n",
      "Epoch [1/1], Batch [11430/30000], Loss: 2.4404\n",
      "Epoch [1/1], Batch [11440/30000], Loss: 2.1836\n",
      "Epoch [1/1], Batch [11450/30000], Loss: 2.0508\n",
      "Epoch [1/1], Batch [11460/30000], Loss: 2.4473\n",
      "Epoch [1/1], Batch [11470/30000], Loss: 2.3037\n",
      "Epoch [1/1], Batch [11480/30000], Loss: 2.5381\n",
      "Epoch [1/1], Batch [11490/30000], Loss: 2.2910\n",
      "Epoch [1/1], Batch [11500/30000], Loss: 2.2930\n",
      "Epoch [1/1], Batch [11510/30000], Loss: 2.3477\n",
      "Epoch [1/1], Batch [11520/30000], Loss: 2.0938\n",
      "Epoch [1/1], Batch [11530/30000], Loss: 2.2178\n",
      "Epoch [1/1], Batch [11540/30000], Loss: 2.0415\n",
      "Epoch [1/1], Batch [11550/30000], Loss: 2.3604\n",
      "Epoch [1/1], Batch [11560/30000], Loss: 2.2275\n",
      "Epoch [1/1], Batch [11570/30000], Loss: 2.2051\n",
      "Epoch [1/1], Batch [11580/30000], Loss: 2.3145\n",
      "Epoch [1/1], Batch [11590/30000], Loss: 2.2314\n",
      "Epoch [1/1], Batch [11600/30000], Loss: 2.2637\n",
      "Epoch [1/1], Batch [11610/30000], Loss: 2.3037\n",
      "Epoch [1/1], Batch [11620/30000], Loss: 2.3389\n",
      "Epoch [1/1], Batch [11630/30000], Loss: 2.3730\n",
      "Epoch [1/1], Batch [11640/30000], Loss: 2.1768\n",
      "Epoch [1/1], Batch [11650/30000], Loss: 2.1592\n",
      "Epoch [1/1], Batch [11660/30000], Loss: 2.3623\n",
      "Epoch [1/1], Batch [11670/30000], Loss: 2.3408\n",
      "Epoch [1/1], Batch [11680/30000], Loss: 2.2183\n",
      "Epoch [1/1], Batch [11690/30000], Loss: 2.0410\n",
      "Epoch [1/1], Batch [11700/30000], Loss: 2.5205\n",
      "Epoch [1/1], Batch [11710/30000], Loss: 2.3672\n",
      "Epoch [1/1], Batch [11720/30000], Loss: 2.4902\n",
      "Epoch [1/1], Batch [11730/30000], Loss: 2.3730\n",
      "Epoch [1/1], Batch [11740/30000], Loss: 2.2861\n",
      "Epoch [1/1], Batch [11750/30000], Loss: 2.4756\n",
      "Epoch [1/1], Batch [11760/30000], Loss: 2.4004\n",
      "Epoch [1/1], Batch [11770/30000], Loss: 2.3301\n",
      "Epoch [1/1], Batch [11780/30000], Loss: 2.4033\n",
      "Epoch [1/1], Batch [11790/30000], Loss: 2.3477\n",
      "Epoch [1/1], Batch [11800/30000], Loss: 2.3447\n",
      "Epoch [1/1], Batch [11810/30000], Loss: 2.4092\n",
      "Epoch [1/1], Batch [11820/30000], Loss: 2.3105\n",
      "Epoch [1/1], Batch [11830/30000], Loss: 2.4023\n",
      "Epoch [1/1], Batch [11840/30000], Loss: 2.1768\n",
      "Epoch [1/1], Batch [11850/30000], Loss: 2.1865\n",
      "Epoch [1/1], Batch [11860/30000], Loss: 2.4102\n",
      "Epoch [1/1], Batch [11870/30000], Loss: 2.2080\n",
      "Epoch [1/1], Batch [11880/30000], Loss: 2.1909\n",
      "Epoch [1/1], Batch [11890/30000], Loss: 2.2900\n",
      "Epoch [1/1], Batch [11900/30000], Loss: 2.4688\n",
      "Epoch [1/1], Batch [11910/30000], Loss: 2.1787\n",
      "Epoch [1/1], Batch [11920/30000], Loss: 2.3984\n",
      "Epoch [1/1], Batch [11930/30000], Loss: 2.6826\n",
      "Epoch [1/1], Batch [11940/30000], Loss: 2.2275\n",
      "Epoch [1/1], Batch [11950/30000], Loss: 2.2969\n",
      "Epoch [1/1], Batch [11960/30000], Loss: 2.4551\n",
      "Epoch [1/1], Batch [11970/30000], Loss: 2.3828\n",
      "Epoch [1/1], Batch [11980/30000], Loss: 2.3418\n",
      "Epoch [1/1], Batch [11990/30000], Loss: 2.2715\n",
      "Epoch [1/1], Batch [12000/30000], Loss: 2.2793\n",
      "Epoch [1/1], Batch [12010/30000], Loss: 2.2959\n",
      "Epoch [1/1], Batch [12020/30000], Loss: 2.2393\n",
      "Epoch [1/1], Batch [12030/30000], Loss: 2.1587\n",
      "Epoch [1/1], Batch [12040/30000], Loss: 2.3926\n",
      "Epoch [1/1], Batch [12050/30000], Loss: 2.2666\n",
      "Epoch [1/1], Batch [12060/30000], Loss: 2.1924\n",
      "Epoch [1/1], Batch [12070/30000], Loss: 2.4580\n",
      "Epoch [1/1], Batch [12080/30000], Loss: 2.2920\n",
      "Epoch [1/1], Batch [12090/30000], Loss: 2.5186\n",
      "Epoch [1/1], Batch [12100/30000], Loss: 2.2021\n",
      "Epoch [1/1], Batch [12110/30000], Loss: 2.2412\n",
      "Epoch [1/1], Batch [12120/30000], Loss: 2.2363\n",
      "Epoch [1/1], Batch [12130/30000], Loss: 2.4844\n",
      "Epoch [1/1], Batch [12140/30000], Loss: 2.3818\n",
      "Epoch [1/1], Batch [12150/30000], Loss: 2.3916\n",
      "Epoch [1/1], Batch [12160/30000], Loss: 2.2842\n",
      "Epoch [1/1], Batch [12170/30000], Loss: 2.5195\n",
      "Epoch [1/1], Batch [12180/30000], Loss: 2.4297\n",
      "Epoch [1/1], Batch [12190/30000], Loss: 2.1504\n",
      "Epoch [1/1], Batch [12200/30000], Loss: 2.3467\n",
      "Epoch [1/1], Batch [12210/30000], Loss: 2.2188\n",
      "Epoch [1/1], Batch [12220/30000], Loss: 2.4209\n",
      "Epoch [1/1], Batch [12230/30000], Loss: 2.2842\n",
      "Epoch [1/1], Batch [12240/30000], Loss: 2.3379\n",
      "Epoch [1/1], Batch [12250/30000], Loss: 2.3926\n",
      "Epoch [1/1], Batch [12260/30000], Loss: 2.2949\n",
      "Epoch [1/1], Batch [12270/30000], Loss: 2.3525\n",
      "Epoch [1/1], Batch [12280/30000], Loss: 2.2461\n",
      "Epoch [1/1], Batch [12290/30000], Loss: 2.3105\n",
      "Epoch [1/1], Batch [12300/30000], Loss: 2.3955\n",
      "Epoch [1/1], Batch [12310/30000], Loss: 2.2285\n",
      "Epoch [1/1], Batch [12320/30000], Loss: 2.3398\n",
      "Epoch [1/1], Batch [12330/30000], Loss: 2.5000\n",
      "Epoch [1/1], Batch [12340/30000], Loss: 2.6006\n",
      "Epoch [1/1], Batch [12350/30000], Loss: 2.2529\n",
      "Epoch [1/1], Batch [12360/30000], Loss: 2.2695\n",
      "Epoch [1/1], Batch [12370/30000], Loss: 2.2441\n",
      "Epoch [1/1], Batch [12380/30000], Loss: 2.3008\n",
      "Epoch [1/1], Batch [12390/30000], Loss: 2.3730\n",
      "Epoch [1/1], Batch [12400/30000], Loss: 2.3818\n",
      "Epoch [1/1], Batch [12410/30000], Loss: 2.2256\n",
      "Epoch [1/1], Batch [12420/30000], Loss: 2.1055\n",
      "Epoch [1/1], Batch [12430/30000], Loss: 2.4141\n",
      "Epoch [1/1], Batch [12440/30000], Loss: 2.3447\n",
      "Epoch [1/1], Batch [12450/30000], Loss: 2.3281\n",
      "Epoch [1/1], Batch [12460/30000], Loss: 2.4395\n",
      "Epoch [1/1], Batch [12470/30000], Loss: 2.4014\n",
      "Epoch [1/1], Batch [12480/30000], Loss: 2.1523\n",
      "Epoch [1/1], Batch [12490/30000], Loss: 2.4434\n",
      "Epoch [1/1], Batch [12500/30000], Loss: 2.3799\n",
      "Epoch [1/1], Batch [12510/30000], Loss: 2.3750\n",
      "Epoch [1/1], Batch [12520/30000], Loss: 2.3145\n",
      "Epoch [1/1], Batch [12530/30000], Loss: 2.3232\n",
      "Epoch [1/1], Batch [12540/30000], Loss: 2.3926\n",
      "Epoch [1/1], Batch [12550/30000], Loss: 2.3965\n",
      "Epoch [1/1], Batch [12560/30000], Loss: 2.2461\n",
      "Epoch [1/1], Batch [12570/30000], Loss: 2.3467\n",
      "Epoch [1/1], Batch [12580/30000], Loss: 2.4102\n",
      "Epoch [1/1], Batch [12590/30000], Loss: 1.9287\n",
      "Epoch [1/1], Batch [12600/30000], Loss: 2.3662\n",
      "Epoch [1/1], Batch [12610/30000], Loss: 2.4082\n",
      "Epoch [1/1], Batch [12620/30000], Loss: 2.1309\n",
      "Epoch [1/1], Batch [12630/30000], Loss: 2.2256\n",
      "Epoch [1/1], Batch [12640/30000], Loss: 2.3555\n",
      "Epoch [1/1], Batch [12650/30000], Loss: 2.3213\n",
      "Epoch [1/1], Batch [12660/30000], Loss: 2.3057\n",
      "Epoch [1/1], Batch [12670/30000], Loss: 2.2627\n",
      "Epoch [1/1], Batch [12680/30000], Loss: 2.4824\n",
      "Epoch [1/1], Batch [12690/30000], Loss: 2.0718\n",
      "Epoch [1/1], Batch [12700/30000], Loss: 2.1128\n",
      "Epoch [1/1], Batch [12710/30000], Loss: 2.2959\n",
      "Epoch [1/1], Batch [12720/30000], Loss: 2.1562\n",
      "Epoch [1/1], Batch [12730/30000], Loss: 2.3193\n",
      "Epoch [1/1], Batch [12740/30000], Loss: 2.2578\n",
      "Epoch [1/1], Batch [12750/30000], Loss: 2.1348\n",
      "Epoch [1/1], Batch [12760/30000], Loss: 2.2192\n",
      "Epoch [1/1], Batch [12770/30000], Loss: 2.2783\n",
      "Epoch [1/1], Batch [12780/30000], Loss: 1.8389\n",
      "Epoch [1/1], Batch [12790/30000], Loss: 1.8706\n",
      "Epoch [1/1], Batch [12800/30000], Loss: 2.3447\n",
      "Epoch [1/1], Batch [12810/30000], Loss: 2.2607\n",
      "Epoch [1/1], Batch [12820/30000], Loss: 2.3135\n",
      "Epoch [1/1], Batch [12830/30000], Loss: 2.2510\n",
      "Epoch [1/1], Batch [12840/30000], Loss: 2.2803\n",
      "Epoch [1/1], Batch [12850/30000], Loss: 2.3926\n",
      "Epoch [1/1], Batch [12860/30000], Loss: 2.3379\n",
      "Epoch [1/1], Batch [12870/30000], Loss: 2.3457\n",
      "Epoch [1/1], Batch [12880/30000], Loss: 2.2988\n",
      "Epoch [1/1], Batch [12890/30000], Loss: 2.2793\n",
      "Epoch [1/1], Batch [12900/30000], Loss: 2.2881\n",
      "Epoch [1/1], Batch [12910/30000], Loss: 2.4189\n",
      "Epoch [1/1], Batch [12920/30000], Loss: 2.2705\n",
      "Epoch [1/1], Batch [12930/30000], Loss: 2.4082\n",
      "Epoch [1/1], Batch [12940/30000], Loss: 2.4277\n",
      "Epoch [1/1], Batch [12950/30000], Loss: 2.3447\n",
      "Epoch [1/1], Batch [12960/30000], Loss: 2.2617\n",
      "Epoch [1/1], Batch [12970/30000], Loss: 2.4004\n",
      "Epoch [1/1], Batch [12980/30000], Loss: 2.1484\n",
      "Epoch [1/1], Batch [12990/30000], Loss: 2.2334\n",
      "Epoch [1/1], Batch [13000/30000], Loss: 2.6387\n",
      "Epoch [1/1], Batch [13010/30000], Loss: 2.2900\n",
      "Epoch [1/1], Batch [13020/30000], Loss: 2.2998\n",
      "Epoch [1/1], Batch [13030/30000], Loss: 2.3340\n",
      "Epoch [1/1], Batch [13040/30000], Loss: 2.2021\n",
      "Epoch [1/1], Batch [13050/30000], Loss: 2.5088\n",
      "Epoch [1/1], Batch [13060/30000], Loss: 2.4688\n",
      "Epoch [1/1], Batch [13070/30000], Loss: 2.2939\n",
      "Epoch [1/1], Batch [13080/30000], Loss: 2.3418\n",
      "Epoch [1/1], Batch [13090/30000], Loss: 2.2891\n",
      "Epoch [1/1], Batch [13100/30000], Loss: 2.4141\n",
      "Epoch [1/1], Batch [13110/30000], Loss: 2.2158\n",
      "Epoch [1/1], Batch [13120/30000], Loss: 2.2207\n",
      "Epoch [1/1], Batch [13130/30000], Loss: 2.2803\n",
      "Epoch [1/1], Batch [13140/30000], Loss: 2.2666\n",
      "Epoch [1/1], Batch [13150/30000], Loss: 2.4844\n",
      "Epoch [1/1], Batch [13160/30000], Loss: 2.1758\n",
      "Epoch [1/1], Batch [13170/30000], Loss: 2.2051\n",
      "Epoch [1/1], Batch [13180/30000], Loss: 2.3633\n",
      "Epoch [1/1], Batch [13190/30000], Loss: 2.4297\n",
      "Epoch [1/1], Batch [13200/30000], Loss: 2.8174\n",
      "Epoch [1/1], Batch [13210/30000], Loss: 2.2422\n",
      "Epoch [1/1], Batch [13220/30000], Loss: 2.3652\n",
      "Epoch [1/1], Batch [13230/30000], Loss: 2.3037\n",
      "Epoch [1/1], Batch [13240/30000], Loss: 2.3242\n",
      "Epoch [1/1], Batch [13250/30000], Loss: 2.2686\n",
      "Epoch [1/1], Batch [13260/30000], Loss: 2.1035\n",
      "Epoch [1/1], Batch [13270/30000], Loss: 2.2803\n",
      "Epoch [1/1], Batch [13280/30000], Loss: 2.3203\n",
      "Epoch [1/1], Batch [13290/30000], Loss: 2.4941\n",
      "Epoch [1/1], Batch [13300/30000], Loss: 2.3594\n",
      "Epoch [1/1], Batch [13310/30000], Loss: 2.1670\n",
      "Epoch [1/1], Batch [13320/30000], Loss: 2.2617\n",
      "Epoch [1/1], Batch [13330/30000], Loss: 2.5156\n",
      "Epoch [1/1], Batch [13340/30000], Loss: 2.4180\n",
      "Epoch [1/1], Batch [13350/30000], Loss: 2.2295\n",
      "Epoch [1/1], Batch [13360/30000], Loss: 2.3545\n",
      "Epoch [1/1], Batch [13370/30000], Loss: 2.3398\n",
      "Epoch [1/1], Batch [13380/30000], Loss: 2.1421\n",
      "Epoch [1/1], Batch [13390/30000], Loss: 2.5156\n",
      "Epoch [1/1], Batch [13400/30000], Loss: 2.1572\n",
      "Epoch [1/1], Batch [13410/30000], Loss: 2.6357\n",
      "Epoch [1/1], Batch [13420/30000], Loss: 2.5537\n",
      "Epoch [1/1], Batch [13430/30000], Loss: 2.2910\n",
      "Epoch [1/1], Batch [13440/30000], Loss: 2.3467\n",
      "Epoch [1/1], Batch [13450/30000], Loss: 2.3174\n",
      "Epoch [1/1], Batch [13460/30000], Loss: 2.3867\n",
      "Epoch [1/1], Batch [13470/30000], Loss: 2.3643\n",
      "Epoch [1/1], Batch [13480/30000], Loss: 2.1582\n",
      "Epoch [1/1], Batch [13490/30000], Loss: 2.5439\n",
      "Epoch [1/1], Batch [13500/30000], Loss: 2.4570\n",
      "Epoch [1/1], Batch [13510/30000], Loss: 2.3584\n",
      "Epoch [1/1], Batch [13520/30000], Loss: 1.7422\n",
      "Epoch [1/1], Batch [13530/30000], Loss: 2.3408\n",
      "Epoch [1/1], Batch [13540/30000], Loss: 2.3281\n",
      "Epoch [1/1], Batch [13550/30000], Loss: 2.3555\n",
      "Epoch [1/1], Batch [13560/30000], Loss: 2.2969\n",
      "Epoch [1/1], Batch [13570/30000], Loss: 2.2676\n",
      "Epoch [1/1], Batch [13580/30000], Loss: 2.3311\n",
      "Epoch [1/1], Batch [13590/30000], Loss: 2.1914\n",
      "Epoch [1/1], Batch [13600/30000], Loss: 2.4180\n",
      "Epoch [1/1], Batch [13610/30000], Loss: 2.2822\n",
      "Epoch [1/1], Batch [13620/30000], Loss: 2.3174\n",
      "Epoch [1/1], Batch [13630/30000], Loss: 2.0732\n",
      "Epoch [1/1], Batch [13640/30000], Loss: 2.6514\n",
      "Epoch [1/1], Batch [13650/30000], Loss: 2.4756\n",
      "Epoch [1/1], Batch [13660/30000], Loss: 2.3662\n",
      "Epoch [1/1], Batch [13670/30000], Loss: 2.5830\n",
      "Epoch [1/1], Batch [13680/30000], Loss: 2.3252\n",
      "Epoch [1/1], Batch [13690/30000], Loss: 2.2100\n",
      "Epoch [1/1], Batch [13700/30000], Loss: 2.2598\n",
      "Epoch [1/1], Batch [13710/30000], Loss: 2.2510\n",
      "Epoch [1/1], Batch [13720/30000], Loss: 2.1934\n",
      "Epoch [1/1], Batch [13730/30000], Loss: 2.1924\n",
      "Epoch [1/1], Batch [13740/30000], Loss: 2.5098\n",
      "Epoch [1/1], Batch [13750/30000], Loss: 2.2451\n",
      "Epoch [1/1], Batch [13760/30000], Loss: 2.2188\n",
      "Epoch [1/1], Batch [13770/30000], Loss: 2.3164\n",
      "Epoch [1/1], Batch [13780/30000], Loss: 2.4121\n",
      "Epoch [1/1], Batch [13790/30000], Loss: 2.3271\n",
      "Epoch [1/1], Batch [13800/30000], Loss: 2.2744\n",
      "Epoch [1/1], Batch [13810/30000], Loss: 2.2861\n",
      "Epoch [1/1], Batch [13820/30000], Loss: 2.3203\n",
      "Epoch [1/1], Batch [13830/30000], Loss: 2.4590\n",
      "Epoch [1/1], Batch [13840/30000], Loss: 2.3867\n",
      "Epoch [1/1], Batch [13850/30000], Loss: 2.3340\n",
      "Epoch [1/1], Batch [13860/30000], Loss: 2.3555\n",
      "Epoch [1/1], Batch [13870/30000], Loss: 2.2598\n",
      "Epoch [1/1], Batch [13880/30000], Loss: 2.2568\n",
      "Epoch [1/1], Batch [13890/30000], Loss: 2.3232\n",
      "Epoch [1/1], Batch [13900/30000], Loss: 2.3379\n",
      "Epoch [1/1], Batch [13910/30000], Loss: 2.3223\n",
      "Epoch [1/1], Batch [13920/30000], Loss: 2.1963\n",
      "Epoch [1/1], Batch [13930/30000], Loss: 2.4658\n",
      "Epoch [1/1], Batch [13940/30000], Loss: 2.2334\n",
      "Epoch [1/1], Batch [13950/30000], Loss: 2.2588\n",
      "Epoch [1/1], Batch [13960/30000], Loss: 2.3535\n",
      "Epoch [1/1], Batch [13970/30000], Loss: 2.2617\n",
      "Epoch [1/1], Batch [13980/30000], Loss: 2.2979\n",
      "Epoch [1/1], Batch [13990/30000], Loss: 2.2646\n",
      "Epoch [1/1], Batch [14000/30000], Loss: 2.2246\n",
      "Epoch [1/1], Batch [14010/30000], Loss: 2.2217\n",
      "Epoch [1/1], Batch [14020/30000], Loss: 2.4238\n",
      "Epoch [1/1], Batch [14030/30000], Loss: 2.3330\n",
      "Epoch [1/1], Batch [14040/30000], Loss: 2.1914\n",
      "Epoch [1/1], Batch [14050/30000], Loss: 2.4814\n",
      "Epoch [1/1], Batch [14060/30000], Loss: 2.3691\n",
      "Epoch [1/1], Batch [14070/30000], Loss: 2.7070\n",
      "Epoch [1/1], Batch [14080/30000], Loss: 2.2075\n",
      "Epoch [1/1], Batch [14090/30000], Loss: 2.2178\n",
      "Epoch [1/1], Batch [14100/30000], Loss: 2.4121\n",
      "Epoch [1/1], Batch [14110/30000], Loss: 2.2871\n",
      "Epoch [1/1], Batch [14120/30000], Loss: 2.1875\n",
      "Epoch [1/1], Batch [14130/30000], Loss: 2.4570\n",
      "Epoch [1/1], Batch [14140/30000], Loss: 2.2900\n",
      "Epoch [1/1], Batch [14150/30000], Loss: 2.3174\n",
      "Epoch [1/1], Batch [14160/30000], Loss: 2.2676\n",
      "Epoch [1/1], Batch [14170/30000], Loss: 2.4229\n",
      "Epoch [1/1], Batch [14180/30000], Loss: 2.2803\n",
      "Epoch [1/1], Batch [14190/30000], Loss: 2.1885\n",
      "Epoch [1/1], Batch [14200/30000], Loss: 2.1836\n",
      "Epoch [1/1], Batch [14210/30000], Loss: 2.3711\n",
      "Epoch [1/1], Batch [14220/30000], Loss: 2.2354\n",
      "Epoch [1/1], Batch [14230/30000], Loss: 2.2715\n",
      "Epoch [1/1], Batch [14240/30000], Loss: 2.3281\n",
      "Epoch [1/1], Batch [14250/30000], Loss: 2.3164\n",
      "Epoch [1/1], Batch [14260/30000], Loss: 2.1104\n",
      "Epoch [1/1], Batch [14270/30000], Loss: 2.1787\n",
      "Epoch [1/1], Batch [14280/30000], Loss: 2.4561\n",
      "Epoch [1/1], Batch [14290/30000], Loss: 2.3926\n",
      "Epoch [1/1], Batch [14300/30000], Loss: 2.2949\n",
      "Epoch [1/1], Batch [14310/30000], Loss: 2.1982\n",
      "Epoch [1/1], Batch [14320/30000], Loss: 2.2686\n",
      "Epoch [1/1], Batch [14330/30000], Loss: 2.1309\n",
      "Epoch [1/1], Batch [14340/30000], Loss: 2.3389\n",
      "Epoch [1/1], Batch [14350/30000], Loss: 2.4043\n",
      "Epoch [1/1], Batch [14360/30000], Loss: 2.4570\n",
      "Epoch [1/1], Batch [14370/30000], Loss: 2.5693\n",
      "Epoch [1/1], Batch [14380/30000], Loss: 2.1895\n",
      "Epoch [1/1], Batch [14390/30000], Loss: 2.3037\n",
      "Epoch [1/1], Batch [14400/30000], Loss: 2.3066\n",
      "Epoch [1/1], Batch [14410/30000], Loss: 2.3389\n",
      "Epoch [1/1], Batch [14420/30000], Loss: 2.2969\n",
      "Epoch [1/1], Batch [14430/30000], Loss: 2.3281\n",
      "Epoch [1/1], Batch [14440/30000], Loss: 2.2910\n",
      "Epoch [1/1], Batch [14450/30000], Loss: 2.2832\n",
      "Epoch [1/1], Batch [14460/30000], Loss: 2.1885\n",
      "Epoch [1/1], Batch [14470/30000], Loss: 2.3525\n",
      "Epoch [1/1], Batch [14480/30000], Loss: 2.2119\n",
      "Epoch [1/1], Batch [14490/30000], Loss: 2.0332\n",
      "Epoch [1/1], Batch [14500/30000], Loss: 1.9565\n",
      "Epoch [1/1], Batch [14510/30000], Loss: 2.0054\n",
      "Epoch [1/1], Batch [14520/30000], Loss: 2.1367\n",
      "Epoch [1/1], Batch [14530/30000], Loss: 2.4443\n",
      "Epoch [1/1], Batch [14540/30000], Loss: 2.2969\n",
      "Epoch [1/1], Batch [14550/30000], Loss: 2.3174\n",
      "Epoch [1/1], Batch [14560/30000], Loss: 2.2021\n",
      "Epoch [1/1], Batch [14570/30000], Loss: 2.3721\n",
      "Epoch [1/1], Batch [14580/30000], Loss: 2.3701\n",
      "Epoch [1/1], Batch [14590/30000], Loss: 2.4121\n",
      "Epoch [1/1], Batch [14600/30000], Loss: 2.3223\n",
      "Epoch [1/1], Batch [14610/30000], Loss: 2.6094\n",
      "Epoch [1/1], Batch [14620/30000], Loss: 2.2891\n",
      "Epoch [1/1], Batch [14630/30000], Loss: 2.2041\n",
      "Epoch [1/1], Batch [14640/30000], Loss: 2.5479\n",
      "Epoch [1/1], Batch [14650/30000], Loss: 2.2305\n",
      "Epoch [1/1], Batch [14660/30000], Loss: 2.2441\n",
      "Epoch [1/1], Batch [14670/30000], Loss: 2.4170\n",
      "Epoch [1/1], Batch [14680/30000], Loss: 2.3125\n",
      "Epoch [1/1], Batch [14690/30000], Loss: 2.2881\n",
      "Epoch [1/1], Batch [14700/30000], Loss: 2.4131\n",
      "Epoch [1/1], Batch [14710/30000], Loss: 2.2998\n",
      "Epoch [1/1], Batch [14720/30000], Loss: 2.3809\n",
      "Epoch [1/1], Batch [14730/30000], Loss: 2.5684\n",
      "Epoch [1/1], Batch [14740/30000], Loss: 2.2881\n",
      "Epoch [1/1], Batch [14750/30000], Loss: 2.4297\n",
      "Epoch [1/1], Batch [14760/30000], Loss: 2.4365\n",
      "Epoch [1/1], Batch [14770/30000], Loss: 2.7656\n",
      "Epoch [1/1], Batch [14780/30000], Loss: 2.3643\n",
      "Epoch [1/1], Batch [14790/30000], Loss: 2.2842\n",
      "Epoch [1/1], Batch [14800/30000], Loss: 2.2920\n",
      "Epoch [1/1], Batch [14810/30000], Loss: 2.3281\n",
      "Epoch [1/1], Batch [14820/30000], Loss: 2.1816\n",
      "Epoch [1/1], Batch [14830/30000], Loss: 2.2227\n",
      "Epoch [1/1], Batch [14840/30000], Loss: 2.2998\n",
      "Epoch [1/1], Batch [14850/30000], Loss: 2.1211\n",
      "Epoch [1/1], Batch [14860/30000], Loss: 2.1680\n",
      "Epoch [1/1], Batch [14870/30000], Loss: 2.2041\n",
      "Epoch [1/1], Batch [14880/30000], Loss: 2.3223\n",
      "Epoch [1/1], Batch [14890/30000], Loss: 2.2070\n",
      "Epoch [1/1], Batch [14900/30000], Loss: 2.3242\n",
      "Epoch [1/1], Batch [14910/30000], Loss: 2.3574\n",
      "Epoch [1/1], Batch [14920/30000], Loss: 2.2139\n",
      "Epoch [1/1], Batch [14930/30000], Loss: 2.3135\n",
      "Epoch [1/1], Batch [14940/30000], Loss: 2.4600\n",
      "Epoch [1/1], Batch [14950/30000], Loss: 2.1592\n",
      "Epoch [1/1], Batch [14960/30000], Loss: 2.2725\n",
      "Epoch [1/1], Batch [14970/30000], Loss: 2.3242\n",
      "Epoch [1/1], Batch [14980/30000], Loss: 2.3496\n",
      "Epoch [1/1], Batch [14990/30000], Loss: 2.3662\n",
      "Epoch [1/1], Batch [15000/30000], Loss: 2.3105\n",
      "Epoch [1/1], Batch [15010/30000], Loss: 2.2910\n",
      "Epoch [1/1], Batch [15020/30000], Loss: 2.3477\n",
      "Epoch [1/1], Batch [15030/30000], Loss: 2.4238\n",
      "Epoch [1/1], Batch [15040/30000], Loss: 2.3115\n",
      "Epoch [1/1], Batch [15050/30000], Loss: 2.3711\n",
      "Epoch [1/1], Batch [15060/30000], Loss: 2.3633\n",
      "Epoch [1/1], Batch [15070/30000], Loss: 2.2891\n",
      "Epoch [1/1], Batch [15080/30000], Loss: 2.3320\n",
      "Epoch [1/1], Batch [15090/30000], Loss: 2.2734\n",
      "Epoch [1/1], Batch [15100/30000], Loss: 2.3096\n",
      "Epoch [1/1], Batch [15110/30000], Loss: 2.3477\n",
      "Epoch [1/1], Batch [15120/30000], Loss: 2.2578\n",
      "Epoch [1/1], Batch [15130/30000], Loss: 2.0679\n",
      "Epoch [1/1], Batch [15140/30000], Loss: 2.1719\n",
      "Epoch [1/1], Batch [15150/30000], Loss: 2.4023\n",
      "Epoch [1/1], Batch [15160/30000], Loss: 2.3047\n",
      "Epoch [1/1], Batch [15170/30000], Loss: 2.2695\n",
      "Epoch [1/1], Batch [15180/30000], Loss: 2.3789\n",
      "Epoch [1/1], Batch [15190/30000], Loss: 2.2285\n",
      "Epoch [1/1], Batch [15200/30000], Loss: 2.1719\n",
      "Epoch [1/1], Batch [15210/30000], Loss: 2.2480\n",
      "Epoch [1/1], Batch [15220/30000], Loss: 2.3037\n",
      "Epoch [1/1], Batch [15230/30000], Loss: 2.4590\n",
      "Epoch [1/1], Batch [15240/30000], Loss: 2.4336\n",
      "Epoch [1/1], Batch [15250/30000], Loss: 2.3770\n",
      "Epoch [1/1], Batch [15260/30000], Loss: 2.3965\n",
      "Epoch [1/1], Batch [15270/30000], Loss: 2.3555\n",
      "Epoch [1/1], Batch [15280/30000], Loss: 2.3291\n",
      "Epoch [1/1], Batch [15290/30000], Loss: 2.1953\n",
      "Epoch [1/1], Batch [15300/30000], Loss: 2.2979\n",
      "Epoch [1/1], Batch [15310/30000], Loss: 2.2207\n",
      "Epoch [1/1], Batch [15320/30000], Loss: 2.2002\n",
      "Epoch [1/1], Batch [15330/30000], Loss: 2.4346\n",
      "Epoch [1/1], Batch [15340/30000], Loss: 2.1416\n",
      "Epoch [1/1], Batch [15350/30000], Loss: 2.3877\n",
      "Epoch [1/1], Batch [15360/30000], Loss: 1.9258\n",
      "Epoch [1/1], Batch [15370/30000], Loss: 2.1006\n",
      "Epoch [1/1], Batch [15380/30000], Loss: 2.3984\n",
      "Epoch [1/1], Batch [15390/30000], Loss: 2.3682\n",
      "Epoch [1/1], Batch [15400/30000], Loss: 2.3838\n",
      "Epoch [1/1], Batch [15410/30000], Loss: 2.3857\n",
      "Epoch [1/1], Batch [15420/30000], Loss: 2.2363\n",
      "Epoch [1/1], Batch [15430/30000], Loss: 2.3916\n",
      "Epoch [1/1], Batch [15440/30000], Loss: 2.3936\n",
      "Epoch [1/1], Batch [15450/30000], Loss: 2.3486\n",
      "Epoch [1/1], Batch [15460/30000], Loss: 2.2480\n",
      "Epoch [1/1], Batch [15470/30000], Loss: 2.3359\n",
      "Epoch [1/1], Batch [15480/30000], Loss: 2.3252\n",
      "Epoch [1/1], Batch [15490/30000], Loss: 2.4834\n",
      "Epoch [1/1], Batch [15500/30000], Loss: 2.2402\n",
      "Epoch [1/1], Batch [15510/30000], Loss: 2.3154\n",
      "Epoch [1/1], Batch [15520/30000], Loss: 2.2305\n",
      "Epoch [1/1], Batch [15530/30000], Loss: 2.2930\n",
      "Epoch [1/1], Batch [15540/30000], Loss: 2.2559\n",
      "Epoch [1/1], Batch [15550/30000], Loss: 2.3428\n",
      "Epoch [1/1], Batch [15560/30000], Loss: 2.2764\n",
      "Epoch [1/1], Batch [15570/30000], Loss: 2.2510\n",
      "Epoch [1/1], Batch [15580/30000], Loss: 2.4307\n",
      "Epoch [1/1], Batch [15590/30000], Loss: 2.3457\n",
      "Epoch [1/1], Batch [15600/30000], Loss: 2.2070\n",
      "Epoch [1/1], Batch [15610/30000], Loss: 2.2510\n",
      "Epoch [1/1], Batch [15620/30000], Loss: 2.1592\n",
      "Epoch [1/1], Batch [15630/30000], Loss: 2.2930\n",
      "Epoch [1/1], Batch [15640/30000], Loss: 2.2285\n",
      "Epoch [1/1], Batch [15650/30000], Loss: 2.2012\n",
      "Epoch [1/1], Batch [15660/30000], Loss: 2.3672\n",
      "Epoch [1/1], Batch [15670/30000], Loss: 2.1895\n",
      "Epoch [1/1], Batch [15680/30000], Loss: 2.3701\n",
      "Epoch [1/1], Batch [15690/30000], Loss: 2.3945\n",
      "Epoch [1/1], Batch [15700/30000], Loss: 2.3965\n",
      "Epoch [1/1], Batch [15710/30000], Loss: 2.2773\n",
      "Epoch [1/1], Batch [15720/30000], Loss: 2.3145\n",
      "Epoch [1/1], Batch [15730/30000], Loss: 2.2578\n",
      "Epoch [1/1], Batch [15740/30000], Loss: 2.4082\n",
      "Epoch [1/1], Batch [15750/30000], Loss: 2.3145\n",
      "Epoch [1/1], Batch [15760/30000], Loss: 2.2461\n",
      "Epoch [1/1], Batch [15770/30000], Loss: 2.3184\n",
      "Epoch [1/1], Batch [15780/30000], Loss: 2.3643\n",
      "Epoch [1/1], Batch [15790/30000], Loss: 2.3467\n",
      "Epoch [1/1], Batch [15800/30000], Loss: 2.0747\n",
      "Epoch [1/1], Batch [15810/30000], Loss: 2.2197\n",
      "Epoch [1/1], Batch [15820/30000], Loss: 2.2080\n",
      "Epoch [1/1], Batch [15830/30000], Loss: 2.3242\n",
      "Epoch [1/1], Batch [15840/30000], Loss: 2.4961\n",
      "Epoch [1/1], Batch [15850/30000], Loss: 2.3896\n",
      "Epoch [1/1], Batch [15860/30000], Loss: 2.4072\n",
      "Epoch [1/1], Batch [15870/30000], Loss: 2.2686\n",
      "Epoch [1/1], Batch [15880/30000], Loss: 2.3682\n",
      "Epoch [1/1], Batch [15890/30000], Loss: 2.2168\n",
      "Epoch [1/1], Batch [15900/30000], Loss: 2.1592\n",
      "Epoch [1/1], Batch [15910/30000], Loss: 2.4414\n",
      "Epoch [1/1], Batch [15920/30000], Loss: 2.3496\n",
      "Epoch [1/1], Batch [15930/30000], Loss: 2.2158\n",
      "Epoch [1/1], Batch [15940/30000], Loss: 2.3799\n",
      "Epoch [1/1], Batch [15950/30000], Loss: 2.2012\n",
      "Epoch [1/1], Batch [15960/30000], Loss: 2.5205\n",
      "Epoch [1/1], Batch [15970/30000], Loss: 2.6865\n",
      "Epoch [1/1], Batch [15980/30000], Loss: 2.2188\n",
      "Epoch [1/1], Batch [15990/30000], Loss: 2.3457\n",
      "Epoch [1/1], Batch [16000/30000], Loss: 2.5029\n",
      "Epoch [1/1], Batch [16010/30000], Loss: 2.3242\n",
      "Epoch [1/1], Batch [16020/30000], Loss: 2.2109\n",
      "Epoch [1/1], Batch [16030/30000], Loss: 2.4902\n",
      "Epoch [1/1], Batch [16040/30000], Loss: 2.1445\n",
      "Epoch [1/1], Batch [16050/30000], Loss: 2.5312\n",
      "Epoch [1/1], Batch [16060/30000], Loss: 2.3057\n",
      "Epoch [1/1], Batch [16070/30000], Loss: 2.2959\n",
      "Epoch [1/1], Batch [16080/30000], Loss: 2.2930\n",
      "Epoch [1/1], Batch [16090/30000], Loss: 2.2334\n",
      "Epoch [1/1], Batch [16100/30000], Loss: 2.1816\n",
      "Epoch [1/1], Batch [16110/30000], Loss: 2.2148\n",
      "Epoch [1/1], Batch [16120/30000], Loss: 2.4131\n",
      "Epoch [1/1], Batch [16130/30000], Loss: 2.3223\n",
      "Epoch [1/1], Batch [16140/30000], Loss: 2.2891\n",
      "Epoch [1/1], Batch [16150/30000], Loss: 2.2920\n",
      "Epoch [1/1], Batch [16160/30000], Loss: 2.1816\n",
      "Epoch [1/1], Batch [16170/30000], Loss: 2.5166\n",
      "Epoch [1/1], Batch [16180/30000], Loss: 2.4531\n",
      "Epoch [1/1], Batch [16190/30000], Loss: 2.2471\n",
      "Epoch [1/1], Batch [16200/30000], Loss: 2.3379\n",
      "Epoch [1/1], Batch [16210/30000], Loss: 2.4893\n",
      "Epoch [1/1], Batch [16220/30000], Loss: 2.2451\n",
      "Epoch [1/1], Batch [16230/30000], Loss: 2.3564\n",
      "Epoch [1/1], Batch [16240/30000], Loss: 2.4766\n",
      "Epoch [1/1], Batch [16250/30000], Loss: 2.2988\n",
      "Epoch [1/1], Batch [16260/30000], Loss: 2.5703\n",
      "Epoch [1/1], Batch [16270/30000], Loss: 2.3652\n",
      "Epoch [1/1], Batch [16280/30000], Loss: 2.2012\n",
      "Epoch [1/1], Batch [16290/30000], Loss: 2.3682\n",
      "Epoch [1/1], Batch [16300/30000], Loss: 2.2803\n",
      "Epoch [1/1], Batch [16310/30000], Loss: 2.2510\n",
      "Epoch [1/1], Batch [16320/30000], Loss: 2.2275\n",
      "Epoch [1/1], Batch [16330/30000], Loss: 2.4463\n",
      "Epoch [1/1], Batch [16340/30000], Loss: 2.3076\n",
      "Epoch [1/1], Batch [16350/30000], Loss: 2.3496\n",
      "Epoch [1/1], Batch [16360/30000], Loss: 2.3340\n",
      "Epoch [1/1], Batch [16370/30000], Loss: 2.1953\n",
      "Epoch [1/1], Batch [16380/30000], Loss: 2.2695\n",
      "Epoch [1/1], Batch [16390/30000], Loss: 2.1973\n",
      "Epoch [1/1], Batch [16400/30000], Loss: 2.1816\n",
      "Epoch [1/1], Batch [16410/30000], Loss: 2.1538\n",
      "Epoch [1/1], Batch [16420/30000], Loss: 2.8691\n",
      "Epoch [1/1], Batch [16430/30000], Loss: 2.2734\n",
      "Epoch [1/1], Batch [16440/30000], Loss: 2.2441\n",
      "Epoch [1/1], Batch [16450/30000], Loss: 2.1982\n",
      "Epoch [1/1], Batch [16460/30000], Loss: 2.2266\n",
      "Epoch [1/1], Batch [16470/30000], Loss: 2.2383\n",
      "Epoch [1/1], Batch [16480/30000], Loss: 2.1758\n",
      "Epoch [1/1], Batch [16490/30000], Loss: 2.2344\n",
      "Epoch [1/1], Batch [16500/30000], Loss: 2.6045\n",
      "Epoch [1/1], Batch [16510/30000], Loss: 2.3682\n",
      "Epoch [1/1], Batch [16520/30000], Loss: 2.2373\n",
      "Epoch [1/1], Batch [16530/30000], Loss: 2.6504\n",
      "Epoch [1/1], Batch [16540/30000], Loss: 2.3516\n",
      "Epoch [1/1], Batch [16550/30000], Loss: 2.2656\n",
      "Epoch [1/1], Batch [16560/30000], Loss: 2.4082\n",
      "Epoch [1/1], Batch [16570/30000], Loss: 2.2969\n",
      "Epoch [1/1], Batch [16580/30000], Loss: 2.2900\n",
      "Epoch [1/1], Batch [16590/30000], Loss: 2.3389\n",
      "Epoch [1/1], Batch [16600/30000], Loss: 2.2793\n",
      "Epoch [1/1], Batch [16610/30000], Loss: 2.2324\n",
      "Epoch [1/1], Batch [16620/30000], Loss: 2.2109\n",
      "Epoch [1/1], Batch [16630/30000], Loss: 2.2207\n",
      "Epoch [1/1], Batch [16640/30000], Loss: 2.4121\n",
      "Epoch [1/1], Batch [16650/30000], Loss: 2.3486\n",
      "Epoch [1/1], Batch [16660/30000], Loss: 2.2256\n",
      "Epoch [1/1], Batch [16670/30000], Loss: 2.3828\n",
      "Epoch [1/1], Batch [16680/30000], Loss: 2.3701\n",
      "Epoch [1/1], Batch [16690/30000], Loss: 2.1182\n",
      "Epoch [1/1], Batch [16700/30000], Loss: 2.5156\n",
      "Epoch [1/1], Batch [16710/30000], Loss: 2.2148\n",
      "Epoch [1/1], Batch [16720/30000], Loss: 2.2646\n",
      "Epoch [1/1], Batch [16730/30000], Loss: 2.2197\n",
      "Epoch [1/1], Batch [16740/30000], Loss: 2.5352\n",
      "Epoch [1/1], Batch [16750/30000], Loss: 2.2539\n",
      "Epoch [1/1], Batch [16760/30000], Loss: 2.2871\n",
      "Epoch [1/1], Batch [16770/30000], Loss: 2.1865\n",
      "Epoch [1/1], Batch [16780/30000], Loss: 2.3135\n",
      "Epoch [1/1], Batch [16790/30000], Loss: 2.2275\n",
      "Epoch [1/1], Batch [16800/30000], Loss: 2.4941\n",
      "Epoch [1/1], Batch [16810/30000], Loss: 2.1011\n",
      "Epoch [1/1], Batch [16820/30000], Loss: 2.4873\n",
      "Epoch [1/1], Batch [16830/30000], Loss: 2.3008\n",
      "Epoch [1/1], Batch [16840/30000], Loss: 2.3398\n",
      "Epoch [1/1], Batch [16850/30000], Loss: 2.3203\n",
      "Epoch [1/1], Batch [16860/30000], Loss: 2.1250\n",
      "Epoch [1/1], Batch [16870/30000], Loss: 2.2969\n",
      "Epoch [1/1], Batch [16880/30000], Loss: 2.2803\n",
      "Epoch [1/1], Batch [16890/30000], Loss: 2.3379\n",
      "Epoch [1/1], Batch [16900/30000], Loss: 2.1777\n",
      "Epoch [1/1], Batch [16910/30000], Loss: 2.1562\n",
      "Epoch [1/1], Batch [16920/30000], Loss: 2.3398\n",
      "Epoch [1/1], Batch [16930/30000], Loss: 2.4209\n",
      "Epoch [1/1], Batch [16940/30000], Loss: 2.3262\n",
      "Epoch [1/1], Batch [16950/30000], Loss: 2.0938\n",
      "Epoch [1/1], Batch [16960/30000], Loss: 2.2236\n",
      "Epoch [1/1], Batch [16970/30000], Loss: 2.3447\n",
      "Epoch [1/1], Batch [16980/30000], Loss: 2.4043\n",
      "Epoch [1/1], Batch [16990/30000], Loss: 2.1973\n",
      "Epoch [1/1], Batch [17000/30000], Loss: 2.2461\n",
      "Epoch [1/1], Batch [17010/30000], Loss: 2.3730\n",
      "Epoch [1/1], Batch [17020/30000], Loss: 2.2559\n",
      "Epoch [1/1], Batch [17030/30000], Loss: 2.4521\n",
      "Epoch [1/1], Batch [17040/30000], Loss: 2.3174\n",
      "Epoch [1/1], Batch [17050/30000], Loss: 2.3564\n",
      "Epoch [1/1], Batch [17060/30000], Loss: 2.3516\n",
      "Epoch [1/1], Batch [17070/30000], Loss: 2.2568\n",
      "Epoch [1/1], Batch [17080/30000], Loss: 2.3164\n",
      "Epoch [1/1], Batch [17090/30000], Loss: 2.2227\n",
      "Epoch [1/1], Batch [17100/30000], Loss: 2.2324\n",
      "Epoch [1/1], Batch [17110/30000], Loss: 2.3174\n",
      "Epoch [1/1], Batch [17120/30000], Loss: 2.3896\n",
      "Epoch [1/1], Batch [17130/30000], Loss: 2.3838\n",
      "Epoch [1/1], Batch [17140/30000], Loss: 2.3291\n",
      "Epoch [1/1], Batch [17150/30000], Loss: 2.4473\n",
      "Epoch [1/1], Batch [17160/30000], Loss: 2.3555\n",
      "Epoch [1/1], Batch [17170/30000], Loss: 2.2002\n",
      "Epoch [1/1], Batch [17180/30000], Loss: 2.4160\n",
      "Epoch [1/1], Batch [17190/30000], Loss: 2.1992\n",
      "Epoch [1/1], Batch [17200/30000], Loss: 2.3076\n",
      "Epoch [1/1], Batch [17210/30000], Loss: 2.2578\n",
      "Epoch [1/1], Batch [17220/30000], Loss: 2.3311\n",
      "Epoch [1/1], Batch [17230/30000], Loss: 2.3604\n",
      "Epoch [1/1], Batch [17240/30000], Loss: 2.1602\n",
      "Epoch [1/1], Batch [17250/30000], Loss: 2.3506\n",
      "Epoch [1/1], Batch [17260/30000], Loss: 2.3721\n",
      "Epoch [1/1], Batch [17270/30000], Loss: 2.2852\n",
      "Epoch [1/1], Batch [17280/30000], Loss: 2.2637\n",
      "Epoch [1/1], Batch [17290/30000], Loss: 2.1201\n",
      "Epoch [1/1], Batch [17300/30000], Loss: 2.2319\n",
      "Epoch [1/1], Batch [17310/30000], Loss: 2.3799\n",
      "Epoch [1/1], Batch [17320/30000], Loss: 2.3955\n",
      "Epoch [1/1], Batch [17330/30000], Loss: 2.2568\n",
      "Epoch [1/1], Batch [17340/30000], Loss: 2.4541\n",
      "Epoch [1/1], Batch [17350/30000], Loss: 2.3594\n",
      "Epoch [1/1], Batch [17360/30000], Loss: 2.1865\n",
      "Epoch [1/1], Batch [17370/30000], Loss: 2.2764\n",
      "Epoch [1/1], Batch [17380/30000], Loss: 2.4424\n",
      "Epoch [1/1], Batch [17390/30000], Loss: 2.1582\n",
      "Epoch [1/1], Batch [17400/30000], Loss: 2.2520\n",
      "Epoch [1/1], Batch [17410/30000], Loss: 2.2793\n",
      "Epoch [1/1], Batch [17420/30000], Loss: 2.3408\n",
      "Epoch [1/1], Batch [17430/30000], Loss: 2.4697\n",
      "Epoch [1/1], Batch [17440/30000], Loss: 2.1104\n",
      "Epoch [1/1], Batch [17450/30000], Loss: 2.2842\n",
      "Epoch [1/1], Batch [17460/30000], Loss: 2.1768\n",
      "Epoch [1/1], Batch [17470/30000], Loss: 2.2295\n",
      "Epoch [1/1], Batch [17480/30000], Loss: 2.2500\n",
      "Epoch [1/1], Batch [17490/30000], Loss: 2.3223\n",
      "Epoch [1/1], Batch [17500/30000], Loss: 2.3535\n",
      "Epoch [1/1], Batch [17510/30000], Loss: 2.2520\n",
      "Epoch [1/1], Batch [17520/30000], Loss: 2.3848\n",
      "Epoch [1/1], Batch [17530/30000], Loss: 2.3652\n",
      "Epoch [1/1], Batch [17540/30000], Loss: 2.3682\n",
      "Epoch [1/1], Batch [17550/30000], Loss: 2.2178\n",
      "Epoch [1/1], Batch [17560/30000], Loss: 2.3330\n",
      "Epoch [1/1], Batch [17570/30000], Loss: 2.3867\n",
      "Epoch [1/1], Batch [17580/30000], Loss: 2.2412\n",
      "Epoch [1/1], Batch [17590/30000], Loss: 2.2881\n",
      "Epoch [1/1], Batch [17600/30000], Loss: 2.2139\n",
      "Epoch [1/1], Batch [17610/30000], Loss: 2.2637\n",
      "Epoch [1/1], Batch [17620/30000], Loss: 2.2637\n",
      "Epoch [1/1], Batch [17630/30000], Loss: 2.2256\n",
      "Epoch [1/1], Batch [17640/30000], Loss: 2.2783\n",
      "Epoch [1/1], Batch [17650/30000], Loss: 2.3174\n",
      "Epoch [1/1], Batch [17660/30000], Loss: 2.2666\n",
      "Epoch [1/1], Batch [17670/30000], Loss: 2.3604\n",
      "Epoch [1/1], Batch [17680/30000], Loss: 2.2529\n",
      "Epoch [1/1], Batch [17690/30000], Loss: 2.4180\n",
      "Epoch [1/1], Batch [17700/30000], Loss: 2.2617\n",
      "Epoch [1/1], Batch [17710/30000], Loss: 2.3428\n",
      "Epoch [1/1], Batch [17720/30000], Loss: 2.2861\n",
      "Epoch [1/1], Batch [17730/30000], Loss: 2.3438\n",
      "Epoch [1/1], Batch [17740/30000], Loss: 2.3008\n",
      "Epoch [1/1], Batch [17750/30000], Loss: 2.3047\n",
      "Epoch [1/1], Batch [17760/30000], Loss: 2.3262\n",
      "Epoch [1/1], Batch [17770/30000], Loss: 2.3984\n",
      "Epoch [1/1], Batch [17780/30000], Loss: 2.3750\n",
      "Epoch [1/1], Batch [17790/30000], Loss: 2.1704\n",
      "Epoch [1/1], Batch [17800/30000], Loss: 2.3057\n",
      "Epoch [1/1], Batch [17810/30000], Loss: 1.9683\n",
      "Epoch [1/1], Batch [17820/30000], Loss: 2.3359\n",
      "Epoch [1/1], Batch [17830/30000], Loss: 2.0493\n",
      "Epoch [1/1], Batch [17840/30000], Loss: 2.2319\n",
      "Epoch [1/1], Batch [17850/30000], Loss: 2.3672\n",
      "Epoch [1/1], Batch [17860/30000], Loss: 2.2324\n",
      "Epoch [1/1], Batch [17870/30000], Loss: 2.4570\n",
      "Epoch [1/1], Batch [17880/30000], Loss: 2.4385\n",
      "Epoch [1/1], Batch [17890/30000], Loss: 2.3662\n",
      "Epoch [1/1], Batch [17900/30000], Loss: 2.3232\n",
      "Epoch [1/1], Batch [17910/30000], Loss: 2.2920\n",
      "Epoch [1/1], Batch [17920/30000], Loss: 2.3252\n",
      "Epoch [1/1], Batch [17930/30000], Loss: 2.3740\n",
      "Epoch [1/1], Batch [17940/30000], Loss: 2.3408\n",
      "Epoch [1/1], Batch [17950/30000], Loss: 2.3486\n",
      "Epoch [1/1], Batch [17960/30000], Loss: 2.3164\n",
      "Epoch [1/1], Batch [17970/30000], Loss: 2.3574\n",
      "Epoch [1/1], Batch [17980/30000], Loss: 2.3066\n",
      "Epoch [1/1], Batch [17990/30000], Loss: 2.2842\n",
      "Epoch [1/1], Batch [18000/30000], Loss: 2.1846\n",
      "Epoch [1/1], Batch [18010/30000], Loss: 2.4307\n",
      "Epoch [1/1], Batch [18020/30000], Loss: 2.3496\n",
      "Epoch [1/1], Batch [18030/30000], Loss: 2.3369\n",
      "Epoch [1/1], Batch [18040/30000], Loss: 2.3799\n",
      "Epoch [1/1], Batch [18050/30000], Loss: 2.3389\n",
      "Epoch [1/1], Batch [18060/30000], Loss: 2.2012\n",
      "Epoch [1/1], Batch [18070/30000], Loss: 2.3496\n",
      "Epoch [1/1], Batch [18080/30000], Loss: 2.2979\n",
      "Epoch [1/1], Batch [18090/30000], Loss: 2.2432\n",
      "Epoch [1/1], Batch [18100/30000], Loss: 2.3486\n",
      "Epoch [1/1], Batch [18110/30000], Loss: 2.4766\n",
      "Epoch [1/1], Batch [18120/30000], Loss: 2.2324\n",
      "Epoch [1/1], Batch [18130/30000], Loss: 2.2695\n",
      "Epoch [1/1], Batch [18140/30000], Loss: 2.4082\n",
      "Epoch [1/1], Batch [18150/30000], Loss: 2.2129\n",
      "Epoch [1/1], Batch [18160/30000], Loss: 2.2617\n",
      "Epoch [1/1], Batch [18170/30000], Loss: 2.3252\n",
      "Epoch [1/1], Batch [18180/30000], Loss: 2.2705\n",
      "Epoch [1/1], Batch [18190/30000], Loss: 2.3008\n",
      "Epoch [1/1], Batch [18200/30000], Loss: 2.2412\n",
      "Epoch [1/1], Batch [18210/30000], Loss: 2.2715\n",
      "Epoch [1/1], Batch [18220/30000], Loss: 2.3652\n",
      "Epoch [1/1], Batch [18230/30000], Loss: 2.3320\n",
      "Epoch [1/1], Batch [18240/30000], Loss: 2.4072\n",
      "Epoch [1/1], Batch [18250/30000], Loss: 2.1719\n",
      "Epoch [1/1], Batch [18260/30000], Loss: 2.3809\n",
      "Epoch [1/1], Batch [18270/30000], Loss: 2.2754\n",
      "Epoch [1/1], Batch [18280/30000], Loss: 2.2305\n",
      "Epoch [1/1], Batch [18290/30000], Loss: 2.3633\n",
      "Epoch [1/1], Batch [18300/30000], Loss: 2.1846\n",
      "Epoch [1/1], Batch [18310/30000], Loss: 2.1113\n",
      "Epoch [1/1], Batch [18320/30000], Loss: 2.3271\n",
      "Epoch [1/1], Batch [18330/30000], Loss: 2.4277\n",
      "Epoch [1/1], Batch [18340/30000], Loss: 2.3799\n",
      "Epoch [1/1], Batch [18350/30000], Loss: 2.2969\n",
      "Epoch [1/1], Batch [18360/30000], Loss: 2.3486\n",
      "Epoch [1/1], Batch [18370/30000], Loss: 2.2998\n",
      "Epoch [1/1], Batch [18380/30000], Loss: 2.2930\n",
      "Epoch [1/1], Batch [18390/30000], Loss: 2.1816\n",
      "Epoch [1/1], Batch [18400/30000], Loss: 2.2754\n",
      "Epoch [1/1], Batch [18410/30000], Loss: 2.3486\n",
      "Epoch [1/1], Batch [18420/30000], Loss: 2.3760\n",
      "Epoch [1/1], Batch [18430/30000], Loss: 2.3164\n",
      "Epoch [1/1], Batch [18440/30000], Loss: 2.3262\n",
      "Epoch [1/1], Batch [18450/30000], Loss: 2.3535\n",
      "Epoch [1/1], Batch [18460/30000], Loss: 2.2061\n",
      "Epoch [1/1], Batch [18470/30000], Loss: 2.2568\n",
      "Epoch [1/1], Batch [18480/30000], Loss: 2.2080\n",
      "Epoch [1/1], Batch [18490/30000], Loss: 2.2188\n",
      "Epoch [1/1], Batch [18500/30000], Loss: 2.2529\n",
      "Epoch [1/1], Batch [18510/30000], Loss: 2.5117\n",
      "Epoch [1/1], Batch [18520/30000], Loss: 2.5117\n",
      "Epoch [1/1], Batch [18530/30000], Loss: 2.5547\n",
      "Epoch [1/1], Batch [18540/30000], Loss: 2.2246\n",
      "Epoch [1/1], Batch [18550/30000], Loss: 2.4551\n",
      "Epoch [1/1], Batch [18560/30000], Loss: 2.3242\n",
      "Epoch [1/1], Batch [18570/30000], Loss: 2.2822\n",
      "Epoch [1/1], Batch [18580/30000], Loss: 2.3682\n",
      "Epoch [1/1], Batch [18590/30000], Loss: 2.3145\n",
      "Epoch [1/1], Batch [18600/30000], Loss: 2.0381\n",
      "Epoch [1/1], Batch [18610/30000], Loss: 2.1362\n",
      "Epoch [1/1], Batch [18620/30000], Loss: 2.3105\n",
      "Epoch [1/1], Batch [18630/30000], Loss: 2.4639\n",
      "Epoch [1/1], Batch [18640/30000], Loss: 2.4600\n",
      "Epoch [1/1], Batch [18650/30000], Loss: 2.3291\n",
      "Epoch [1/1], Batch [18660/30000], Loss: 2.2559\n",
      "Epoch [1/1], Batch [18670/30000], Loss: 2.4258\n",
      "Epoch [1/1], Batch [18680/30000], Loss: 2.5508\n",
      "Epoch [1/1], Batch [18690/30000], Loss: 2.2900\n",
      "Epoch [1/1], Batch [18700/30000], Loss: 2.4590\n",
      "Epoch [1/1], Batch [18710/30000], Loss: 2.4541\n",
      "Epoch [1/1], Batch [18720/30000], Loss: 2.3330\n",
      "Epoch [1/1], Batch [18730/30000], Loss: 2.3506\n",
      "Epoch [1/1], Batch [18740/30000], Loss: 2.3711\n",
      "Epoch [1/1], Batch [18750/30000], Loss: 2.3535\n",
      "Epoch [1/1], Batch [18760/30000], Loss: 2.3145\n",
      "Epoch [1/1], Batch [18770/30000], Loss: 2.3184\n",
      "Epoch [1/1], Batch [18780/30000], Loss: 2.3301\n",
      "Epoch [1/1], Batch [18790/30000], Loss: 2.3789\n",
      "Epoch [1/1], Batch [18800/30000], Loss: 2.4619\n",
      "Epoch [1/1], Batch [18810/30000], Loss: 2.1143\n",
      "Epoch [1/1], Batch [18820/30000], Loss: 2.1699\n",
      "Epoch [1/1], Batch [18830/30000], Loss: 2.3379\n",
      "Epoch [1/1], Batch [18840/30000], Loss: 2.1768\n",
      "Epoch [1/1], Batch [18850/30000], Loss: 2.1040\n",
      "Epoch [1/1], Batch [18860/30000], Loss: 2.2021\n",
      "Epoch [1/1], Batch [18870/30000], Loss: 2.2998\n",
      "Epoch [1/1], Batch [18880/30000], Loss: 2.3018\n",
      "Epoch [1/1], Batch [18890/30000], Loss: 2.0679\n",
      "Epoch [1/1], Batch [18900/30000], Loss: 2.2461\n",
      "Epoch [1/1], Batch [18910/30000], Loss: 2.4404\n",
      "Epoch [1/1], Batch [18920/30000], Loss: 2.2246\n",
      "Epoch [1/1], Batch [18930/30000], Loss: 2.3779\n",
      "Epoch [1/1], Batch [18940/30000], Loss: 2.3867\n",
      "Epoch [1/1], Batch [18950/30000], Loss: 2.3965\n",
      "Epoch [1/1], Batch [18960/30000], Loss: 2.2529\n",
      "Epoch [1/1], Batch [18970/30000], Loss: 2.3350\n",
      "Epoch [1/1], Batch [18980/30000], Loss: 2.3105\n",
      "Epoch [1/1], Batch [18990/30000], Loss: 2.2529\n",
      "Epoch [1/1], Batch [19000/30000], Loss: 2.4141\n",
      "Epoch [1/1], Batch [19010/30000], Loss: 2.4170\n",
      "Epoch [1/1], Batch [19020/30000], Loss: 2.2744\n",
      "Epoch [1/1], Batch [19030/30000], Loss: 2.2812\n",
      "Epoch [1/1], Batch [19040/30000], Loss: 2.2500\n",
      "Epoch [1/1], Batch [19050/30000], Loss: 2.7080\n",
      "Epoch [1/1], Batch [19060/30000], Loss: 2.4404\n",
      "Epoch [1/1], Batch [19070/30000], Loss: 2.1836\n",
      "Epoch [1/1], Batch [19080/30000], Loss: 2.3213\n",
      "Epoch [1/1], Batch [19090/30000], Loss: 2.4219\n",
      "Epoch [1/1], Batch [19100/30000], Loss: 2.2422\n",
      "Epoch [1/1], Batch [19110/30000], Loss: 2.2969\n",
      "Epoch [1/1], Batch [19120/30000], Loss: 2.3398\n",
      "Epoch [1/1], Batch [19130/30000], Loss: 2.3447\n",
      "Epoch [1/1], Batch [19140/30000], Loss: 2.4033\n",
      "Epoch [1/1], Batch [19150/30000], Loss: 2.4219\n",
      "Epoch [1/1], Batch [19160/30000], Loss: 2.4297\n",
      "Epoch [1/1], Batch [19170/30000], Loss: 2.4102\n",
      "Epoch [1/1], Batch [19180/30000], Loss: 2.2686\n",
      "Epoch [1/1], Batch [19190/30000], Loss: 2.3545\n",
      "Epoch [1/1], Batch [19200/30000], Loss: 2.3281\n",
      "Epoch [1/1], Batch [19210/30000], Loss: 2.3359\n",
      "Epoch [1/1], Batch [19220/30000], Loss: 2.3779\n",
      "Epoch [1/1], Batch [19230/30000], Loss: 2.1680\n",
      "Epoch [1/1], Batch [19240/30000], Loss: 2.2227\n",
      "Epoch [1/1], Batch [19250/30000], Loss: 2.3086\n",
      "Epoch [1/1], Batch [19260/30000], Loss: 2.3154\n",
      "Epoch [1/1], Batch [19270/30000], Loss: 2.2793\n",
      "Epoch [1/1], Batch [19280/30000], Loss: 2.4287\n",
      "Epoch [1/1], Batch [19290/30000], Loss: 2.3984\n",
      "Epoch [1/1], Batch [19300/30000], Loss: 2.3652\n",
      "Epoch [1/1], Batch [19310/30000], Loss: 2.2207\n",
      "Epoch [1/1], Batch [19320/30000], Loss: 2.3242\n",
      "Epoch [1/1], Batch [19330/30000], Loss: 2.3555\n",
      "Epoch [1/1], Batch [19340/30000], Loss: 2.1650\n",
      "Epoch [1/1], Batch [19350/30000], Loss: 2.2061\n",
      "Epoch [1/1], Batch [19360/30000], Loss: 2.4141\n",
      "Epoch [1/1], Batch [19370/30000], Loss: 2.2627\n",
      "Epoch [1/1], Batch [19380/30000], Loss: 2.2676\n",
      "Epoch [1/1], Batch [19390/30000], Loss: 2.2471\n",
      "Epoch [1/1], Batch [19400/30000], Loss: 2.0918\n",
      "Epoch [1/1], Batch [19410/30000], Loss: 2.4199\n",
      "Epoch [1/1], Batch [19420/30000], Loss: 2.3262\n",
      "Epoch [1/1], Batch [19430/30000], Loss: 2.3262\n",
      "Epoch [1/1], Batch [19440/30000], Loss: 2.2998\n",
      "Epoch [1/1], Batch [19450/30000], Loss: 2.2861\n",
      "Epoch [1/1], Batch [19460/30000], Loss: 2.2490\n",
      "Epoch [1/1], Batch [19470/30000], Loss: 2.2090\n",
      "Epoch [1/1], Batch [19480/30000], Loss: 2.1826\n",
      "Epoch [1/1], Batch [19490/30000], Loss: 2.1797\n",
      "Epoch [1/1], Batch [19500/30000], Loss: 2.0830\n",
      "Epoch [1/1], Batch [19510/30000], Loss: 2.2686\n",
      "Epoch [1/1], Batch [19520/30000], Loss: 2.1992\n",
      "Epoch [1/1], Batch [19530/30000], Loss: 2.2402\n",
      "Epoch [1/1], Batch [19540/30000], Loss: 2.2217\n",
      "Epoch [1/1], Batch [19550/30000], Loss: 2.4326\n",
      "Epoch [1/1], Batch [19560/30000], Loss: 2.4561\n",
      "Epoch [1/1], Batch [19570/30000], Loss: 2.2422\n",
      "Epoch [1/1], Batch [19580/30000], Loss: 2.1201\n",
      "Epoch [1/1], Batch [19590/30000], Loss: 2.3574\n",
      "Epoch [1/1], Batch [19600/30000], Loss: 2.2510\n",
      "Epoch [1/1], Batch [19610/30000], Loss: 2.4121\n",
      "Epoch [1/1], Batch [19620/30000], Loss: 2.4824\n",
      "Epoch [1/1], Batch [19630/30000], Loss: 2.2334\n",
      "Epoch [1/1], Batch [19640/30000], Loss: 2.3018\n",
      "Epoch [1/1], Batch [19650/30000], Loss: 2.3301\n",
      "Epoch [1/1], Batch [19660/30000], Loss: 2.2803\n",
      "Epoch [1/1], Batch [19670/30000], Loss: 2.1777\n",
      "Epoch [1/1], Batch [19680/30000], Loss: 2.3301\n",
      "Epoch [1/1], Batch [19690/30000], Loss: 2.3408\n",
      "Epoch [1/1], Batch [19700/30000], Loss: 2.3564\n",
      "Epoch [1/1], Batch [19710/30000], Loss: 2.3887\n",
      "Epoch [1/1], Batch [19720/30000], Loss: 2.3096\n",
      "Epoch [1/1], Batch [19730/30000], Loss: 2.3242\n",
      "Epoch [1/1], Batch [19740/30000], Loss: 2.1719\n",
      "Epoch [1/1], Batch [19750/30000], Loss: 2.3164\n",
      "Epoch [1/1], Batch [19760/30000], Loss: 2.3643\n",
      "Epoch [1/1], Batch [19770/30000], Loss: 2.3389\n",
      "Epoch [1/1], Batch [19780/30000], Loss: 2.2373\n",
      "Epoch [1/1], Batch [19790/30000], Loss: 2.2803\n",
      "Epoch [1/1], Batch [19800/30000], Loss: 2.3203\n",
      "Epoch [1/1], Batch [19810/30000], Loss: 2.2295\n",
      "Epoch [1/1], Batch [19820/30000], Loss: 2.3135\n",
      "Epoch [1/1], Batch [19830/30000], Loss: 2.3789\n",
      "Epoch [1/1], Batch [19840/30000], Loss: 2.3115\n",
      "Epoch [1/1], Batch [19850/30000], Loss: 2.4092\n",
      "Epoch [1/1], Batch [19860/30000], Loss: 2.4697\n",
      "Epoch [1/1], Batch [19870/30000], Loss: 2.2041\n",
      "Epoch [1/1], Batch [19880/30000], Loss: 2.3389\n",
      "Epoch [1/1], Batch [19890/30000], Loss: 2.2139\n",
      "Epoch [1/1], Batch [19900/30000], Loss: 2.4541\n",
      "Epoch [1/1], Batch [19910/30000], Loss: 2.2949\n",
      "Epoch [1/1], Batch [19920/30000], Loss: 2.2617\n",
      "Epoch [1/1], Batch [19930/30000], Loss: 2.3057\n",
      "Epoch [1/1], Batch [19940/30000], Loss: 2.2686\n",
      "Epoch [1/1], Batch [19950/30000], Loss: 2.1875\n",
      "Epoch [1/1], Batch [19960/30000], Loss: 2.2998\n",
      "Epoch [1/1], Batch [19970/30000], Loss: 2.2139\n",
      "Epoch [1/1], Batch [19980/30000], Loss: 2.3213\n",
      "Epoch [1/1], Batch [19990/30000], Loss: 2.3066\n",
      "Epoch [1/1], Batch [20000/30000], Loss: 2.2207\n",
      "Epoch [1/1], Batch [20010/30000], Loss: 2.2383\n",
      "Epoch [1/1], Batch [20020/30000], Loss: 2.3291\n",
      "Epoch [1/1], Batch [20030/30000], Loss: 2.1621\n",
      "Epoch [1/1], Batch [20040/30000], Loss: 2.1304\n",
      "Epoch [1/1], Batch [20050/30000], Loss: 2.3506\n",
      "Epoch [1/1], Batch [20060/30000], Loss: 2.2637\n",
      "Epoch [1/1], Batch [20070/30000], Loss: 2.3096\n",
      "Epoch [1/1], Batch [20080/30000], Loss: 2.2959\n",
      "Epoch [1/1], Batch [20090/30000], Loss: 2.3779\n",
      "Epoch [1/1], Batch [20100/30000], Loss: 2.3086\n",
      "Epoch [1/1], Batch [20110/30000], Loss: 2.3623\n",
      "Epoch [1/1], Batch [20120/30000], Loss: 2.3066\n",
      "Epoch [1/1], Batch [20130/30000], Loss: 2.3203\n",
      "Epoch [1/1], Batch [20140/30000], Loss: 2.2490\n",
      "Epoch [1/1], Batch [20150/30000], Loss: 2.3711\n",
      "Epoch [1/1], Batch [20160/30000], Loss: 2.2910\n",
      "Epoch [1/1], Batch [20170/30000], Loss: 2.2783\n",
      "Epoch [1/1], Batch [20180/30000], Loss: 2.2471\n",
      "Epoch [1/1], Batch [20190/30000], Loss: 2.2881\n",
      "Epoch [1/1], Batch [20200/30000], Loss: 2.2910\n",
      "Epoch [1/1], Batch [20210/30000], Loss: 2.2900\n",
      "Epoch [1/1], Batch [20220/30000], Loss: 2.3076\n",
      "Epoch [1/1], Batch [20230/30000], Loss: 2.3408\n",
      "Epoch [1/1], Batch [20240/30000], Loss: 2.2588\n",
      "Epoch [1/1], Batch [20250/30000], Loss: 2.2305\n",
      "Epoch [1/1], Batch [20260/30000], Loss: 2.3984\n",
      "Epoch [1/1], Batch [20270/30000], Loss: 2.2617\n",
      "Epoch [1/1], Batch [20280/30000], Loss: 2.3975\n",
      "Epoch [1/1], Batch [20290/30000], Loss: 2.2246\n",
      "Epoch [1/1], Batch [20300/30000], Loss: 2.3467\n",
      "Epoch [1/1], Batch [20310/30000], Loss: 2.1533\n",
      "Epoch [1/1], Batch [20320/30000], Loss: 2.3652\n",
      "Epoch [1/1], Batch [20330/30000], Loss: 2.3018\n",
      "Epoch [1/1], Batch [20340/30000], Loss: 2.4600\n",
      "Epoch [1/1], Batch [20350/30000], Loss: 2.3828\n",
      "Epoch [1/1], Batch [20360/30000], Loss: 2.2754\n",
      "Epoch [1/1], Batch [20370/30000], Loss: 2.2607\n",
      "Epoch [1/1], Batch [20380/30000], Loss: 2.3848\n",
      "Epoch [1/1], Batch [20390/30000], Loss: 2.3086\n",
      "Epoch [1/1], Batch [20400/30000], Loss: 2.3027\n",
      "Epoch [1/1], Batch [20410/30000], Loss: 2.2129\n",
      "Epoch [1/1], Batch [20420/30000], Loss: 2.2305\n",
      "Epoch [1/1], Batch [20430/30000], Loss: 2.3359\n",
      "Epoch [1/1], Batch [20440/30000], Loss: 2.2656\n",
      "Epoch [1/1], Batch [20450/30000], Loss: 2.3066\n",
      "Epoch [1/1], Batch [20460/30000], Loss: 2.2939\n",
      "Epoch [1/1], Batch [20470/30000], Loss: 2.3359\n",
      "Epoch [1/1], Batch [20480/30000], Loss: 2.3125\n",
      "Epoch [1/1], Batch [20490/30000], Loss: 2.3428\n",
      "Epoch [1/1], Batch [20500/30000], Loss: 2.3223\n",
      "Epoch [1/1], Batch [20510/30000], Loss: 2.4775\n",
      "Epoch [1/1], Batch [20520/30000], Loss: 2.3857\n",
      "Epoch [1/1], Batch [20530/30000], Loss: 2.2920\n",
      "Epoch [1/1], Batch [20540/30000], Loss: 2.2568\n",
      "Epoch [1/1], Batch [20550/30000], Loss: 2.2285\n",
      "Epoch [1/1], Batch [20560/30000], Loss: 2.2568\n",
      "Epoch [1/1], Batch [20570/30000], Loss: 2.3809\n",
      "Epoch [1/1], Batch [20580/30000], Loss: 2.1650\n",
      "Epoch [1/1], Batch [20590/30000], Loss: 2.2344\n",
      "Epoch [1/1], Batch [20600/30000], Loss: 2.2354\n",
      "Epoch [1/1], Batch [20610/30000], Loss: 2.2832\n",
      "Epoch [1/1], Batch [20620/30000], Loss: 2.3672\n",
      "Epoch [1/1], Batch [20630/30000], Loss: 2.3164\n",
      "Epoch [1/1], Batch [20640/30000], Loss: 2.3486\n",
      "Epoch [1/1], Batch [20650/30000], Loss: 2.3105\n",
      "Epoch [1/1], Batch [20660/30000], Loss: 2.2266\n",
      "Epoch [1/1], Batch [20670/30000], Loss: 2.2900\n",
      "Epoch [1/1], Batch [20680/30000], Loss: 2.2266\n",
      "Epoch [1/1], Batch [20690/30000], Loss: 2.2920\n",
      "Epoch [1/1], Batch [20700/30000], Loss: 2.3057\n",
      "Epoch [1/1], Batch [20710/30000], Loss: 2.2871\n",
      "Epoch [1/1], Batch [20720/30000], Loss: 2.4883\n",
      "Epoch [1/1], Batch [20730/30000], Loss: 2.1777\n",
      "Epoch [1/1], Batch [20740/30000], Loss: 2.3643\n",
      "Epoch [1/1], Batch [20750/30000], Loss: 2.2471\n",
      "Epoch [1/1], Batch [20760/30000], Loss: 2.3057\n",
      "Epoch [1/1], Batch [20770/30000], Loss: 2.2754\n",
      "Epoch [1/1], Batch [20780/30000], Loss: 2.3428\n",
      "Epoch [1/1], Batch [20790/30000], Loss: 2.3223\n",
      "Epoch [1/1], Batch [20800/30000], Loss: 2.3164\n",
      "Epoch [1/1], Batch [20810/30000], Loss: 2.2998\n",
      "Epoch [1/1], Batch [20820/30000], Loss: 2.3164\n",
      "Epoch [1/1], Batch [20830/30000], Loss: 2.3066\n",
      "Epoch [1/1], Batch [20840/30000], Loss: 2.3184\n",
      "Epoch [1/1], Batch [20850/30000], Loss: 2.2578\n",
      "Epoch [1/1], Batch [20860/30000], Loss: 2.2490\n",
      "Epoch [1/1], Batch [20870/30000], Loss: 2.2334\n",
      "Epoch [1/1], Batch [20880/30000], Loss: 2.3301\n",
      "Epoch [1/1], Batch [20890/30000], Loss: 2.3975\n",
      "Epoch [1/1], Batch [20900/30000], Loss: 2.3857\n",
      "Epoch [1/1], Batch [20910/30000], Loss: 2.2207\n",
      "Epoch [1/1], Batch [20920/30000], Loss: 2.5000\n",
      "Epoch [1/1], Batch [20930/30000], Loss: 2.3037\n",
      "Epoch [1/1], Batch [20940/30000], Loss: 2.5371\n",
      "Epoch [1/1], Batch [20950/30000], Loss: 2.4551\n",
      "Epoch [1/1], Batch [20960/30000], Loss: 2.4238\n",
      "Epoch [1/1], Batch [20970/30000], Loss: 2.3223\n",
      "Epoch [1/1], Batch [20980/30000], Loss: 2.3320\n",
      "Epoch [1/1], Batch [20990/30000], Loss: 2.3047\n",
      "Epoch [1/1], Batch [21000/30000], Loss: 2.3174\n",
      "Epoch [1/1], Batch [21010/30000], Loss: 2.4512\n",
      "Epoch [1/1], Batch [21020/30000], Loss: 2.3896\n",
      "Epoch [1/1], Batch [21030/30000], Loss: 2.1455\n",
      "Epoch [1/1], Batch [21040/30000], Loss: 2.2939\n",
      "Epoch [1/1], Batch [21050/30000], Loss: 2.2588\n",
      "Epoch [1/1], Batch [21060/30000], Loss: 2.3340\n",
      "Epoch [1/1], Batch [21070/30000], Loss: 2.2158\n",
      "Epoch [1/1], Batch [21080/30000], Loss: 2.2812\n",
      "Epoch [1/1], Batch [21090/30000], Loss: 2.6484\n",
      "Epoch [1/1], Batch [21100/30000], Loss: 2.1934\n",
      "Epoch [1/1], Batch [21110/30000], Loss: 2.3311\n",
      "Epoch [1/1], Batch [21120/30000], Loss: 2.1660\n",
      "Epoch [1/1], Batch [21130/30000], Loss: 2.3408\n",
      "Epoch [1/1], Batch [21140/30000], Loss: 2.4092\n",
      "Epoch [1/1], Batch [21150/30000], Loss: 2.2520\n",
      "Epoch [1/1], Batch [21160/30000], Loss: 2.3174\n",
      "Epoch [1/1], Batch [21170/30000], Loss: 2.2646\n",
      "Epoch [1/1], Batch [21180/30000], Loss: 2.2510\n",
      "Epoch [1/1], Batch [21190/30000], Loss: 2.4541\n",
      "Epoch [1/1], Batch [21200/30000], Loss: 2.5107\n",
      "Epoch [1/1], Batch [21210/30000], Loss: 2.2559\n",
      "Epoch [1/1], Batch [21220/30000], Loss: 2.2959\n",
      "Epoch [1/1], Batch [21230/30000], Loss: 2.3066\n",
      "Epoch [1/1], Batch [21240/30000], Loss: 2.2588\n",
      "Epoch [1/1], Batch [21250/30000], Loss: 2.3496\n",
      "Epoch [1/1], Batch [21260/30000], Loss: 2.3506\n",
      "Epoch [1/1], Batch [21270/30000], Loss: 2.1328\n",
      "Epoch [1/1], Batch [21280/30000], Loss: 2.3975\n",
      "Epoch [1/1], Batch [21290/30000], Loss: 2.1719\n",
      "Epoch [1/1], Batch [21300/30000], Loss: 2.2441\n",
      "Epoch [1/1], Batch [21310/30000], Loss: 2.2637\n",
      "Epoch [1/1], Batch [21320/30000], Loss: 2.3232\n",
      "Epoch [1/1], Batch [21330/30000], Loss: 2.2930\n",
      "Epoch [1/1], Batch [21340/30000], Loss: 2.4004\n",
      "Epoch [1/1], Batch [21350/30000], Loss: 2.4199\n",
      "Epoch [1/1], Batch [21360/30000], Loss: 2.2124\n",
      "Epoch [1/1], Batch [21370/30000], Loss: 2.3955\n",
      "Epoch [1/1], Batch [21380/30000], Loss: 2.3135\n",
      "Epoch [1/1], Batch [21390/30000], Loss: 2.2988\n",
      "Epoch [1/1], Batch [21400/30000], Loss: 2.4492\n",
      "Epoch [1/1], Batch [21410/30000], Loss: 2.1450\n",
      "Epoch [1/1], Batch [21420/30000], Loss: 2.2539\n",
      "Epoch [1/1], Batch [21430/30000], Loss: 2.2051\n",
      "Epoch [1/1], Batch [21440/30000], Loss: 2.3027\n",
      "Epoch [1/1], Batch [21450/30000], Loss: 2.2046\n",
      "Epoch [1/1], Batch [21460/30000], Loss: 2.4814\n",
      "Epoch [1/1], Batch [21470/30000], Loss: 2.1982\n",
      "Epoch [1/1], Batch [21480/30000], Loss: 2.3213\n",
      "Epoch [1/1], Batch [21490/30000], Loss: 2.3477\n",
      "Epoch [1/1], Batch [21500/30000], Loss: 2.4443\n",
      "Epoch [1/1], Batch [21510/30000], Loss: 2.3877\n",
      "Epoch [1/1], Batch [21520/30000], Loss: 2.2656\n",
      "Epoch [1/1], Batch [21530/30000], Loss: 2.3506\n",
      "Epoch [1/1], Batch [21540/30000], Loss: 2.3525\n",
      "Epoch [1/1], Batch [21550/30000], Loss: 2.4854\n",
      "Epoch [1/1], Batch [21560/30000], Loss: 2.2900\n",
      "Epoch [1/1], Batch [21570/30000], Loss: 2.5264\n",
      "Epoch [1/1], Batch [21580/30000], Loss: 2.1777\n",
      "Epoch [1/1], Batch [21590/30000], Loss: 2.2051\n",
      "Epoch [1/1], Batch [21600/30000], Loss: 2.1992\n",
      "Epoch [1/1], Batch [21610/30000], Loss: 2.3154\n",
      "Epoch [1/1], Batch [21620/30000], Loss: 2.0693\n",
      "Epoch [1/1], Batch [21630/30000], Loss: 2.2949\n",
      "Epoch [1/1], Batch [21640/30000], Loss: 2.2549\n",
      "Epoch [1/1], Batch [21650/30000], Loss: 2.2871\n",
      "Epoch [1/1], Batch [21660/30000], Loss: 2.3184\n",
      "Epoch [1/1], Batch [21670/30000], Loss: 2.2334\n",
      "Epoch [1/1], Batch [21680/30000], Loss: 2.3975\n",
      "Epoch [1/1], Batch [21690/30000], Loss: 2.2256\n",
      "Epoch [1/1], Batch [21700/30000], Loss: 2.0688\n",
      "Epoch [1/1], Batch [21710/30000], Loss: 2.3672\n",
      "Epoch [1/1], Batch [21720/30000], Loss: 2.5537\n",
      "Epoch [1/1], Batch [21730/30000], Loss: 2.2422\n",
      "Epoch [1/1], Batch [21740/30000], Loss: 2.3691\n",
      "Epoch [1/1], Batch [21750/30000], Loss: 2.2471\n",
      "Epoch [1/1], Batch [21760/30000], Loss: 2.2842\n",
      "Epoch [1/1], Batch [21770/30000], Loss: 2.3018\n",
      "Epoch [1/1], Batch [21780/30000], Loss: 2.2900\n",
      "Epoch [1/1], Batch [21790/30000], Loss: 2.2852\n",
      "Epoch [1/1], Batch [21800/30000], Loss: 2.6250\n",
      "Epoch [1/1], Batch [21810/30000], Loss: 2.3330\n",
      "Epoch [1/1], Batch [21820/30000], Loss: 2.2627\n",
      "Epoch [1/1], Batch [21830/30000], Loss: 2.2314\n",
      "Epoch [1/1], Batch [21840/30000], Loss: 2.3008\n",
      "Epoch [1/1], Batch [21850/30000], Loss: 2.3242\n",
      "Epoch [1/1], Batch [21860/30000], Loss: 2.3945\n",
      "Epoch [1/1], Batch [21870/30000], Loss: 2.1738\n",
      "Epoch [1/1], Batch [21880/30000], Loss: 2.3223\n",
      "Epoch [1/1], Batch [21890/30000], Loss: 2.3389\n",
      "Epoch [1/1], Batch [21900/30000], Loss: 2.3984\n",
      "Epoch [1/1], Batch [21910/30000], Loss: 2.2393\n",
      "Epoch [1/1], Batch [21920/30000], Loss: 2.3496\n",
      "Epoch [1/1], Batch [21930/30000], Loss: 2.2852\n",
      "Epoch [1/1], Batch [21940/30000], Loss: 2.3047\n",
      "Epoch [1/1], Batch [21950/30000], Loss: 2.3789\n",
      "Epoch [1/1], Batch [21960/30000], Loss: 2.2012\n",
      "Epoch [1/1], Batch [21970/30000], Loss: 2.0542\n",
      "Epoch [1/1], Batch [21980/30000], Loss: 2.2764\n",
      "Epoch [1/1], Batch [21990/30000], Loss: 2.1699\n",
      "Epoch [1/1], Batch [22000/30000], Loss: 2.2705\n",
      "Epoch [1/1], Batch [22010/30000], Loss: 2.1846\n",
      "Epoch [1/1], Batch [22020/30000], Loss: 2.2734\n",
      "Epoch [1/1], Batch [22030/30000], Loss: 2.3809\n",
      "Epoch [1/1], Batch [22040/30000], Loss: 2.1885\n",
      "Epoch [1/1], Batch [22050/30000], Loss: 2.3320\n",
      "Epoch [1/1], Batch [22060/30000], Loss: 2.3574\n",
      "Epoch [1/1], Batch [22070/30000], Loss: 2.3486\n",
      "Epoch [1/1], Batch [22080/30000], Loss: 2.3262\n",
      "Epoch [1/1], Batch [22090/30000], Loss: 2.3242\n",
      "Epoch [1/1], Batch [22100/30000], Loss: 2.3135\n",
      "Epoch [1/1], Batch [22110/30000], Loss: 2.3262\n",
      "Epoch [1/1], Batch [22120/30000], Loss: 2.3027\n",
      "Epoch [1/1], Batch [22130/30000], Loss: 2.3584\n",
      "Epoch [1/1], Batch [22140/30000], Loss: 2.3564\n",
      "Epoch [1/1], Batch [22150/30000], Loss: 2.2129\n",
      "Epoch [1/1], Batch [22160/30000], Loss: 2.4131\n",
      "Epoch [1/1], Batch [22170/30000], Loss: 2.2500\n",
      "Epoch [1/1], Batch [22180/30000], Loss: 2.3369\n",
      "Epoch [1/1], Batch [22190/30000], Loss: 2.2686\n",
      "Epoch [1/1], Batch [22200/30000], Loss: 2.2686\n",
      "Epoch [1/1], Batch [22210/30000], Loss: 2.1699\n",
      "Epoch [1/1], Batch [22220/30000], Loss: 2.3369\n",
      "Epoch [1/1], Batch [22230/30000], Loss: 2.3652\n",
      "Epoch [1/1], Batch [22240/30000], Loss: 2.2539\n",
      "Epoch [1/1], Batch [22250/30000], Loss: 2.3057\n",
      "Epoch [1/1], Batch [22260/30000], Loss: 2.3281\n",
      "Epoch [1/1], Batch [22270/30000], Loss: 2.2705\n",
      "Epoch [1/1], Batch [22280/30000], Loss: 2.2891\n",
      "Epoch [1/1], Batch [22290/30000], Loss: 2.3184\n",
      "Epoch [1/1], Batch [22300/30000], Loss: 2.2764\n",
      "Epoch [1/1], Batch [22310/30000], Loss: 2.3682\n",
      "Epoch [1/1], Batch [22320/30000], Loss: 2.2871\n",
      "Epoch [1/1], Batch [22330/30000], Loss: 2.2891\n",
      "Epoch [1/1], Batch [22340/30000], Loss: 2.3701\n",
      "Epoch [1/1], Batch [22350/30000], Loss: 2.3242\n",
      "Epoch [1/1], Batch [22360/30000], Loss: 2.3438\n",
      "Epoch [1/1], Batch [22370/30000], Loss: 2.3066\n",
      "Epoch [1/1], Batch [22380/30000], Loss: 2.3213\n",
      "Epoch [1/1], Batch [22390/30000], Loss: 2.3789\n",
      "Epoch [1/1], Batch [22400/30000], Loss: 2.2422\n",
      "Epoch [1/1], Batch [22410/30000], Loss: 2.3682\n",
      "Epoch [1/1], Batch [22420/30000], Loss: 2.2930\n",
      "Epoch [1/1], Batch [22430/30000], Loss: 2.3418\n",
      "Epoch [1/1], Batch [22440/30000], Loss: 2.3213\n",
      "Epoch [1/1], Batch [22450/30000], Loss: 2.2852\n",
      "Epoch [1/1], Batch [22460/30000], Loss: 2.3027\n",
      "Epoch [1/1], Batch [22470/30000], Loss: 2.3076\n",
      "Epoch [1/1], Batch [22480/30000], Loss: 2.3232\n",
      "Epoch [1/1], Batch [22490/30000], Loss: 2.4219\n",
      "Epoch [1/1], Batch [22500/30000], Loss: 2.2051\n",
      "Epoch [1/1], Batch [22510/30000], Loss: 2.2852\n",
      "Epoch [1/1], Batch [22520/30000], Loss: 2.1924\n",
      "Epoch [1/1], Batch [22530/30000], Loss: 2.3115\n",
      "Epoch [1/1], Batch [22540/30000], Loss: 2.2949\n",
      "Epoch [1/1], Batch [22550/30000], Loss: 2.3848\n",
      "Epoch [1/1], Batch [22560/30000], Loss: 2.4258\n",
      "Epoch [1/1], Batch [22570/30000], Loss: 2.2109\n",
      "Epoch [1/1], Batch [22580/30000], Loss: 2.2686\n",
      "Epoch [1/1], Batch [22590/30000], Loss: 2.3555\n",
      "Epoch [1/1], Batch [22600/30000], Loss: 2.3779\n",
      "Epoch [1/1], Batch [22610/30000], Loss: 2.2871\n",
      "Epoch [1/1], Batch [22620/30000], Loss: 2.2383\n",
      "Epoch [1/1], Batch [22630/30000], Loss: 2.2979\n",
      "Epoch [1/1], Batch [22640/30000], Loss: 2.2051\n",
      "Epoch [1/1], Batch [22650/30000], Loss: 2.3242\n",
      "Epoch [1/1], Batch [22660/30000], Loss: 2.4082\n",
      "Epoch [1/1], Batch [22670/30000], Loss: 2.3867\n",
      "Epoch [1/1], Batch [22680/30000], Loss: 2.1484\n",
      "Epoch [1/1], Batch [22690/30000], Loss: 2.1787\n",
      "Epoch [1/1], Batch [22700/30000], Loss: 2.0996\n",
      "Epoch [1/1], Batch [22710/30000], Loss: 2.3301\n",
      "Epoch [1/1], Batch [22720/30000], Loss: 2.4512\n",
      "Epoch [1/1], Batch [22730/30000], Loss: 2.3096\n",
      "Epoch [1/1], Batch [22740/30000], Loss: 2.3232\n",
      "Epoch [1/1], Batch [22750/30000], Loss: 2.2529\n",
      "Epoch [1/1], Batch [22760/30000], Loss: 2.2617\n",
      "Epoch [1/1], Batch [22770/30000], Loss: 2.2998\n",
      "Epoch [1/1], Batch [22780/30000], Loss: 2.3584\n",
      "Epoch [1/1], Batch [22790/30000], Loss: 2.3418\n",
      "Epoch [1/1], Batch [22800/30000], Loss: 2.3203\n",
      "Epoch [1/1], Batch [22810/30000], Loss: 2.3418\n",
      "Epoch [1/1], Batch [22820/30000], Loss: 2.2686\n",
      "Epoch [1/1], Batch [22830/30000], Loss: 2.2852\n",
      "Epoch [1/1], Batch [22840/30000], Loss: 2.3867\n",
      "Epoch [1/1], Batch [22850/30000], Loss: 2.2041\n",
      "Epoch [1/1], Batch [22860/30000], Loss: 2.1787\n",
      "Epoch [1/1], Batch [22870/30000], Loss: 2.2090\n",
      "Epoch [1/1], Batch [22880/30000], Loss: 2.2676\n",
      "Epoch [1/1], Batch [22890/30000], Loss: 2.4238\n",
      "Epoch [1/1], Batch [22900/30000], Loss: 2.3301\n",
      "Epoch [1/1], Batch [22910/30000], Loss: 2.3252\n",
      "Epoch [1/1], Batch [22920/30000], Loss: 2.2969\n",
      "Epoch [1/1], Batch [22930/30000], Loss: 2.2998\n",
      "Epoch [1/1], Batch [22940/30000], Loss: 2.2393\n",
      "Epoch [1/1], Batch [22950/30000], Loss: 2.3340\n",
      "Epoch [1/1], Batch [22960/30000], Loss: 2.2715\n",
      "Epoch [1/1], Batch [22970/30000], Loss: 2.3447\n",
      "Epoch [1/1], Batch [22980/30000], Loss: 2.2939\n",
      "Epoch [1/1], Batch [22990/30000], Loss: 2.3857\n",
      "Epoch [1/1], Batch [23000/30000], Loss: 2.3271\n",
      "Epoch [1/1], Batch [23010/30000], Loss: 2.2520\n",
      "Epoch [1/1], Batch [23020/30000], Loss: 2.2295\n",
      "Epoch [1/1], Batch [23030/30000], Loss: 2.3887\n",
      "Epoch [1/1], Batch [23040/30000], Loss: 2.3418\n",
      "Epoch [1/1], Batch [23050/30000], Loss: 2.2354\n",
      "Epoch [1/1], Batch [23060/30000], Loss: 2.2666\n",
      "Epoch [1/1], Batch [23070/30000], Loss: 2.4229\n",
      "Epoch [1/1], Batch [23080/30000], Loss: 2.3213\n",
      "Epoch [1/1], Batch [23090/30000], Loss: 2.2129\n",
      "Epoch [1/1], Batch [23100/30000], Loss: 2.3516\n",
      "Epoch [1/1], Batch [23110/30000], Loss: 2.3574\n",
      "Epoch [1/1], Batch [23120/30000], Loss: 2.2764\n",
      "Epoch [1/1], Batch [23130/30000], Loss: 2.4062\n",
      "Epoch [1/1], Batch [23140/30000], Loss: 2.3252\n",
      "Epoch [1/1], Batch [23150/30000], Loss: 2.2783\n",
      "Epoch [1/1], Batch [23160/30000], Loss: 2.3008\n",
      "Epoch [1/1], Batch [23170/30000], Loss: 2.2168\n",
      "Epoch [1/1], Batch [23180/30000], Loss: 2.2266\n",
      "Epoch [1/1], Batch [23190/30000], Loss: 2.1855\n",
      "Epoch [1/1], Batch [23200/30000], Loss: 2.2539\n",
      "Epoch [1/1], Batch [23210/30000], Loss: 2.0605\n",
      "Epoch [1/1], Batch [23220/30000], Loss: 2.2378\n",
      "Epoch [1/1], Batch [23230/30000], Loss: 2.4209\n",
      "Epoch [1/1], Batch [23240/30000], Loss: 2.4414\n",
      "Epoch [1/1], Batch [23250/30000], Loss: 2.3457\n",
      "Epoch [1/1], Batch [23260/30000], Loss: 2.3242\n",
      "Epoch [1/1], Batch [23270/30000], Loss: 2.2012\n",
      "Epoch [1/1], Batch [23280/30000], Loss: 2.3828\n",
      "Epoch [1/1], Batch [23290/30000], Loss: 2.2832\n",
      "Epoch [1/1], Batch [23300/30000], Loss: 2.2832\n",
      "Epoch [1/1], Batch [23310/30000], Loss: 2.2949\n",
      "Epoch [1/1], Batch [23320/30000], Loss: 2.2998\n",
      "Epoch [1/1], Batch [23330/30000], Loss: 2.1670\n",
      "Epoch [1/1], Batch [23340/30000], Loss: 2.2051\n",
      "Epoch [1/1], Batch [23350/30000], Loss: 2.2480\n",
      "Epoch [1/1], Batch [23360/30000], Loss: 2.2461\n",
      "Epoch [1/1], Batch [23370/30000], Loss: 2.2227\n",
      "Epoch [1/1], Batch [23380/30000], Loss: 2.2617\n",
      "Epoch [1/1], Batch [23390/30000], Loss: 2.3027\n",
      "Epoch [1/1], Batch [23400/30000], Loss: 2.2090\n",
      "Epoch [1/1], Batch [23410/30000], Loss: 2.2041\n",
      "Epoch [1/1], Batch [23420/30000], Loss: 2.2139\n",
      "Epoch [1/1], Batch [23430/30000], Loss: 2.1074\n",
      "Epoch [1/1], Batch [23440/30000], Loss: 2.1777\n",
      "Epoch [1/1], Batch [23450/30000], Loss: 2.1924\n",
      "Epoch [1/1], Batch [23460/30000], Loss: 2.2705\n",
      "Epoch [1/1], Batch [23470/30000], Loss: 2.2432\n",
      "Epoch [1/1], Batch [23480/30000], Loss: 2.2158\n",
      "Epoch [1/1], Batch [23490/30000], Loss: 2.4297\n",
      "Epoch [1/1], Batch [23500/30000], Loss: 2.2812\n",
      "Epoch [1/1], Batch [23510/30000], Loss: 2.2539\n",
      "Epoch [1/1], Batch [23520/30000], Loss: 2.3604\n",
      "Epoch [1/1], Batch [23530/30000], Loss: 2.2305\n",
      "Epoch [1/1], Batch [23540/30000], Loss: 2.2227\n",
      "Epoch [1/1], Batch [23550/30000], Loss: 2.2178\n",
      "Epoch [1/1], Batch [23560/30000], Loss: 2.3008\n",
      "Epoch [1/1], Batch [23570/30000], Loss: 2.2021\n",
      "Epoch [1/1], Batch [23580/30000], Loss: 2.3242\n",
      "Epoch [1/1], Batch [23590/30000], Loss: 2.2432\n",
      "Epoch [1/1], Batch [23600/30000], Loss: 2.2246\n",
      "Epoch [1/1], Batch [23610/30000], Loss: 2.3369\n",
      "Epoch [1/1], Batch [23620/30000], Loss: 2.2822\n",
      "Epoch [1/1], Batch [23630/30000], Loss: 2.1992\n",
      "Epoch [1/1], Batch [23640/30000], Loss: 2.1641\n",
      "Epoch [1/1], Batch [23650/30000], Loss: 2.2803\n",
      "Epoch [1/1], Batch [23660/30000], Loss: 2.1929\n",
      "Epoch [1/1], Batch [23670/30000], Loss: 2.2324\n",
      "Epoch [1/1], Batch [23680/30000], Loss: 2.3086\n",
      "Epoch [1/1], Batch [23690/30000], Loss: 2.6777\n",
      "Epoch [1/1], Batch [23700/30000], Loss: 2.3467\n",
      "Epoch [1/1], Batch [23710/30000], Loss: 2.1318\n",
      "Epoch [1/1], Batch [23720/30000], Loss: 2.2266\n",
      "Epoch [1/1], Batch [23730/30000], Loss: 2.3633\n",
      "Epoch [1/1], Batch [23740/30000], Loss: 2.4414\n",
      "Epoch [1/1], Batch [23750/30000], Loss: 2.3057\n",
      "Epoch [1/1], Batch [23760/30000], Loss: 2.3047\n",
      "Epoch [1/1], Batch [23770/30000], Loss: 2.2158\n",
      "Epoch [1/1], Batch [23780/30000], Loss: 2.3779\n",
      "Epoch [1/1], Batch [23790/30000], Loss: 2.3145\n",
      "Epoch [1/1], Batch [23800/30000], Loss: 2.2871\n",
      "Epoch [1/1], Batch [23810/30000], Loss: 2.2998\n",
      "Epoch [1/1], Batch [23820/30000], Loss: 2.4395\n",
      "Epoch [1/1], Batch [23830/30000], Loss: 2.1865\n",
      "Epoch [1/1], Batch [23840/30000], Loss: 2.2275\n",
      "Epoch [1/1], Batch [23850/30000], Loss: 2.2559\n",
      "Epoch [1/1], Batch [23860/30000], Loss: 2.3057\n",
      "Epoch [1/1], Batch [23870/30000], Loss: 2.3066\n",
      "Epoch [1/1], Batch [23880/30000], Loss: 2.3252\n",
      "Epoch [1/1], Batch [23890/30000], Loss: 2.2812\n",
      "Epoch [1/1], Batch [23900/30000], Loss: 2.3398\n",
      "Epoch [1/1], Batch [23910/30000], Loss: 2.3760\n",
      "Epoch [1/1], Batch [23920/30000], Loss: 2.3145\n",
      "Epoch [1/1], Batch [23930/30000], Loss: 2.5098\n",
      "Epoch [1/1], Batch [23940/30000], Loss: 2.0415\n",
      "Epoch [1/1], Batch [23950/30000], Loss: 2.4014\n",
      "Epoch [1/1], Batch [23960/30000], Loss: 2.2881\n",
      "Epoch [1/1], Batch [23970/30000], Loss: 2.3027\n",
      "Epoch [1/1], Batch [23980/30000], Loss: 2.3564\n",
      "Epoch [1/1], Batch [23990/30000], Loss: 2.2871\n",
      "Epoch [1/1], Batch [24000/30000], Loss: 2.4766\n",
      "Epoch [1/1], Batch [24010/30000], Loss: 2.4043\n",
      "Epoch [1/1], Batch [24020/30000], Loss: 2.3086\n",
      "Epoch [1/1], Batch [24030/30000], Loss: 2.1641\n",
      "Epoch [1/1], Batch [24040/30000], Loss: 2.1084\n",
      "Epoch [1/1], Batch [24050/30000], Loss: 2.1738\n",
      "Epoch [1/1], Batch [24060/30000], Loss: 2.2666\n",
      "Epoch [1/1], Batch [24070/30000], Loss: 2.1855\n",
      "Epoch [1/1], Batch [24080/30000], Loss: 2.2271\n",
      "Epoch [1/1], Batch [24090/30000], Loss: 2.9248\n",
      "Epoch [1/1], Batch [24100/30000], Loss: 2.3955\n",
      "Epoch [1/1], Batch [24110/30000], Loss: 2.3418\n",
      "Epoch [1/1], Batch [24120/30000], Loss: 2.2764\n",
      "Epoch [1/1], Batch [24130/30000], Loss: 2.1533\n",
      "Epoch [1/1], Batch [24140/30000], Loss: 2.2344\n",
      "Epoch [1/1], Batch [24150/30000], Loss: 2.2881\n",
      "Epoch [1/1], Batch [24160/30000], Loss: 2.3203\n",
      "Epoch [1/1], Batch [24170/30000], Loss: 2.2285\n",
      "Epoch [1/1], Batch [24180/30000], Loss: 2.3389\n",
      "Epoch [1/1], Batch [24190/30000], Loss: 2.4033\n",
      "Epoch [1/1], Batch [24200/30000], Loss: 2.2178\n",
      "Epoch [1/1], Batch [24210/30000], Loss: 2.3076\n",
      "Epoch [1/1], Batch [24220/30000], Loss: 2.3379\n",
      "Epoch [1/1], Batch [24230/30000], Loss: 2.3877\n",
      "Epoch [1/1], Batch [24240/30000], Loss: 2.3018\n",
      "Epoch [1/1], Batch [24250/30000], Loss: 2.2529\n",
      "Epoch [1/1], Batch [24260/30000], Loss: 2.2578\n",
      "Epoch [1/1], Batch [24270/30000], Loss: 2.3721\n",
      "Epoch [1/1], Batch [24280/30000], Loss: 2.2881\n",
      "Epoch [1/1], Batch [24290/30000], Loss: 2.4170\n",
      "Epoch [1/1], Batch [24300/30000], Loss: 2.2236\n",
      "Epoch [1/1], Batch [24310/30000], Loss: 2.1309\n",
      "Epoch [1/1], Batch [24320/30000], Loss: 2.3672\n",
      "Epoch [1/1], Batch [24330/30000], Loss: 2.3516\n",
      "Epoch [1/1], Batch [24340/30000], Loss: 2.1992\n",
      "Epoch [1/1], Batch [24350/30000], Loss: 2.0547\n",
      "Epoch [1/1], Batch [24360/30000], Loss: 2.3057\n",
      "Epoch [1/1], Batch [24370/30000], Loss: 2.1494\n",
      "Epoch [1/1], Batch [24380/30000], Loss: 2.0591\n",
      "Epoch [1/1], Batch [24390/30000], Loss: 2.1553\n",
      "Epoch [1/1], Batch [24400/30000], Loss: 2.2275\n",
      "Epoch [1/1], Batch [24410/30000], Loss: 2.3721\n",
      "Epoch [1/1], Batch [24420/30000], Loss: 2.3154\n",
      "Epoch [1/1], Batch [24430/30000], Loss: 2.4521\n",
      "Epoch [1/1], Batch [24440/30000], Loss: 2.2998\n",
      "Epoch [1/1], Batch [24450/30000], Loss: 2.2383\n",
      "Epoch [1/1], Batch [24460/30000], Loss: 2.3369\n",
      "Epoch [1/1], Batch [24470/30000], Loss: 2.3027\n",
      "Epoch [1/1], Batch [24480/30000], Loss: 2.2812\n",
      "Epoch [1/1], Batch [24490/30000], Loss: 2.3447\n",
      "Epoch [1/1], Batch [24500/30000], Loss: 2.1904\n",
      "Epoch [1/1], Batch [24510/30000], Loss: 2.2568\n",
      "Epoch [1/1], Batch [24520/30000], Loss: 2.5518\n",
      "Epoch [1/1], Batch [24530/30000], Loss: 2.3271\n",
      "Epoch [1/1], Batch [24540/30000], Loss: 2.3516\n",
      "Epoch [1/1], Batch [24550/30000], Loss: 2.2871\n",
      "Epoch [1/1], Batch [24560/30000], Loss: 2.5068\n",
      "Epoch [1/1], Batch [24570/30000], Loss: 2.2334\n",
      "Epoch [1/1], Batch [24580/30000], Loss: 2.2861\n",
      "Epoch [1/1], Batch [24590/30000], Loss: 2.1538\n",
      "Epoch [1/1], Batch [24600/30000], Loss: 2.2129\n",
      "Epoch [1/1], Batch [24610/30000], Loss: 2.3916\n",
      "Epoch [1/1], Batch [24620/30000], Loss: 2.2549\n",
      "Epoch [1/1], Batch [24630/30000], Loss: 2.2549\n",
      "Epoch [1/1], Batch [24640/30000], Loss: 2.2930\n",
      "Epoch [1/1], Batch [24650/30000], Loss: 2.1396\n",
      "Epoch [1/1], Batch [24660/30000], Loss: 2.0898\n",
      "Epoch [1/1], Batch [24670/30000], Loss: 2.1323\n",
      "Epoch [1/1], Batch [24680/30000], Loss: 2.2715\n",
      "Epoch [1/1], Batch [24690/30000], Loss: 2.3535\n",
      "Epoch [1/1], Batch [24700/30000], Loss: 2.2637\n",
      "Epoch [1/1], Batch [24710/30000], Loss: 2.3027\n",
      "Epoch [1/1], Batch [24720/30000], Loss: 2.2354\n",
      "Epoch [1/1], Batch [24730/30000], Loss: 2.4336\n",
      "Epoch [1/1], Batch [24740/30000], Loss: 2.2461\n",
      "Epoch [1/1], Batch [24750/30000], Loss: 2.5957\n",
      "Epoch [1/1], Batch [24760/30000], Loss: 2.2432\n",
      "Epoch [1/1], Batch [24770/30000], Loss: 2.3193\n",
      "Epoch [1/1], Batch [24780/30000], Loss: 2.2646\n",
      "Epoch [1/1], Batch [24790/30000], Loss: 2.2998\n",
      "Epoch [1/1], Batch [24800/30000], Loss: 2.2988\n",
      "Epoch [1/1], Batch [24810/30000], Loss: 2.3027\n",
      "Epoch [1/1], Batch [24820/30000], Loss: 2.2871\n",
      "Epoch [1/1], Batch [24830/30000], Loss: 2.3984\n",
      "Epoch [1/1], Batch [24840/30000], Loss: 2.3223\n",
      "Epoch [1/1], Batch [24850/30000], Loss: 2.4131\n",
      "Epoch [1/1], Batch [24860/30000], Loss: 2.3496\n",
      "Epoch [1/1], Batch [24870/30000], Loss: 2.4268\n",
      "Epoch [1/1], Batch [24880/30000], Loss: 2.3662\n",
      "Epoch [1/1], Batch [24890/30000], Loss: 2.3232\n",
      "Epoch [1/1], Batch [24900/30000], Loss: 2.2793\n",
      "Epoch [1/1], Batch [24910/30000], Loss: 2.3301\n",
      "Epoch [1/1], Batch [24920/30000], Loss: 2.1670\n",
      "Epoch [1/1], Batch [24930/30000], Loss: 2.3896\n",
      "Epoch [1/1], Batch [24940/30000], Loss: 2.3662\n",
      "Epoch [1/1], Batch [24950/30000], Loss: 2.2305\n",
      "Epoch [1/1], Batch [24960/30000], Loss: 2.3887\n",
      "Epoch [1/1], Batch [24970/30000], Loss: 2.3398\n",
      "Epoch [1/1], Batch [24980/30000], Loss: 2.3564\n",
      "Epoch [1/1], Batch [24990/30000], Loss: 2.4258\n",
      "Epoch [1/1], Batch [25000/30000], Loss: 2.1582\n",
      "Epoch [1/1], Batch [25010/30000], Loss: 2.3867\n",
      "Epoch [1/1], Batch [25020/30000], Loss: 2.3438\n",
      "Epoch [1/1], Batch [25030/30000], Loss: 2.3496\n",
      "Epoch [1/1], Batch [25040/30000], Loss: 2.3740\n",
      "Epoch [1/1], Batch [25050/30000], Loss: 2.2402\n",
      "Epoch [1/1], Batch [25060/30000], Loss: 2.3438\n",
      "Epoch [1/1], Batch [25070/30000], Loss: 2.3223\n",
      "Epoch [1/1], Batch [25080/30000], Loss: 2.3242\n",
      "Epoch [1/1], Batch [25090/30000], Loss: 2.3164\n",
      "Epoch [1/1], Batch [25100/30000], Loss: 2.2861\n",
      "Epoch [1/1], Batch [25110/30000], Loss: 2.4746\n",
      "Epoch [1/1], Batch [25120/30000], Loss: 2.2734\n",
      "Epoch [1/1], Batch [25130/30000], Loss: 2.2275\n",
      "Epoch [1/1], Batch [25140/30000], Loss: 2.2510\n",
      "Epoch [1/1], Batch [25150/30000], Loss: 2.4072\n",
      "Epoch [1/1], Batch [25160/30000], Loss: 2.4033\n",
      "Epoch [1/1], Batch [25170/30000], Loss: 2.1709\n",
      "Epoch [1/1], Batch [25180/30000], Loss: 2.3574\n",
      "Epoch [1/1], Batch [25190/30000], Loss: 2.3818\n",
      "Epoch [1/1], Batch [25200/30000], Loss: 2.3232\n",
      "Epoch [1/1], Batch [25210/30000], Loss: 2.2930\n",
      "Epoch [1/1], Batch [25220/30000], Loss: 2.2188\n",
      "Epoch [1/1], Batch [25230/30000], Loss: 2.1230\n",
      "Epoch [1/1], Batch [25240/30000], Loss: 2.4102\n",
      "Epoch [1/1], Batch [25250/30000], Loss: 2.3408\n",
      "Epoch [1/1], Batch [25260/30000], Loss: 2.3857\n",
      "Epoch [1/1], Batch [25270/30000], Loss: 2.2051\n",
      "Epoch [1/1], Batch [25280/30000], Loss: 2.2852\n",
      "Epoch [1/1], Batch [25290/30000], Loss: 2.2422\n",
      "Epoch [1/1], Batch [25300/30000], Loss: 2.2930\n",
      "Epoch [1/1], Batch [25310/30000], Loss: 2.1836\n",
      "Epoch [1/1], Batch [25320/30000], Loss: 2.3154\n",
      "Epoch [1/1], Batch [25330/30000], Loss: 2.4141\n",
      "Epoch [1/1], Batch [25340/30000], Loss: 2.2529\n",
      "Epoch [1/1], Batch [25350/30000], Loss: 2.2520\n",
      "Epoch [1/1], Batch [25360/30000], Loss: 2.2764\n",
      "Epoch [1/1], Batch [25370/30000], Loss: 2.2588\n",
      "Epoch [1/1], Batch [25380/30000], Loss: 2.4316\n",
      "Epoch [1/1], Batch [25390/30000], Loss: 2.3701\n",
      "Epoch [1/1], Batch [25400/30000], Loss: 2.2803\n",
      "Epoch [1/1], Batch [25410/30000], Loss: 2.2695\n",
      "Epoch [1/1], Batch [25420/30000], Loss: 2.3545\n",
      "Epoch [1/1], Batch [25430/30000], Loss: 2.4004\n",
      "Epoch [1/1], Batch [25440/30000], Loss: 2.2373\n",
      "Epoch [1/1], Batch [25450/30000], Loss: 2.3652\n",
      "Epoch [1/1], Batch [25460/30000], Loss: 2.2744\n",
      "Epoch [1/1], Batch [25470/30000], Loss: 2.6182\n",
      "Epoch [1/1], Batch [25480/30000], Loss: 2.4375\n",
      "Epoch [1/1], Batch [25490/30000], Loss: 2.3174\n",
      "Epoch [1/1], Batch [25500/30000], Loss: 2.3115\n",
      "Epoch [1/1], Batch [25510/30000], Loss: 2.2754\n",
      "Epoch [1/1], Batch [25520/30000], Loss: 2.3232\n",
      "Epoch [1/1], Batch [25530/30000], Loss: 2.3242\n",
      "Epoch [1/1], Batch [25540/30000], Loss: 2.2773\n",
      "Epoch [1/1], Batch [25550/30000], Loss: 2.2256\n",
      "Epoch [1/1], Batch [25560/30000], Loss: 2.2666\n",
      "Epoch [1/1], Batch [25570/30000], Loss: 2.2734\n",
      "Epoch [1/1], Batch [25580/30000], Loss: 2.2041\n",
      "Epoch [1/1], Batch [25590/30000], Loss: 2.2119\n",
      "Epoch [1/1], Batch [25600/30000], Loss: 2.3936\n",
      "Epoch [1/1], Batch [25610/30000], Loss: 2.2109\n",
      "Epoch [1/1], Batch [25620/30000], Loss: 2.1650\n",
      "Epoch [1/1], Batch [25630/30000], Loss: 2.3965\n",
      "Epoch [1/1], Batch [25640/30000], Loss: 2.5391\n",
      "Epoch [1/1], Batch [25650/30000], Loss: 2.2383\n",
      "Epoch [1/1], Batch [25660/30000], Loss: 2.2910\n",
      "Epoch [1/1], Batch [25670/30000], Loss: 2.2783\n",
      "Epoch [1/1], Batch [25680/30000], Loss: 2.4424\n",
      "Epoch [1/1], Batch [25690/30000], Loss: 2.2588\n",
      "Epoch [1/1], Batch [25700/30000], Loss: 2.3037\n",
      "Epoch [1/1], Batch [25710/30000], Loss: 2.1719\n",
      "Epoch [1/1], Batch [25720/30000], Loss: 2.2559\n",
      "Epoch [1/1], Batch [25730/30000], Loss: 2.4189\n",
      "Epoch [1/1], Batch [25740/30000], Loss: 2.4307\n",
      "Epoch [1/1], Batch [25750/30000], Loss: 2.2949\n",
      "Epoch [1/1], Batch [25760/30000], Loss: 2.3271\n",
      "Epoch [1/1], Batch [25770/30000], Loss: 2.3330\n",
      "Epoch [1/1], Batch [25780/30000], Loss: 2.2979\n",
      "Epoch [1/1], Batch [25790/30000], Loss: 2.4033\n",
      "Epoch [1/1], Batch [25800/30000], Loss: 2.2910\n",
      "Epoch [1/1], Batch [25810/30000], Loss: 2.2969\n",
      "Epoch [1/1], Batch [25820/30000], Loss: 2.4580\n",
      "Epoch [1/1], Batch [25830/30000], Loss: 2.3066\n",
      "Epoch [1/1], Batch [25840/30000], Loss: 2.3350\n",
      "Epoch [1/1], Batch [25850/30000], Loss: 2.3037\n",
      "Epoch [1/1], Batch [25860/30000], Loss: 2.3301\n",
      "Epoch [1/1], Batch [25870/30000], Loss: 2.3887\n",
      "Epoch [1/1], Batch [25880/30000], Loss: 2.2148\n",
      "Epoch [1/1], Batch [25890/30000], Loss: 2.1318\n",
      "Epoch [1/1], Batch [25900/30000], Loss: 2.3857\n",
      "Epoch [1/1], Batch [25910/30000], Loss: 2.3564\n",
      "Epoch [1/1], Batch [25920/30000], Loss: 2.4727\n",
      "Epoch [1/1], Batch [25930/30000], Loss: 2.3936\n",
      "Epoch [1/1], Batch [25940/30000], Loss: 2.3174\n",
      "Epoch [1/1], Batch [25950/30000], Loss: 2.2754\n",
      "Epoch [1/1], Batch [25960/30000], Loss: 2.2363\n",
      "Epoch [1/1], Batch [25970/30000], Loss: 2.3037\n",
      "Epoch [1/1], Batch [25980/30000], Loss: 2.0996\n",
      "Epoch [1/1], Batch [25990/30000], Loss: 2.2324\n",
      "Epoch [1/1], Batch [26000/30000], Loss: 2.0918\n",
      "Epoch [1/1], Batch [26010/30000], Loss: 2.0063\n",
      "Epoch [1/1], Batch [26020/30000], Loss: 2.6182\n",
      "Epoch [1/1], Batch [26030/30000], Loss: 2.1240\n",
      "Epoch [1/1], Batch [26040/30000], Loss: 2.1035\n",
      "Epoch [1/1], Batch [26050/30000], Loss: 2.2412\n",
      "Epoch [1/1], Batch [26060/30000], Loss: 2.3574\n",
      "Epoch [1/1], Batch [26070/30000], Loss: 2.3193\n",
      "Epoch [1/1], Batch [26080/30000], Loss: 2.0723\n",
      "Epoch [1/1], Batch [26090/30000], Loss: 2.4131\n",
      "Epoch [1/1], Batch [26100/30000], Loss: 2.0244\n",
      "Epoch [1/1], Batch [26110/30000], Loss: 2.3418\n",
      "Epoch [1/1], Batch [26120/30000], Loss: 2.3408\n",
      "Epoch [1/1], Batch [26130/30000], Loss: 2.2246\n",
      "Epoch [1/1], Batch [26140/30000], Loss: 2.2617\n",
      "Epoch [1/1], Batch [26150/30000], Loss: 2.3936\n",
      "Epoch [1/1], Batch [26160/30000], Loss: 2.3154\n",
      "Epoch [1/1], Batch [26170/30000], Loss: 2.3496\n",
      "Epoch [1/1], Batch [26180/30000], Loss: 2.2949\n",
      "Epoch [1/1], Batch [26190/30000], Loss: 2.2959\n",
      "Epoch [1/1], Batch [26200/30000], Loss: 2.2949\n",
      "Epoch [1/1], Batch [26210/30000], Loss: 2.3047\n",
      "Epoch [1/1], Batch [26220/30000], Loss: 2.3945\n",
      "Epoch [1/1], Batch [26230/30000], Loss: 2.3574\n",
      "Epoch [1/1], Batch [26240/30000], Loss: 2.3193\n",
      "Epoch [1/1], Batch [26250/30000], Loss: 2.3740\n",
      "Epoch [1/1], Batch [26260/30000], Loss: 2.3438\n",
      "Epoch [1/1], Batch [26270/30000], Loss: 2.2725\n",
      "Epoch [1/1], Batch [26280/30000], Loss: 2.3721\n",
      "Epoch [1/1], Batch [26290/30000], Loss: 2.2676\n",
      "Epoch [1/1], Batch [26300/30000], Loss: 2.4531\n",
      "Epoch [1/1], Batch [26310/30000], Loss: 2.2764\n",
      "Epoch [1/1], Batch [26320/30000], Loss: 2.2666\n",
      "Epoch [1/1], Batch [26330/30000], Loss: 2.2344\n",
      "Epoch [1/1], Batch [26340/30000], Loss: 2.2080\n",
      "Epoch [1/1], Batch [26350/30000], Loss: 2.5195\n",
      "Epoch [1/1], Batch [26360/30000], Loss: 2.1885\n",
      "Epoch [1/1], Batch [26370/30000], Loss: 2.1836\n",
      "Epoch [1/1], Batch [26380/30000], Loss: 2.3398\n",
      "Epoch [1/1], Batch [26390/30000], Loss: 2.4297\n",
      "Epoch [1/1], Batch [26400/30000], Loss: 2.4043\n",
      "Epoch [1/1], Batch [26410/30000], Loss: 2.3545\n",
      "Epoch [1/1], Batch [26420/30000], Loss: 2.2051\n",
      "Epoch [1/1], Batch [26430/30000], Loss: 2.1338\n",
      "Epoch [1/1], Batch [26440/30000], Loss: 2.3799\n",
      "Epoch [1/1], Batch [26450/30000], Loss: 2.1816\n",
      "Epoch [1/1], Batch [26460/30000], Loss: 2.2080\n",
      "Epoch [1/1], Batch [26470/30000], Loss: 2.2852\n",
      "Epoch [1/1], Batch [26480/30000], Loss: 2.3379\n",
      "Epoch [1/1], Batch [26490/30000], Loss: 2.3301\n",
      "Epoch [1/1], Batch [26500/30000], Loss: 2.3467\n",
      "Epoch [1/1], Batch [26510/30000], Loss: 2.3438\n",
      "Epoch [1/1], Batch [26520/30000], Loss: 2.1719\n",
      "Epoch [1/1], Batch [26530/30000], Loss: 2.4141\n",
      "Epoch [1/1], Batch [26540/30000], Loss: 2.2676\n",
      "Epoch [1/1], Batch [26550/30000], Loss: 2.4053\n",
      "Epoch [1/1], Batch [26560/30000], Loss: 2.3838\n",
      "Epoch [1/1], Batch [26570/30000], Loss: 2.3066\n",
      "Epoch [1/1], Batch [26580/30000], Loss: 2.2246\n",
      "Epoch [1/1], Batch [26590/30000], Loss: 2.2754\n",
      "Epoch [1/1], Batch [26600/30000], Loss: 2.3223\n",
      "Epoch [1/1], Batch [26610/30000], Loss: 2.2695\n",
      "Epoch [1/1], Batch [26620/30000], Loss: 2.2617\n",
      "Epoch [1/1], Batch [26630/30000], Loss: 2.3174\n",
      "Epoch [1/1], Batch [26640/30000], Loss: 2.3447\n",
      "Epoch [1/1], Batch [26650/30000], Loss: 2.2666\n",
      "Epoch [1/1], Batch [26660/30000], Loss: 2.2285\n",
      "Epoch [1/1], Batch [26670/30000], Loss: 2.2617\n",
      "Epoch [1/1], Batch [26680/30000], Loss: 2.2676\n",
      "Epoch [1/1], Batch [26690/30000], Loss: 2.2852\n",
      "Epoch [1/1], Batch [26700/30000], Loss: 2.2871\n",
      "Epoch [1/1], Batch [26710/30000], Loss: 2.2500\n",
      "Epoch [1/1], Batch [26720/30000], Loss: 2.2988\n",
      "Epoch [1/1], Batch [26730/30000], Loss: 2.2061\n",
      "Epoch [1/1], Batch [26740/30000], Loss: 2.3662\n",
      "Epoch [1/1], Batch [26750/30000], Loss: 2.3623\n",
      "Epoch [1/1], Batch [26760/30000], Loss: 2.1494\n",
      "Epoch [1/1], Batch [26770/30000], Loss: 2.3574\n",
      "Epoch [1/1], Batch [26780/30000], Loss: 2.1826\n",
      "Epoch [1/1], Batch [26790/30000], Loss: 2.3018\n",
      "Epoch [1/1], Batch [26800/30000], Loss: 2.2549\n",
      "Epoch [1/1], Batch [26810/30000], Loss: 2.2686\n",
      "Epoch [1/1], Batch [26820/30000], Loss: 2.3838\n",
      "Epoch [1/1], Batch [26830/30000], Loss: 2.3623\n",
      "Epoch [1/1], Batch [26840/30000], Loss: 2.3770\n",
      "Epoch [1/1], Batch [26850/30000], Loss: 2.3838\n",
      "Epoch [1/1], Batch [26860/30000], Loss: 2.3135\n",
      "Epoch [1/1], Batch [26870/30000], Loss: 2.3740\n",
      "Epoch [1/1], Batch [26880/30000], Loss: 2.2676\n",
      "Epoch [1/1], Batch [26890/30000], Loss: 2.3564\n",
      "Epoch [1/1], Batch [26900/30000], Loss: 2.1768\n",
      "Epoch [1/1], Batch [26910/30000], Loss: 2.3584\n",
      "Epoch [1/1], Batch [26920/30000], Loss: 2.2100\n",
      "Epoch [1/1], Batch [26930/30000], Loss: 2.1904\n",
      "Epoch [1/1], Batch [26940/30000], Loss: 2.2070\n",
      "Epoch [1/1], Batch [26950/30000], Loss: 2.2979\n",
      "Epoch [1/1], Batch [26960/30000], Loss: 2.3018\n",
      "Epoch [1/1], Batch [26970/30000], Loss: 2.2832\n",
      "Epoch [1/1], Batch [26980/30000], Loss: 2.3174\n",
      "Epoch [1/1], Batch [26990/30000], Loss: 2.2441\n",
      "Epoch [1/1], Batch [27000/30000], Loss: 2.2930\n",
      "Epoch [1/1], Batch [27010/30000], Loss: 2.3604\n",
      "Epoch [1/1], Batch [27020/30000], Loss: 2.3105\n",
      "Epoch [1/1], Batch [27030/30000], Loss: 2.3066\n",
      "Epoch [1/1], Batch [27040/30000], Loss: 2.4082\n",
      "Epoch [1/1], Batch [27050/30000], Loss: 2.4033\n",
      "Epoch [1/1], Batch [27060/30000], Loss: 2.1362\n",
      "Epoch [1/1], Batch [27070/30000], Loss: 2.3242\n",
      "Epoch [1/1], Batch [27080/30000], Loss: 2.3604\n",
      "Epoch [1/1], Batch [27090/30000], Loss: 2.2422\n",
      "Epoch [1/1], Batch [27100/30000], Loss: 2.2549\n",
      "Epoch [1/1], Batch [27110/30000], Loss: 2.3594\n",
      "Epoch [1/1], Batch [27120/30000], Loss: 2.1914\n",
      "Epoch [1/1], Batch [27130/30000], Loss: 2.1836\n",
      "Epoch [1/1], Batch [27140/30000], Loss: 2.3721\n",
      "Epoch [1/1], Batch [27150/30000], Loss: 2.2314\n",
      "Epoch [1/1], Batch [27160/30000], Loss: 2.2246\n",
      "Epoch [1/1], Batch [27170/30000], Loss: 2.2812\n",
      "Epoch [1/1], Batch [27180/30000], Loss: 2.3516\n",
      "Epoch [1/1], Batch [27190/30000], Loss: 2.3418\n",
      "Epoch [1/1], Batch [27200/30000], Loss: 2.4199\n",
      "Epoch [1/1], Batch [27210/30000], Loss: 2.3564\n",
      "Epoch [1/1], Batch [27220/30000], Loss: 2.5195\n",
      "Epoch [1/1], Batch [27230/30000], Loss: 2.3066\n",
      "Epoch [1/1], Batch [27240/30000], Loss: 2.4209\n",
      "Epoch [1/1], Batch [27250/30000], Loss: 2.2598\n",
      "Epoch [1/1], Batch [27260/30000], Loss: 2.2959\n",
      "Epoch [1/1], Batch [27270/30000], Loss: 2.2627\n",
      "Epoch [1/1], Batch [27280/30000], Loss: 2.2500\n",
      "Epoch [1/1], Batch [27290/30000], Loss: 2.2666\n",
      "Epoch [1/1], Batch [27300/30000], Loss: 2.2588\n",
      "Epoch [1/1], Batch [27310/30000], Loss: 2.3555\n",
      "Epoch [1/1], Batch [27320/30000], Loss: 2.3398\n",
      "Epoch [1/1], Batch [27330/30000], Loss: 2.3398\n",
      "Epoch [1/1], Batch [27340/30000], Loss: 2.4619\n",
      "Epoch [1/1], Batch [27350/30000], Loss: 2.3604\n",
      "Epoch [1/1], Batch [27360/30000], Loss: 2.3389\n",
      "Epoch [1/1], Batch [27370/30000], Loss: 2.2891\n",
      "Epoch [1/1], Batch [27380/30000], Loss: 2.2637\n",
      "Epoch [1/1], Batch [27390/30000], Loss: 2.3154\n",
      "Epoch [1/1], Batch [27400/30000], Loss: 2.3535\n",
      "Epoch [1/1], Batch [27410/30000], Loss: 2.2422\n",
      "Epoch [1/1], Batch [27420/30000], Loss: 2.3105\n",
      "Epoch [1/1], Batch [27430/30000], Loss: 2.2637\n",
      "Epoch [1/1], Batch [27440/30000], Loss: 2.3359\n",
      "Epoch [1/1], Batch [27450/30000], Loss: 2.4053\n",
      "Epoch [1/1], Batch [27460/30000], Loss: 2.3379\n",
      "Epoch [1/1], Batch [27470/30000], Loss: 2.2803\n",
      "Epoch [1/1], Batch [27480/30000], Loss: 2.3164\n",
      "Epoch [1/1], Batch [27490/30000], Loss: 2.3145\n",
      "Epoch [1/1], Batch [27500/30000], Loss: 2.3457\n",
      "Epoch [1/1], Batch [27510/30000], Loss: 2.2480\n",
      "Epoch [1/1], Batch [27520/30000], Loss: 2.3770\n",
      "Epoch [1/1], Batch [27530/30000], Loss: 2.2393\n",
      "Epoch [1/1], Batch [27540/30000], Loss: 2.3330\n",
      "Epoch [1/1], Batch [27550/30000], Loss: 2.3975\n",
      "Epoch [1/1], Batch [27560/30000], Loss: 2.2178\n",
      "Epoch [1/1], Batch [27570/30000], Loss: 2.3457\n",
      "Epoch [1/1], Batch [27580/30000], Loss: 2.3506\n",
      "Epoch [1/1], Batch [27590/30000], Loss: 2.2607\n",
      "Epoch [1/1], Batch [27600/30000], Loss: 2.3525\n",
      "Epoch [1/1], Batch [27610/30000], Loss: 2.2998\n",
      "Epoch [1/1], Batch [27620/30000], Loss: 2.4404\n",
      "Epoch [1/1], Batch [27630/30000], Loss: 2.3535\n",
      "Epoch [1/1], Batch [27640/30000], Loss: 2.2373\n",
      "Epoch [1/1], Batch [27650/30000], Loss: 2.3193\n",
      "Epoch [1/1], Batch [27660/30000], Loss: 2.2842\n",
      "Epoch [1/1], Batch [27670/30000], Loss: 2.2686\n",
      "Epoch [1/1], Batch [27680/30000], Loss: 2.3223\n",
      "Epoch [1/1], Batch [27690/30000], Loss: 2.2910\n",
      "Epoch [1/1], Batch [27700/30000], Loss: 2.3828\n",
      "Epoch [1/1], Batch [27710/30000], Loss: 2.3418\n",
      "Epoch [1/1], Batch [27720/30000], Loss: 2.3486\n",
      "Epoch [1/1], Batch [27730/30000], Loss: 2.2549\n",
      "Epoch [1/1], Batch [27740/30000], Loss: 2.3438\n",
      "Epoch [1/1], Batch [27750/30000], Loss: 2.3652\n",
      "Epoch [1/1], Batch [27760/30000], Loss: 2.2236\n",
      "Epoch [1/1], Batch [27770/30000], Loss: 2.2793\n",
      "Epoch [1/1], Batch [27780/30000], Loss: 2.3750\n",
      "Epoch [1/1], Batch [27790/30000], Loss: 2.2656\n",
      "Epoch [1/1], Batch [27800/30000], Loss: 2.3203\n",
      "Epoch [1/1], Batch [27810/30000], Loss: 2.3115\n",
      "Epoch [1/1], Batch [27820/30000], Loss: 2.2871\n",
      "Epoch [1/1], Batch [27830/30000], Loss: 2.2988\n",
      "Epoch [1/1], Batch [27840/30000], Loss: 2.4941\n",
      "Epoch [1/1], Batch [27850/30000], Loss: 2.3535\n",
      "Epoch [1/1], Batch [27860/30000], Loss: 2.3242\n",
      "Epoch [1/1], Batch [27870/30000], Loss: 2.1582\n",
      "Epoch [1/1], Batch [27880/30000], Loss: 2.3936\n",
      "Epoch [1/1], Batch [27890/30000], Loss: 2.5469\n",
      "Epoch [1/1], Batch [27900/30000], Loss: 2.4219\n",
      "Epoch [1/1], Batch [27910/30000], Loss: 2.1992\n",
      "Epoch [1/1], Batch [27920/30000], Loss: 2.5068\n",
      "Epoch [1/1], Batch [27930/30000], Loss: 2.3203\n",
      "Epoch [1/1], Batch [27940/30000], Loss: 2.2861\n",
      "Epoch [1/1], Batch [27950/30000], Loss: 2.3145\n",
      "Epoch [1/1], Batch [27960/30000], Loss: 2.3467\n",
      "Epoch [1/1], Batch [27970/30000], Loss: 2.3730\n",
      "Epoch [1/1], Batch [27980/30000], Loss: 2.3145\n",
      "Epoch [1/1], Batch [27990/30000], Loss: 2.3154\n",
      "Epoch [1/1], Batch [28000/30000], Loss: 2.4434\n",
      "Epoch [1/1], Batch [28010/30000], Loss: 2.4189\n",
      "Epoch [1/1], Batch [28020/30000], Loss: 2.2529\n",
      "Epoch [1/1], Batch [28030/30000], Loss: 2.2500\n",
      "Epoch [1/1], Batch [28040/30000], Loss: 2.2568\n",
      "Epoch [1/1], Batch [28050/30000], Loss: 2.4082\n",
      "Epoch [1/1], Batch [28060/30000], Loss: 2.2510\n",
      "Epoch [1/1], Batch [28070/30000], Loss: 2.2266\n",
      "Epoch [1/1], Batch [28080/30000], Loss: 2.1494\n",
      "Epoch [1/1], Batch [28090/30000], Loss: 2.6514\n",
      "Epoch [1/1], Batch [28100/30000], Loss: 2.3291\n",
      "Epoch [1/1], Batch [28110/30000], Loss: 2.1289\n",
      "Epoch [1/1], Batch [28120/30000], Loss: 2.2822\n",
      "Epoch [1/1], Batch [28130/30000], Loss: 2.2227\n",
      "Epoch [1/1], Batch [28140/30000], Loss: 2.0361\n",
      "Epoch [1/1], Batch [28150/30000], Loss: 2.4980\n",
      "Epoch [1/1], Batch [28160/30000], Loss: 2.3037\n",
      "Epoch [1/1], Batch [28170/30000], Loss: 2.3203\n",
      "Epoch [1/1], Batch [28180/30000], Loss: 2.2529\n",
      "Epoch [1/1], Batch [28190/30000], Loss: 2.2500\n",
      "Epoch [1/1], Batch [28200/30000], Loss: 2.3115\n",
      "Epoch [1/1], Batch [28210/30000], Loss: 2.1436\n",
      "Epoch [1/1], Batch [28220/30000], Loss: 2.3613\n",
      "Epoch [1/1], Batch [28230/30000], Loss: 2.1113\n",
      "Epoch [1/1], Batch [28240/30000], Loss: 2.3594\n",
      "Epoch [1/1], Batch [28250/30000], Loss: 2.4199\n",
      "Epoch [1/1], Batch [28260/30000], Loss: 2.4385\n",
      "Epoch [1/1], Batch [28270/30000], Loss: 2.2705\n",
      "Epoch [1/1], Batch [28280/30000], Loss: 2.3730\n",
      "Epoch [1/1], Batch [28290/30000], Loss: 2.3320\n",
      "Epoch [1/1], Batch [28300/30000], Loss: 2.2783\n",
      "Epoch [1/1], Batch [28310/30000], Loss: 2.1055\n",
      "Epoch [1/1], Batch [28320/30000], Loss: 2.4062\n",
      "Epoch [1/1], Batch [28330/30000], Loss: 2.3799\n",
      "Epoch [1/1], Batch [28340/30000], Loss: 2.2695\n",
      "Epoch [1/1], Batch [28350/30000], Loss: 2.2783\n",
      "Epoch [1/1], Batch [28360/30000], Loss: 2.3740\n",
      "Epoch [1/1], Batch [28370/30000], Loss: 2.3184\n",
      "Epoch [1/1], Batch [28380/30000], Loss: 2.2734\n",
      "Epoch [1/1], Batch [28390/30000], Loss: 2.2930\n",
      "Epoch [1/1], Batch [28400/30000], Loss: 2.2217\n",
      "Epoch [1/1], Batch [28410/30000], Loss: 2.3105\n",
      "Epoch [1/1], Batch [28420/30000], Loss: 2.2705\n",
      "Epoch [1/1], Batch [28430/30000], Loss: 2.3301\n",
      "Epoch [1/1], Batch [28440/30000], Loss: 2.2959\n",
      "Epoch [1/1], Batch [28450/30000], Loss: 2.2969\n",
      "Epoch [1/1], Batch [28460/30000], Loss: 2.1279\n",
      "Epoch [1/1], Batch [28470/30000], Loss: 2.2471\n",
      "Epoch [1/1], Batch [28480/30000], Loss: 2.5693\n",
      "Epoch [1/1], Batch [28490/30000], Loss: 2.4844\n",
      "Epoch [1/1], Batch [28500/30000], Loss: 2.2031\n",
      "Epoch [1/1], Batch [28510/30000], Loss: 2.3340\n",
      "Epoch [1/1], Batch [28520/30000], Loss: 2.2412\n",
      "Epoch [1/1], Batch [28530/30000], Loss: 2.2021\n",
      "Epoch [1/1], Batch [28540/30000], Loss: 2.3408\n",
      "Epoch [1/1], Batch [28550/30000], Loss: 2.0918\n",
      "Epoch [1/1], Batch [28560/30000], Loss: 2.2891\n",
      "Epoch [1/1], Batch [28570/30000], Loss: 2.3516\n",
      "Epoch [1/1], Batch [28580/30000], Loss: 2.3789\n",
      "Epoch [1/1], Batch [28590/30000], Loss: 2.4746\n",
      "Epoch [1/1], Batch [28600/30000], Loss: 2.2764\n",
      "Epoch [1/1], Batch [28610/30000], Loss: 2.3438\n",
      "Epoch [1/1], Batch [28620/30000], Loss: 2.2764\n",
      "Epoch [1/1], Batch [28630/30000], Loss: 2.1201\n",
      "Epoch [1/1], Batch [28640/30000], Loss: 2.2822\n",
      "Epoch [1/1], Batch [28650/30000], Loss: 2.2461\n",
      "Epoch [1/1], Batch [28660/30000], Loss: 2.2803\n",
      "Epoch [1/1], Batch [28670/30000], Loss: 2.3594\n",
      "Epoch [1/1], Batch [28680/30000], Loss: 2.3281\n",
      "Epoch [1/1], Batch [28690/30000], Loss: 2.3105\n",
      "Epoch [1/1], Batch [28700/30000], Loss: 2.3506\n",
      "Epoch [1/1], Batch [28710/30000], Loss: 2.2793\n",
      "Epoch [1/1], Batch [28720/30000], Loss: 2.2021\n",
      "Epoch [1/1], Batch [28730/30000], Loss: 2.2627\n",
      "Epoch [1/1], Batch [28740/30000], Loss: 2.2676\n",
      "Epoch [1/1], Batch [28750/30000], Loss: 2.2568\n",
      "Epoch [1/1], Batch [28760/30000], Loss: 2.2773\n",
      "Epoch [1/1], Batch [28770/30000], Loss: 2.5293\n",
      "Epoch [1/1], Batch [28780/30000], Loss: 2.3359\n",
      "Epoch [1/1], Batch [28790/30000], Loss: 2.3555\n",
      "Epoch [1/1], Batch [28800/30000], Loss: 2.4199\n",
      "Epoch [1/1], Batch [28810/30000], Loss: 2.3047\n",
      "Epoch [1/1], Batch [28820/30000], Loss: 2.1445\n",
      "Epoch [1/1], Batch [28830/30000], Loss: 2.3252\n",
      "Epoch [1/1], Batch [28840/30000], Loss: 2.0977\n",
      "Epoch [1/1], Batch [28850/30000], Loss: 2.3125\n",
      "Epoch [1/1], Batch [28860/30000], Loss: 2.3398\n",
      "Epoch [1/1], Batch [28870/30000], Loss: 2.2207\n",
      "Epoch [1/1], Batch [28880/30000], Loss: 2.4746\n",
      "Epoch [1/1], Batch [28890/30000], Loss: 2.2881\n",
      "Epoch [1/1], Batch [28900/30000], Loss: 2.3672\n",
      "Epoch [1/1], Batch [28910/30000], Loss: 2.2715\n",
      "Epoch [1/1], Batch [28920/30000], Loss: 2.2627\n",
      "Epoch [1/1], Batch [28930/30000], Loss: 2.2490\n",
      "Epoch [1/1], Batch [28940/30000], Loss: 2.3311\n",
      "Epoch [1/1], Batch [28950/30000], Loss: 2.2285\n",
      "Epoch [1/1], Batch [28960/30000], Loss: 2.2939\n",
      "Epoch [1/1], Batch [28970/30000], Loss: 2.3516\n",
      "Epoch [1/1], Batch [28980/30000], Loss: 2.2422\n",
      "Epoch [1/1], Batch [28990/30000], Loss: 2.3057\n",
      "Epoch [1/1], Batch [29000/30000], Loss: 2.2979\n",
      "Epoch [1/1], Batch [29010/30000], Loss: 2.2822\n",
      "Epoch [1/1], Batch [29020/30000], Loss: 2.3037\n",
      "Epoch [1/1], Batch [29030/30000], Loss: 2.2139\n",
      "Epoch [1/1], Batch [29040/30000], Loss: 2.1943\n",
      "Epoch [1/1], Batch [29050/30000], Loss: 2.2832\n",
      "Epoch [1/1], Batch [29060/30000], Loss: 2.3574\n",
      "Epoch [1/1], Batch [29070/30000], Loss: 2.1802\n",
      "Epoch [1/1], Batch [29080/30000], Loss: 2.1606\n",
      "Epoch [1/1], Batch [29090/30000], Loss: 2.2266\n",
      "Epoch [1/1], Batch [29100/30000], Loss: 2.1416\n",
      "Epoch [1/1], Batch [29110/30000], Loss: 2.3936\n",
      "Epoch [1/1], Batch [29120/30000], Loss: 2.2207\n",
      "Epoch [1/1], Batch [29130/30000], Loss: 2.4590\n",
      "Epoch [1/1], Batch [29140/30000], Loss: 2.3896\n",
      "Epoch [1/1], Batch [29150/30000], Loss: 2.1982\n",
      "Epoch [1/1], Batch [29160/30000], Loss: 2.1328\n",
      "Epoch [1/1], Batch [29170/30000], Loss: 2.3604\n",
      "Epoch [1/1], Batch [29180/30000], Loss: 2.3682\n",
      "Epoch [1/1], Batch [29190/30000], Loss: 2.3506\n",
      "Epoch [1/1], Batch [29200/30000], Loss: 2.3721\n",
      "Epoch [1/1], Batch [29210/30000], Loss: 2.3652\n",
      "Epoch [1/1], Batch [29220/30000], Loss: 1.9922\n",
      "Epoch [1/1], Batch [29230/30000], Loss: 2.3008\n",
      "Epoch [1/1], Batch [29240/30000], Loss: 2.3652\n",
      "Epoch [1/1], Batch [29250/30000], Loss: 2.3027\n",
      "Epoch [1/1], Batch [29260/30000], Loss: 2.2021\n",
      "Epoch [1/1], Batch [29270/30000], Loss: 2.0293\n",
      "Epoch [1/1], Batch [29280/30000], Loss: 2.2305\n",
      "Epoch [1/1], Batch [29290/30000], Loss: 2.2451\n",
      "Epoch [1/1], Batch [29300/30000], Loss: 2.2891\n",
      "Epoch [1/1], Batch [29310/30000], Loss: 2.2725\n",
      "Epoch [1/1], Batch [29320/30000], Loss: 2.2920\n",
      "Epoch [1/1], Batch [29330/30000], Loss: 2.4072\n",
      "Epoch [1/1], Batch [29340/30000], Loss: 2.4150\n",
      "Epoch [1/1], Batch [29350/30000], Loss: 2.4678\n",
      "Epoch [1/1], Batch [29360/30000], Loss: 2.4443\n",
      "Epoch [1/1], Batch [29370/30000], Loss: 2.3945\n",
      "Epoch [1/1], Batch [29380/30000], Loss: 2.2256\n",
      "Epoch [1/1], Batch [29390/30000], Loss: 2.4541\n",
      "Epoch [1/1], Batch [29400/30000], Loss: 2.3291\n",
      "Epoch [1/1], Batch [29410/30000], Loss: 2.2852\n",
      "Epoch [1/1], Batch [29420/30000], Loss: 2.3340\n",
      "Epoch [1/1], Batch [29430/30000], Loss: 2.3115\n",
      "Epoch [1/1], Batch [29440/30000], Loss: 2.3721\n",
      "Epoch [1/1], Batch [29450/30000], Loss: 2.3252\n",
      "Epoch [1/1], Batch [29460/30000], Loss: 2.4043\n",
      "Epoch [1/1], Batch [29470/30000], Loss: 2.3252\n",
      "Epoch [1/1], Batch [29480/30000], Loss: 2.4453\n",
      "Epoch [1/1], Batch [29490/30000], Loss: 2.2539\n",
      "Epoch [1/1], Batch [29500/30000], Loss: 2.3242\n",
      "Epoch [1/1], Batch [29510/30000], Loss: 2.4512\n",
      "Epoch [1/1], Batch [29520/30000], Loss: 2.2861\n",
      "Epoch [1/1], Batch [29530/30000], Loss: 2.3584\n",
      "Epoch [1/1], Batch [29540/30000], Loss: 2.3232\n",
      "Epoch [1/1], Batch [29550/30000], Loss: 2.2852\n",
      "Epoch [1/1], Batch [29560/30000], Loss: 2.2686\n",
      "Epoch [1/1], Batch [29570/30000], Loss: 2.3213\n",
      "Epoch [1/1], Batch [29580/30000], Loss: 2.3096\n",
      "Epoch [1/1], Batch [29590/30000], Loss: 2.2197\n",
      "Epoch [1/1], Batch [29600/30000], Loss: 2.2451\n",
      "Epoch [1/1], Batch [29610/30000], Loss: 1.9404\n",
      "Epoch [1/1], Batch [29620/30000], Loss: 2.3564\n",
      "Epoch [1/1], Batch [29630/30000], Loss: 2.3359\n",
      "Epoch [1/1], Batch [29640/30000], Loss: 2.2930\n",
      "Epoch [1/1], Batch [29650/30000], Loss: 2.2168\n",
      "Epoch [1/1], Batch [29660/30000], Loss: 2.3184\n",
      "Epoch [1/1], Batch [29670/30000], Loss: 2.2256\n",
      "Epoch [1/1], Batch [29680/30000], Loss: 2.3369\n",
      "Epoch [1/1], Batch [29690/30000], Loss: 2.2676\n",
      "Epoch [1/1], Batch [29700/30000], Loss: 2.2275\n",
      "Epoch [1/1], Batch [29710/30000], Loss: 2.3486\n",
      "Epoch [1/1], Batch [29720/30000], Loss: 2.2812\n",
      "Epoch [1/1], Batch [29730/30000], Loss: 2.2783\n",
      "Epoch [1/1], Batch [29740/30000], Loss: 2.3906\n",
      "Epoch [1/1], Batch [29750/30000], Loss: 2.0781\n",
      "Epoch [1/1], Batch [29760/30000], Loss: 2.4961\n",
      "Epoch [1/1], Batch [29770/30000], Loss: 2.1611\n",
      "Epoch [1/1], Batch [29780/30000], Loss: 2.3613\n",
      "Epoch [1/1], Batch [29790/30000], Loss: 2.3066\n",
      "Epoch [1/1], Batch [29800/30000], Loss: 2.3613\n",
      "Epoch [1/1], Batch [29810/30000], Loss: 2.3906\n",
      "Epoch [1/1], Batch [29820/30000], Loss: 2.2812\n",
      "Epoch [1/1], Batch [29830/30000], Loss: 2.3008\n",
      "Epoch [1/1], Batch [29840/30000], Loss: 2.5479\n",
      "Epoch [1/1], Batch [29850/30000], Loss: 2.2227\n",
      "Epoch [1/1], Batch [29860/30000], Loss: 2.3291\n",
      "Epoch [1/1], Batch [29870/30000], Loss: 2.3682\n",
      "Epoch [1/1], Batch [29880/30000], Loss: 2.1973\n",
      "Epoch [1/1], Batch [29890/30000], Loss: 2.3672\n",
      "Epoch [1/1], Batch [29900/30000], Loss: 2.2129\n",
      "Epoch [1/1], Batch [29910/30000], Loss: 2.3438\n",
      "Epoch [1/1], Batch [29920/30000], Loss: 2.4756\n",
      "Epoch [1/1], Batch [29930/30000], Loss: 2.2842\n",
      "Epoch [1/1], Batch [29940/30000], Loss: 2.2930\n",
      "Epoch [1/1], Batch [29950/30000], Loss: 2.2871\n",
      "Epoch [1/1], Batch [29960/30000], Loss: 2.3613\n",
      "Epoch [1/1], Batch [29970/30000], Loss: 2.2881\n",
      "Epoch [1/1], Batch [29980/30000], Loss: 2.2695\n",
      "Epoch [1/1], Batch [29990/30000], Loss: 2.4229\n",
      "Epoch 1/1 completed. Average Loss: 2.3188\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, criterion, optimizer, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6d3944b-9a84-4769-9b32-0734f7133ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.3016, Accuracy: 11.35%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.301613800764084, 11.35)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Run evaluation\n",
    "evaluate_model(model, test_loader, criterion)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30650c54-4b93-4af6-be25-9cdc3d3bc9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_env)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
